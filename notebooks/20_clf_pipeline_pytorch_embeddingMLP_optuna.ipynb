{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERAL THOUGHTS:**\n",
    "\n",
    "\n",
    "\n",
    "**DATA PREPROCESSING:**\n",
    "\n",
    "Imbalanced data:\n",
    "- over_sampling for imbalanced data\n",
    "- cost-sensitive learning for imbalanced data\n",
    "\n",
    "continuous data:\n",
    "- Impute missing data: SimpleImputer(strategy='median')\n",
    "- Standardize data: StandardScaler()\n",
    "\n",
    "categorical data:\n",
    "- Impute missing data: SimpleImputer(strategy='most_frequent')\n",
    "- Ordinal & Nominal data encoding: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "- Unknown values ecoding: custom encoder \"OrdinalEncoderExtensionUnknowns()\"\n",
    "\n",
    "target data:\n",
    "- target encoding: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "**MULTI-CLASS CLASSIFIER:**\n",
    "- Overview models to be considered:  \n",
    "Models:\n",
    "  - [X] Neural Net: MLP with categorical variable embedding (embMLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "  # Import the library to mount Google Drive\n",
    "  from google.colab import drive\n",
    "  # Mount the Google Drive at /content/drive\n",
    "  drive.mount('/content/drive')\n",
    "  # Verify by listing the files in the drive\n",
    "  # !ls /content/drive/My\\ Drive/\n",
    "  # current dir in colab\n",
    "  !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install optuna==3.5.0\n",
    "    # !pip install optuna.integration\n",
    "    !pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "from typing import Dict, Iterable, List, Optional, Tuple, Union, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: if used in google colab, upload env_vars_colab.yml to current google colab directory!\n",
    "\n",
    "# get config\n",
    "if colab:\n",
    "    with open('./env_vars_colab.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    # custom imports\n",
    "    sys.path.append(config['project_directory'])\n",
    "else:\n",
    "    with open('../env_vars.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    # custom imports\n",
    "    sys.path.append(config['project_directory'])\n",
    "\n",
    "from src.tabular_lightning import TabularDataModuleClassificationPACKAGING, MulticlassTabularLightningModule\n",
    "from src import tabular_lightning_utils as tl_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 # Ensure same data split as in other notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets, DataLoaders & LightningDataModule\n",
    "- Logic of using `Datasets`, `DataLoaders` & `LightningDataModule` for **Tabular Data**  \n",
    "    Since we are using tabular data and want to perform non tensor based processing to our date, we use Datasets, DataLoaders & LightningDataModule in a different manner as we would do when applying tensor operations (incl. tensor based preprpcessing) only.  \n",
    "    - `LightningDataModule` \n",
    "        Our LightningDataModule builds the wrapper around this process, with the following intensions:\n",
    "        - `def prepare_data`  \n",
    "        Data Operations that only should be performed once on the data (and should not be performed on a distributed manner). Prepares the data for data pre-processing e.g. using sklearn.  \n",
    "            - Loading the data from .csv to pd.DataFrame\n",
    "            - General dataset preperations like feature selection and data type correction\n",
    "        - `def setup`  \n",
    "        First, data operations (like shuffle, split data, categorical encoding, normalization, etc.), which any dataframe should undergo before feeding into the dataloader will be performed here. Since we use sklearn functionalities for our tabular pre-processing pipeline the data input and output of the pre-processing is a tabular format (dataframe) and not a tensor format.\n",
    "        Second, the outcome of `def setup` are `Dataset` objects for each split (e.g. train, val, test, pred), which is a wrapper around the pre-processed tabular data and provides the samples and their corresponding labels (ideally in tensor format) in a specific way to be compatible for the model(s).\n",
    "            - `Dataset`  \n",
    "            Dataset provides the samples and their corresponding labels in a specific way to be compatible for the model(s). We define the input for our tabular use case as a DataFrame, while the output should generally be a tensor. In our case the output is a tuple of a flattern tensor representing all features and a tensor for the target variable (label). This aligns with the input if a simple MLP model. For more complex models, e.g. that handle continous and categorical variables differently, this should be adapted.  \n",
    "            The class performs specific data type correction for to use of Neural Networks (e.g. ensure that all outputs are numeric values of the correct type depeding of they are categorical or continous nature).\n",
    "        - `def train/val/test/prediction_dataloader`  \n",
    "        Creates our dataloaders within the LightningDataModule. See usage below.\n",
    "            - `DataLoader` \n",
    "            DataLoader wraps an iterable around the Dataset to enable easy access to the samples during training and inference. The Dataset defines the format of the data that is passed to our model. The DataLoader retrieves our dataset’s features and labels. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval, which is handled by the DataLoader. Input and output is a tensor. https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "- Excorsion: Classical approach of using `Datasets`, `DataLoaders` & `LightningDataModule` for e.g. images, ...  \n",
    "The main difference is the usage of tensors instead of a dataframe for efficent GPU usage.\n",
    "    - `LightningDataModule` \n",
    "        Our LightningDataModule builds the wrapper around this process. It encapsulates training, validation, testing, and prediction dataloaders, as well as any necessary steps for data processing, downloads, and transformations. https://lightning.ai/docs/pytorch/stable/data/datamodule.html\n",
    "        - `def prepare_data`  \n",
    "        Loads the data and does general processing befor transfomring to a tensor, so efficent tensor operations can be enabled in `setup'.\n",
    "        - `def setup`  \n",
    "        Efficent tensor operations (like shuffle, split data, categorical encoding, normalization, etc.), which any dataframe should undergo before feeding into the dataloader.\n",
    "        - `def train/val/test_dataloader`  \n",
    "        Creates our dataloaders within the LightningDataModule.\n",
    "    - `Dataset`\n",
    "    Class to create tabular dataset to follow PyTorch Lightning conventions (eventhough we are working on tabular data), where the data for feature variables and the target variable are often already provided in a combined way (e.g. contrary to images and corresbonding labels). For \"classical\" approaches a Dataset class is often used at the start of the machine learning pipeline to provide the data in a format (e.g. combine images and corresponding labels, which are typically not provided in the same file) for further processing and training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TabularDataModuleClassificationPACKAGING(\n",
    "    data_dir=f\"{config['data_directory']}/output/df_ml.csv\",\n",
    "    continuous_cols=['material_weight'],\n",
    "    categorical_cols=[\n",
    "        'material_number',\n",
    "        'brand',\n",
    "        'product_area',\n",
    "        'core_segment',\n",
    "        'component',\n",
    "        'manufactoring_location',\n",
    "        'characteristic_value',\n",
    "        'packaging_code'\n",
    "    ],\n",
    "    target=['packaging_category'],\n",
    "    oversampling=True,\n",
    "    test_size=0.2,\n",
    "    val_size=0.2,\n",
    "    batch_size=64,\n",
    "    num_workers_train=0, # (os.cpu_count() / 2)\n",
    "    num_workers_inference=0, # (os.cpu_count() / 2)\n",
    "    SEED=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Run dm.prepare_data() and dm.setup() to get information from the dataset to build the model.\n",
    "dm.prepare_data()\n",
    "dm.setup(stage='fit')\n",
    "# dm.data.info()\n",
    "# dm.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.train_dataset.get_dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_utils.check_data_consitancy(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_utils.check_dataloader_output(dm, next(iter(dm.train_dataloader())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_utils.print_dataloader_output(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models and Training/HPO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embbeding MLP without HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_data_full = pd.concat([dm.train_dataset.get_dataframe, dm.val_dataset.get_dataframe, dm.test_dataset.get_dataframe], axis=0, ignore_index=True)\n",
    "embedding_sizes_cat_features = tl_utils.get_cat_feature_embedding_sizes(tabular_data_full, categorical_cols=dm.categorical_cols)\n",
    "embedding_sizes_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_utils.print_embbeding_input_output(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassTabularCatEmbeddingMLP(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        continuous_cols: List[str] = None,\n",
    "        categorical_cols: List[str] = None,\n",
    "        output_size: int = None,\n",
    "        # embedding_dim: int = None,\n",
    "        hidden_size: int = None,\n",
    "        n_hidden_layers: int = None,\n",
    "        activation_class: torch.nn.functional = nn.ReLU,\n",
    "        dropout: float = None,\n",
    "        norm: bool = True,\n",
    "        embedding_sizes: (Dict[str, Tuple[int, int]]) = None,\n",
    "    ):\n",
    "        \"\"\"Embedding Multi Layer Perceptron (embMLP) with embedding for categorical features for multiclass classification for tabular data.\n",
    "        Args:\n",
    "            continues_cols (List[str]): order of continuous variables in tensor passed to forward function.\n",
    "            categorical_cols (List[str]): order of categorical variables in tensor passed to forward function.\n",
    "            output_size (int): Number of output classes.\n",
    "            hidden_size (int): Number of neurons in hidden layers.\n",
    "            n_hidden_layers (int): Number of hidden layers.\n",
    "            activation_class (torch.nn.functional): Activation function.\n",
    "            dropout (float): Dropout rate.\n",
    "            norm (bool): Whether to use layer normalization.\n",
    "            embedding_sizes (Dict[str, Tuple[int, int]]): Dictionary of embedding sizes for each categorical feature.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.continuous_cols = continuous_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.output_size = output_size\n",
    "        self.embedding_sizes = embedding_sizes\n",
    "        # self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.activation_class = activation_class\n",
    "        self.dropout = dropout\n",
    "        self.norm = norm\n",
    "\n",
    "        ### define the Embedding MLP ###\n",
    "        ## embedding layers\n",
    "        # cont featurres\n",
    "        self.cont_normalizing = nn.BatchNorm1d(len(self.continuous_cols))\n",
    "        # cat features\n",
    "        self.cat_embeddings = nn.ModuleDict()\n",
    "        for name in embedding_sizes.keys():\n",
    "            self.cat_embeddings[name] = nn.Embedding(\n",
    "                embedding_sizes[name][0],\n",
    "                embedding_sizes[name][1],\n",
    "            )\n",
    "        ## input layer mlp\n",
    "        mlp_input_size = sum(value[1] for value in embedding_sizes.values()) + len(self.continuous_cols)\n",
    "        module_list = [nn.Linear(mlp_input_size, hidden_size), activation_class()]\n",
    "        if dropout is not None:\n",
    "            module_list.append(nn.Dropout(dropout))\n",
    "        if norm:\n",
    "            module_list.append(nn.LayerNorm(hidden_size))\n",
    "        ## hidden layers\n",
    "        for _ in range(n_hidden_layers):\n",
    "            module_list.extend([nn.Linear(hidden_size, hidden_size), activation_class()])\n",
    "            if dropout is not None:\n",
    "                module_list.append(nn.Dropout(dropout))\n",
    "            if norm:\n",
    "                module_list.append(nn.LayerNorm(hidden_size))\n",
    "        ## output layer\n",
    "        module_list.append(nn.Linear(hidden_size, output_size))\n",
    "\n",
    "        self.mlp_layers = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the embMLP.\"\"\"\n",
    "\n",
    "        assert \"continuous\" in x or \"categorical\" in x, \"x must contain either continuous or categorical features\"\n",
    "\n",
    "        ### forward embedding layers ###\n",
    "        # cont features\n",
    "        if len(self.continuous_cols) > 0:\n",
    "            embed_vector_cont = self.cont_normalizing(x[\"continuous\"])\n",
    "        else:\n",
    "            embed_vector_cont = x[\"continuous\"]\n",
    "        # cat features\n",
    "        if len(self.categorical_cols) > 0:\n",
    "            output_vectors = {}\n",
    "            for idx, (name, emb) in enumerate(self.cat_embeddings.items()):\n",
    "                output_vectors[name] = emb(x[\"categorical\"][:, idx])\n",
    "            embed_vector_cat = torch.cat(list(output_vectors.values()), dim=1)\n",
    "        # output_vector_emded\n",
    "        if embed_vector_cont is None:\n",
    "            output_vector_emded = embed_vector_cat\n",
    "        else:\n",
    "            output_vector_emded = torch.cat([embed_vector_cont, embed_vector_cat], dim=1)\n",
    "\n",
    "        ### forward hidden layers ###\n",
    "        return self.mlp_layers(output_vector_emded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Run dm.prepare_data() and dm.setup() to get information from the dataset to build your model.\n",
    "multiclass_embMLP = MulticlassTabularCatEmbeddingMLP(\n",
    "    continuous_cols=dm.continuous_cols,\n",
    "    categorical_cols=dm.categorical_cols,\n",
    "    output_size=dm.n_classes,\n",
    "    hidden_size=64,\n",
    "    n_hidden_layers=3,\n",
    "    dropout=0.2,\n",
    "    norm=True,\n",
    "    embedding_sizes=embedding_sizes_cat_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_utils.print_model_summary(multiclass_embMLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightningmodel = MulticlassTabularLightningModule(\n",
    "    n_classes=dm.n_classes,\n",
    "    model=multiclass_embMLP,\n",
    "    learning_rate=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empmlp_experiment_name = \"embMLP-v0\"\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    devices=\"auto\", # (os.cpu_count() / 2)\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', min_delta=0.00, patience=5),\n",
    "        # L.ModelCheckpoint(\n",
    "        #     monitor=\"val_loss\",\n",
    "        #     mode=\"min\",\n",
    "        #     save_top_k=1,\n",
    "        #     save_path=f\"{save_path}/checkpoints\",\n",
    "        #     filename=\"best_model\",\n",
    "        # ),\n",
    "    ],\n",
    "    logger=CSVLogger(save_dir=\"logs/\", name=empmlp_experiment_name),\n",
    "    max_epochs=2,\n",
    "    precision='bf16-mixed',\n",
    "    default_root_dir=\"lightning_logs/\",\n",
    ")\n",
    "\n",
    "# create a Tuner\n",
    "tuner = Tuner(trainer)\n",
    "\n",
    "# finds learning rate automatically, update hparams.lr to that learning rate\n",
    "lr_finder = tuner.lr_find(lightningmodel, datamodule=dm)\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "#fig.savefig(\"lr_suggest.pdf\")\n",
    "# get suggestion\n",
    "new_lr = lr_finder.suggestion()\n",
    "print(new_lr)\n",
    "# update hparams of the model\n",
    "lightningmodel.learning_rate = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "trainer.fit(model=lightningmodel, train_dataloaders=dm.train_dataloader(), val_dataloaders=dm.val_dataloader()) # stage of the dataloader to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "\n",
    "tl_utils.plot_training_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = trainer.test(model=lightningmodel, dataloaders=dm.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score[0]['test_F1_macro_weighted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test data and evaluate\n",
    "preds_y_test = torch.cat(trainer.predict(model=lightningmodel, dataloaders=dm.test_dataloader()))\n",
    "# inverse transform to get back to original labels\n",
    "preds_y_test = dm.label_encoder_target.inverse_transform(preds_y_test.reshape(-1, 1))\n",
    "y_test = dm.label_encoder_target.inverse_transform(dm.test_dataset.get_dataframe.iloc[:, -1].values.reshape(-1, 1))\n",
    "# calculate classification report\n",
    "print(classification_report(y_test, preds_y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding MLP with HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performe HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptunaObjective(object):\n",
    "    \"\"\"Optuna objective for hyperparameter tuning.\"\"\"\n",
    "    def __init__(self, dm: TabularDataModuleClassificationPACKAGING = None):\n",
    "        self.dm = dm\n",
    "        self.dm.prepare_data()\n",
    "        self.dm.setup(stage='fit')\n",
    "\n",
    "        tabular_data_full = pd.concat([self.dm.train_dataset.get_dataframe, self.dm.val_dataset.get_dataframe, self.dm.test_dataset.get_dataframe], axis=0, ignore_index=True)\n",
    "        self.embedding_sizes_cat_features = tl_utils.get_cat_feature_embedding_sizes(tabular_data_full, categorical_cols=self.dm.categorical_cols)\n",
    "\n",
    "    def __call__(self, trial: optuna.Trial) -> float:\n",
    "        \n",
    "        # joblib.dump(study, 'study.pkl')\n",
    "\n",
    "        # Define the hyperparameter search space\n",
    "        hp_space_optuna = {\n",
    "            'hidden_size': trial.suggest_categorical('hidden_size', [8, 16, 32, 64, 128]), # number of neurons in each layer\n",
    "            'n_hidden_layers': trial.suggest_int(\"n_hidden_layers\", 1, 6), # number of layers\n",
    "            'batch_size': trial.suggest_categorical(\"batch_size\", [16, 32, 64]), # number of samples per batch\n",
    "            'dropout': trial.suggest_categorical(\"dropout\", [0.0, 0.1, 0.2, 0.4]), # dropout rate\n",
    "        }\n",
    "        self.dm.batch_size = hp_space_optuna['batch_size']\n",
    "        # Create a model\n",
    "        model = MulticlassTabularCatEmbeddingMLP(\n",
    "            continuous_cols=self.dm.continuous_cols,\n",
    "            categorical_cols=self.dm.categorical_cols,\n",
    "            output_size=self.dm.n_classes,\n",
    "            hidden_size=hp_space_optuna['hidden_size'],\n",
    "            n_hidden_layers=hp_space_optuna['n_hidden_layers'],\n",
    "            dropout=hp_space_optuna['dropout'],\n",
    "            embedding_sizes=self.embedding_sizes_cat_features\n",
    "        )\n",
    "        # Create a Lightning Module\n",
    "        lightningmodel = MulticlassTabularLightningModule(\n",
    "            n_classes=self.dm.n_classes,\n",
    "            model=model,\n",
    "            learning_rate=0.001,\n",
    "        )\n",
    "        # Create a Lightning Trainer\n",
    "        trainer = L.Trainer(\n",
    "            devices=\"auto\", # (os.cpu_count() / 2)\n",
    "            callbacks=[\n",
    "                PyTorchLightningPruningCallback(trial, monitor=\"val_loss\"),\n",
    "                # EarlyStopping(monitor='val_loss', min_delta=0.00, patience=5),\n",
    "            ],\n",
    "            # logger=CSVLogger(save_dir=\"logs/\", name=\"my-model\"),\n",
    "            max_epochs=2,\n",
    "            precision='bf16-mixed',\n",
    "            default_root_dir=\"lightning_logs/\",\n",
    "        )\n",
    "        # Create a Tuner\n",
    "        tuner = Tuner(trainer)\n",
    "        lr_finder = tuner.lr_find(lightningmodel, datamodule=self.dm) # finds learning rate automatically\n",
    "        new_lr = lr_finder.suggestion()\n",
    "        lightningmodel.learning_rate = new_lr # update hparams of the model\n",
    "        # Train the model\n",
    "        trainer.fit(\n",
    "            model=lightningmodel,\n",
    "            train_dataloaders=self.dm.train_dataloader(),\n",
    "            val_dataloaders=self.dm.val_dataloader()\n",
    "        )\n",
    "\n",
    "        # score = trainer.test(model=lightningmodel, dataloaders=self.dm.test_dataloader())\n",
    "        # score[0]['test_F1_macro_weighted']\n",
    "\n",
    "        return trainer.callback_metrics[\"val_F1_macro_weighted\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper-parameter space, model + training, optimization metric via Objective\n",
    "objective = OptunaObjective(\n",
    "    dm=TabularDataModuleClassificationPACKAGING(\n",
    "        data_dir=f\"{config['data_directory']}/output/df_ml.csv\",\n",
    "        continuous_cols=['material_weight'],\n",
    "        categorical_cols=[\n",
    "            'material_number',\n",
    "            'brand',\n",
    "            'product_area',\n",
    "            'core_segment',\n",
    "            'component',\n",
    "            'manufactoring_location',\n",
    "            'characteristic_value',\n",
    "            'packaging_code'\n",
    "        ],\n",
    "        target=['packaging_category'],\n",
    "        oversampling=True,\n",
    "        test_size=0.2,\n",
    "        val_size=0.2,\n",
    "        batch_size=64,\n",
    "        SEED=SEED\n",
    "    )\n",
    ")\n",
    "\n",
    "# define and run study for optimization\n",
    "storage_name = f\"sqlite:///{config['optuna_storage_directory']}/{empmlp_experiment_name}.db\"\n",
    "study = optuna.create_study(\n",
    "    study_name=empmlp_experiment_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "    pruner=optuna.pruners.MedianPruner()\n",
    ")\n",
    "\n",
    "# define duration of the optimization process by and/or number_of_trails and timeout\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=1,\n",
    "    # timeout=600,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print optimization results\n",
    "print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(\"  Performance: \", best_trial.value)\n",
    "print('  Best trial:', best_trial.params)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Optuna study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history of all trials\n",
    "hist = study.trials_dataframe()\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performance of all trials\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the parameter relationship concerning performance\n",
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots the interactive visualization of the high-dimensional parameter relationship\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots parameter interactive chart from we can choose which hyperparameter space has to explore\n",
    "optuna.visualization.plot_contour(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define best model\n",
    "\n",
    "best_params = best_trial.params\n",
    "\n",
    "# Evaluate best model on test data again\n",
    "def eval_best_model(best_params):\n",
    "    # datamodule\n",
    "    dm=TabularDataModuleClassificationPACKAGING(\n",
    "        data_dir=f\"{config['data_directory']}/output/df_ml.csv\",\n",
    "        continuous_cols=['material_weight'],\n",
    "        categorical_cols=[\n",
    "            'material_number',\n",
    "            'brand',\n",
    "            'product_area',\n",
    "            'core_segment',\n",
    "            'component',\n",
    "            'manufactoring_location',\n",
    "            'characteristic_value',\n",
    "            'packaging_code'\n",
    "        ],\n",
    "        target=['packaging_category'],\n",
    "        oversampling=True,\n",
    "        test_size=0.2,\n",
    "        val_size=0.2,\n",
    "        batch_size=best_params['batch_size'],\n",
    "        SEED=SEED\n",
    "    )\n",
    "    dm.prepare_data()\n",
    "    dm.setup(stage='fit')\n",
    "    # model\n",
    "    tabular_data_full = pd.concat([dm.train_dataset.get_dataframe, dm.val_dataset.get_dataframe, dm.test_dataset.get_dataframe], axis=0, ignore_index=True)\n",
    "    embedding_sizes_cat_features = tl_utils.get_cat_feature_embedding_sizes(tabular_data_full, categorical_cols=dm.categorical_cols)\n",
    "    best_model = MulticlassTabularCatEmbeddingMLP(\n",
    "            continuous_cols=dm.continuous_cols,\n",
    "            categorical_cols=dm.categorical_cols,\n",
    "            output_size=dm.n_classes,\n",
    "            hidden_size=best_params['hidden_size'],\n",
    "            n_hidden_layers=best_params['n_hidden_layers'],\n",
    "            dropout=best_params['dropout'],\n",
    "            norm=True,\n",
    "            embedding_sizes=embedding_sizes_cat_features\n",
    "        )\n",
    "    # lightningmodel\n",
    "    lightningmodel = MulticlassTabularLightningModule(\n",
    "        n_classes=dm.n_classes,\n",
    "        model=best_model,\n",
    "        learning_rate=0.001,\n",
    "    )\n",
    "    # trainer\n",
    "    trainer = L.Trainer(\n",
    "        devices=\"auto\", # (os.cpu_count() / 2)\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', min_delta=0.00, patience=5),\n",
    "        ],\n",
    "        logger=CSVLogger(save_dir=\"logs/\", name=\"MLP-Tuning\"),\n",
    "        max_epochs=3,\n",
    "        precision='bf16-mixed',\n",
    "        default_root_dir=\"lightning_logs/\",\n",
    "    )\n",
    "    # find learning rate\n",
    "    tuner = Tuner(trainer)\n",
    "    lr_finder = tuner.lr_find(lightningmodel, datamodule=dm) # finds learning rate automatically\n",
    "    new_lr = lr_finder.suggestion()\n",
    "    lightningmodel.learning_rate = new_lr # update hparams of the model\n",
    "    # train model\n",
    "    trainer.fit(\n",
    "        model=lightningmodel,\n",
    "        train_dataloaders=dm.train_dataloader(),\n",
    "        val_dataloaders=dm.val_dataloader()\n",
    "    )\n",
    "    # evaluate model on test data\n",
    "    score = trainer.test(model=lightningmodel, dataloaders=dm.test_dataloader())\n",
    "    print(f\"test_F1_macro_weighted: {score[0]['test_F1_macro_weighted']}\")\n",
    "    # make predictions on test data and evaluate\n",
    "    preds_y_test = torch.cat(trainer.predict(model=lightningmodel, dataloaders=dm.test_dataloader()))\n",
    "    preds_y_test = dm.label_encoder_target.inverse_transform(preds_y_test.reshape(-1, 1))\n",
    "    y_test = dm.label_encoder_target.inverse_transform(dm.test_dataset.get_dataframe.iloc[:, -1].values.reshape(-1, 1))\n",
    "    # calculate classification report\n",
    "    print(classification_report(y_test, preds_y_test))\n",
    "\n",
    "eval_best_model(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ml_packaging_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
