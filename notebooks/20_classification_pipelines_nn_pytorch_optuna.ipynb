{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERAL THOUGHTS:**\n",
    "- How to handle SKUs with mulitple components? Does it make more sense to combine them into a single row? -> might want to try this as a next step\n",
    "\n",
    "\n",
    "**DATA PREPROCESSING:**\n",
    "\n",
    "Imbalanced data:\n",
    "- over_sampling for imbalanced data\n",
    "- cost-sensitive learning for imbalanced data\n",
    "\n",
    "categorical data:\n",
    "- Ordinal Data: The categories have an inherent order\n",
    "- Nominal Data: The categories do not have an inherent order\n",
    "\n",
    "Options:\n",
    "- nominal encode 'material_number'\n",
    "- nominal encode 'material_number_text'\n",
    "- nominal encode 'brand'\n",
    "- nominal encode 'product_area'\n",
    "- ...\n",
    "\n",
    "\n",
    "**MULTI-CLASS CLASSIFIER:**\n",
    "- Focus on \"Native Multiclass Classifiers\" as a starting point. Might try \"Binary Transformation\" or \"Hierarchical Classification\" later. https://www.projectpro.io/article/multi-class-classification-python-example/547\n",
    "- Overview models to be considered:  \n",
    "X: to be considered\n",
    "  - [ ] Naive Bayes \n",
    "  - [ ] Decision Trees\n",
    "  - [X] K-Nearest Neighbors\n",
    "  - [X] Ensemble Models (~~Random Forest~~, XGBoost)\n",
    "  - [] Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import xgboost as xgb\n",
    "# import lightgbm as lgbm\n",
    "\n",
    "# import imblearn\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Iterable, List, Optional, Tuple, Union, Literal\n",
    "\n",
    "import lightning as L\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data using Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: Class to create custom dataset to follow PyTorch Lightning conventions eventhough we are working on tabular data,\n",
    "# #       where the data for feature variables and the target variable are often already provided in a combined way (e.g. contrary to images and corresbonding labels).\n",
    "# class TabularDatasetPACKAGING(Dataset):\n",
    "#     def __init__(self, data_dir: str = None, transform=None):\n",
    "#         \"\"\"\n",
    "#         This class is customized to the 'PACKAGING' use case and the related data.\n",
    "#         Dataset to load Tabular Data as a Pandas DataFrame from a .csv file.\n",
    "#         Loads the data as a Pandas DataFrame and performs custom data processing\n",
    "#         related to loading a .csv file (data type correction) and defining a subset of features.\n",
    "#         NOTE: In addition, the original intention of using a Torch Dataset Class, is to provide the output of the data\n",
    "#         as tensors for further use of pytorch and to enable tensor operations. For our (and most) tabular datasets we neglect this aspect,\n",
    "#         since we want to do the data transformations, which are not tensor based, within L.LightningDataModule.\n",
    "\n",
    "#         Args:\n",
    "#             data_dir: Path to the .csv file to be loaded as a Pandas DataFrame.\n",
    "#         Returns:\n",
    "#             dataset: Pandas Dataframe\n",
    "#         \"\"\"\n",
    "#         self.data_dir = data_dir\n",
    "#         self.transform = transform\n",
    "\n",
    "#         self.data = pd.read_csv(self.data_dir, sep='\\t')\n",
    "\n",
    "#         # for inference mode, as the target might not be provided in the data,\n",
    "#         # ensures pre-processing pipeline completes correctly.\n",
    "#         if 'packaging_category' not in self.data.columns:\n",
    "#             # Insert an empty column at the end (position=-1)\n",
    "#             self.data.insert(len(self.data.columns), 'packaging_category', np.nan)\n",
    "\n",
    "#         # select a subset\n",
    "#         self.data = self.data[[\n",
    "#             'material_number',\n",
    "#             'brand',\n",
    "#             'product_area',\n",
    "#             'core_segment',\n",
    "#             'component',\n",
    "#             'manufactoring_location',\n",
    "#             'characteristic_value',\n",
    "#             'material_weight', \n",
    "#             'packaging_code',\n",
    "#             'packaging_category',\n",
    "#         ]]\n",
    "\n",
    "#         self.data['material_number'] = self.data['material_number'].astype('object')\n",
    "\n",
    "#         self.n_samples = self.data.shape[0]\n",
    "\n",
    "\n",
    "#     @property\n",
    "#     def get_dataframe(self):\n",
    "#         \"\"\"Returns the data as a pandas dataframe.\"\"\"\n",
    "#         return self.data\n",
    "\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         \"\"\"\n",
    "#         Generates one single sample of data of the dataset (row)\n",
    "#         and applies transformations to that sample if defined.\n",
    "#         Called iteratively based on batches and batch_size.\n",
    "#         \"\"\"\n",
    "#         sample = self.data[idx]\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             sample = self.transform(sample)\n",
    "\n",
    "#         return sample\n",
    "    \n",
    "    \n",
    "#     def __len__(self):\n",
    "#         \"\"\"Denotes the total number of samples.\"\"\"\n",
    "#         return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets, DataLoaders & LightningDataModule\n",
    "- Logic of using `Datasets`, `DataLoaders` & `LightningDataModule` for **Tabular Data**  \n",
    "    Since we are using tabular data and want to perform non tensor based processing to our date, we use Datasets, DataLoaders & LightningDataModule in a different manner as we would do when applying tensor operations (incl. tensor based preprpcessing) only.  \n",
    "    - `LightningDataModule` \n",
    "        Our LightningDataModule builds the wrapper around this process, with the following intensions:\n",
    "        - `def prepare_data`  \n",
    "        Data Operations that only should be performed once on the data (and should not be performed on a distributed manner). Prepares the data for data pre-processing e.g. using sklearn.  \n",
    "            - Loading the data from .csv to pd.DataFrame\n",
    "            - General dataset preperations like feature selection and data type correction\n",
    "        - `def setup`  \n",
    "        First, data operations (like shuffle, split data, categorical encoding, normalization, etc.), which any dataframe should undergo before feeding into the dataloader will be performed here. Since we use sklearn functionalities for our tabular pre-processing pipeline the data input and output of the pre-processing is a tabular format (dataframe) and not a tensor format.\n",
    "        Second, the outcome of `def setup` are `Dataset` objects for each split (e.g. train, val, test, pred), which is a wrapper around the pre-processed tabular data and provides the samples and their corresponding labels (ideally in tensor format) in a specific way to be compatible for the model(s).\n",
    "            - `Dataset`  \n",
    "            Dataset provides the samples and their corresponding labels in a specific way to be compatible for the model(s). We define the input for our tabular use case as a DataFrame, while the output should generally be a tensor. In our case the output is a tuple of a flattern tensor representing all features and a tensor for the target variable (label). This aligns with the input if a simple MLP model. For more complex models, e.g. that handle continous and categorical variables differently, this should be adapted.  \n",
    "            The class performs specific data type correction for to use of Neural Networks (e.g. ensure that all outputs are numeric values of the correct type depeding of they are categorical or continous nature).\n",
    "        - `def train/val/test/prediction_dataloader`  \n",
    "        Creates our dataloaders within the LightningDataModule. See usage below.\n",
    "            - `DataLoader` \n",
    "            DataLoader wraps an iterable around the Dataset to enable easy access to the samples during training and inference. The Dataset defines the format of the data that is passed to our model. The DataLoader retrieves our dataset’s features and labels. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval, which is handled by the DataLoader. Input and output is a tensor. https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "- Excorsion: Classical approach of using `Datasets`, `DataLoaders` & `LightningDataModule` for e.g. images, ...  \n",
    "The main difference is the usage of tensors instead of a dataframe for efficent GPU usage.\n",
    "    - `LightningDataModule` \n",
    "        Our LightningDataModule builds the wrapper around this process. It encapsulates training, validation, testing, and prediction dataloaders, as well as any necessary steps for data processing, downloads, and transformations. https://lightning.ai/docs/pytorch/stable/data/datamodule.html\n",
    "        - `def prepare_data`  \n",
    "        Loads the data and does general processing befor transfomring to a tensor, so efficent tensor operations can be enabled in `setup'.\n",
    "        - `def setup`  \n",
    "        Efficent tensor operations (like shuffle, split data, categorical encoding, normalization, etc.), which any dataframe should undergo before feeding into the dataloader.\n",
    "        - `def train/val/test_dataloader`  \n",
    "        Creates our dataloaders within the LightningDataModule.\n",
    "    - `Dataset`\n",
    "    Class to create tabular dataset to follow PyTorch Lightning conventions (eventhough we are working on tabular data), where the data for feature variables and the target variable are often already provided in a combined way (e.g. contrary to images and corresbonding labels). For \"classical\" approaches a Dataset class is often used at the start of the machine learning pipeline to provide the data in a format (e.g. combine images and corresponding labels, which are typically not provided in the same file) for further processing and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            data: pd.DataFrame = None,\n",
    "            continuous_cols: List[str] = None,\n",
    "            categorical_cols: List[str] = None,\n",
    "            target: List[str] = None,\n",
    "            task: Literal['classification', 'regression'] = 'classification',\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This class is customized for tabular related data for the use of classification and regression. Returns the tabular data as tensor format.\n",
    "        Input data must be of numeric nature and should be ordinal or label encoded. This should be covered by a related LightningDataModule.\n",
    "        Besides the standard functionality of the 'Dataset' class it provides data type correction to fit the requirements of Neural Networks and for efficent use of Neural Networks.\n",
    "        NOTE: The original intention of using a Torch Dataset Class, is to provide the output of the data as tensors for further use of pytorch\n",
    "        and to enable tensor operations. For our (and most) tabular datasets we neglect the aspect of tensor operations, since we do the data transformations (e.g. using sklearn),\n",
    "        which are not tensor based, within L.LightningDataModule. The TabularDataset class is used to provide the data as tensors to the DataLoaders as a final step after data prepressing.\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): Pandas DataFrame to load during training.\n",
    "            continuous_cols (List[str], optional): A list of names of continuous columns.\n",
    "            categorical_cols (List[str], optional): A list of names of categorical columns. These columns must be ordinal or label encoded beforehand.\n",
    "            target (List[str], optional): A list of strings with target column name(s).\n",
    "            task (str, optional): Whether it is a classification or regression task. If classification, it returns a LongTensor as target.\n",
    "        Returns:\n",
    "            Corrected tabular data as tensor format.\n",
    "        \"\"\"\n",
    "        # self.data = data\n",
    "        self.task = task\n",
    "        self.n_samples = data.shape[0]\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.continuous_cols = continuous_cols\n",
    "        self.target = target\n",
    "\n",
    "        # NOTE: input data must be ordinal or label encoded\n",
    "\n",
    "        # target handling\n",
    "        if self.target:\n",
    "            self.y = data[self.target].astype(np.float32).values # for regression task\n",
    "            if self.task == \"classification\":\n",
    "                self.y = self.y.reshape(-1, 1).astype(np.int64) # for classification task\n",
    "        else:\n",
    "            self.y = np.zeros((self.n_samples, 1))  # for regression task\n",
    "            if self.task == \"classification\":\n",
    "                self.y = self.y.astype(np.int64) # for classification task\n",
    "        \n",
    "        # feature handling\n",
    "        self.categorical_cols = self.categorical_cols if self.categorical_cols else []\n",
    "        self.continuous_cols = self.continuous_cols if self.continuous_cols else []\n",
    "        if self.continuous_cols:\n",
    "            self.continuous_X = data[self.continuous_cols].astype(np.float32).values\n",
    "        if self.categorical_cols:\n",
    "            self.categorical_X = data[self.categorical_cols]\n",
    "            self.categorical_X = self.categorical_X.astype(np.int64).values\n",
    "\n",
    "\n",
    "    @property\n",
    "    def get_dataframe(self):\n",
    "        \"\"\"Creates and returns the dataset as a pandas dataframe.\"\"\"\n",
    "        if self.continuous_cols or self.categorical_cols:\n",
    "            df = pd.DataFrame(\n",
    "                np.concatenate([self.categorical_X, self.continuous_X], axis=1),\n",
    "                columns=self.categorical_cols + self.continuous_cols,\n",
    "            )\n",
    "        else:\n",
    "            df = pd.DataFrame()\n",
    "        df[self.target] = self.y # add target column\n",
    "\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Dict[str, torch.Tensor], torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Generates one single sample of data of the dataset (row)\n",
    "        and applies transformations to that sample if defined.\n",
    "        Called iteratively based on batches and batch_size.\n",
    "        Args:\n",
    "            idx (int): index (between ``0`` and ``len(dataset) - 1``)\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Dict[str, torch.Tensor], torch.Tensor]: x and y for model\n",
    "        \"\"\"\n",
    "\n",
    "        # return {\n",
    "        #     \"features\": (torch.Tensor(np.concatenate([self.categorical_X[idx], self.continuous_X[idx]], axis=1)) if (self.continuous_cols or self.categorical_cols) else torch.Tensor()),\n",
    "        #     \"target\": torch.Tensor(self.target[idx])\n",
    "        # }\n",
    "        return {\n",
    "            \"continuous\": (torch.Tensor(self.continuous_X[idx]) if self.continuous_cols else torch.Tensor()),\n",
    "            \"categorical\": (torch.Tensor(self.categorical_X[idx]) if self.categorical_cols else torch.Tensor()),\n",
    "            \"target\": torch.Tensor(self.target[idx])\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process Data using DataLoader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataModuleClassificationPACKAGING(L.LightningDataModule):\n",
    "    \"\"\"\n",
    "    The class processes the data accordingly, so that the output meets the requirments to be further used by PyTorch/Lightning.\n",
    "    A shareble, reusable class that encapsulates data loading and data preprocessing logic for classification.\n",
    "    The class provides general data handeling and very specific data handeling to the 'Packaging Dataset' ('number` and 'object' types as variables are supported, but no other e.g. like 'date').\n",
    "    NOTE: In addition, the original intention of using a L.LightningDataModule is to performe data operations on tensors to improve compute performance. For our (and most) tabular datasets we neglect this aspect,\n",
    "    since we perform data transformations, which are not tensor based. Therefore data preprocessing and transformations are organized within the class methods 'prepare_data' and 'setup',\n",
    "    based on if they should be performed a single time only or multiple times.\n",
    "    NOTE: Be aware of the status of your transformers (data they are fit on) - performance optimization vs. final evaluation vs. inference only.\n",
    "\n",
    "    Args:\n",
    "        L (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        continuous_cols: List[str] = None,\n",
    "        categorical_cols: List[str] = None,\n",
    "        target: List[str] = None,\n",
    "        task: Literal['classification', 'regression'] = 'classification',\n",
    "        batch_size: int = 64,\n",
    "        batch_size_inference: Optional[int] = None,\n",
    "        SEED: Optional[int] = 42\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.categorical_cols = categorical_cols if categorical_cols else []\n",
    "        self.continuous_cols = continuous_cols if continuous_cols else []\n",
    "        self.task = task\n",
    "        self.target = target\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_inference = self.batch_size if not batch_size_inference else batch_size_inference\n",
    "        self.SEED = SEED\n",
    "\n",
    "        self._prepare_data_called = False\n",
    "        # self._setup_called = False\n",
    "\n",
    "    def _prepare_data(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Performs general, use case independent data input handeling and data type handling.\n",
    "        Used internal in 'prepare_data' for train, val and test dataloaders and in 'inference_dataloader' for prediction.\n",
    "        Target specific handelings are performed in 'perpare_data' to avoid conflicts during inference only scenarios where the target is not available.\n",
    "        General data preparation involves:\n",
    "            - transform target variable to data type 'object' for classificatiomn tasks and to data type 'float32' for regression tasks.\n",
    "            - transform continuous feature variables to data type 'np.float32'.\n",
    "            - transform categorical feature variables to data type 'object'.\n",
    "            - update the processed dataframe accordingly and drops not specified columns.\n",
    "        \"\"\"\n",
    "        if self.task == 'classification':\n",
    "            # transform target variable to data type 'object'\n",
    "            data[self.target] = data[self.target].astype('object').values\n",
    "        elif self.task == 'regression':\n",
    "            # transform target variable to data type 'float32'\n",
    "            data[self.target] = data[self.target].astype(np.float32).values\n",
    "\n",
    "        if len(self.continuous_cols) > 0:\n",
    "            # continuous_cols will be transfomred to float32 ('32' for performance reasons) since NNs do not handle int properly.\n",
    "            data[self.continuous_cols] = data[self.continuous_cols].astype(np.float32).values\n",
    "        if len(self.categorical_cols) > 0:\n",
    "            # ensure that all categorical variables are of type 'object'\n",
    "            data[self.categorical_cols] = data[self.categorical_cols].astype('object').values\n",
    "            \n",
    "        if (len(self.continuous_cols) > 0) or (len(self.categorical_cols) > 0):\n",
    "            # self.feature_cols = self.continuous_cols + self.categorical_cols\n",
    "            pass\n",
    "        else:\n",
    "            raise TypeError(\"Missing required argument: 'continuous_cols' and/or 'categorical_cols'\")\n",
    "        \n",
    "        # Define a subset based on continuous_cols and categorical_cols\n",
    "        data = data[self.continuous_cols + self.categorical_cols + self.target]\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def _preprocessing_pipeline(self, X: pd.DataFrame = None, y: pd.DataFrame = None, stage: str = 'fit') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        PREPROCESSING PIPELINE\n",
    "        Used internal in 'setup' for train, val and test dataloaders and in 'inference_dataloader',\n",
    "        as well as for inverse transformations.\n",
    "        NOTE: TabularDatasetPACKAGING prepares data for prediction only accordingly to support _preprocessing_pipeline.\n",
    "        \"\"\"\n",
    "        \n",
    "        # create pipeline for fit scenario, use existing pipeline for inference scenario\n",
    "        if stage == 'fit':\n",
    "            # numerical feature processing\n",
    "            numerical_features = X.select_dtypes(include='number').columns.tolist()\n",
    "            numeric_feature_pipeline = Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='median')),\n",
    "                ('scale', StandardScaler())\n",
    "            ])\n",
    "            # categorical feature processing\n",
    "            categorical_features = X.select_dtypes(exclude='number').columns.tolist()\n",
    "            categorical_feature_pipeline = Pipeline(steps=[\n",
    "                ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "                # ('label', LabelEncoder()),\n",
    "                ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)), # ordinal is used instead of label encoder to avoid conflicts with inference or \n",
    "                #conflicts caused by data splits of categories with low numerber of classesonly scenarios\n",
    "                # ('one_hot', OneHotEncoder(handle_unknown='ignore', max_categories=None, sparse_output=False))\n",
    "            ])\n",
    "            # apply both pipeline on seperate columns using \"ColumnTransformer\"\n",
    "            self.preprocess_pipeline = ColumnTransformer(transformers=[\n",
    "                ('number', numeric_feature_pipeline, numerical_features),\n",
    "                ('category', categorical_feature_pipeline, categorical_features)],\n",
    "                verbose_feature_names_out=False)\n",
    "            self.preprocess_pipeline.set_output(transform=\"pandas\")\n",
    "\n",
    "            # ordinal is used instead of label encoder to avoid conflicts with inference or \n",
    "            # conflicts caused by data splits of categories with low numerber of classesonly scenarios\n",
    "            self.label_encoder_target = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1) \n",
    "            # self.label_encoder_target = LabelEncoder()\n",
    "        \n",
    "        if stage == 'fit':\n",
    "            X_transformed = self.preprocess_pipeline.fit_transform(X)\n",
    "            y_transformed = pd.DataFrame(data=self.label_encoder_target.fit_transform(y.values.reshape(-1, 1)), index=y.index, columns=y.columns)\n",
    "        elif stage == 'inference':\n",
    "            X_transformed = self.preprocess_pipeline.transform(X)\n",
    "            y_transformed = pd.DataFrame(data=self.label_encoder_target.transform(y.values.reshape(-1, 1)), index=y.index, columns=y.columns)\n",
    "        else:\n",
    "            raise TypeError(\"Missing required argument 'stage', must be 'fit' or 'inference'\")\n",
    "        \n",
    "        return pd.concat([X_transformed, y_transformed], axis=1)\n",
    "    \n",
    "\n",
    "    def prepare_data(self, shuffle: bool = False):\n",
    "        \"\"\" Custom data specific operations and basic tabular specific operations that only should be performed once on the data (and should not be performed on a distributed manner).\n",
    "        Load the data as Tabular Data as a Pandas DataFrame from a .csv file and performs custom data processing related to loading a .csv file (data type correction) and defining a subset of features.\n",
    "        In addition \"_prepare_data\" performace general data preparation for the classification/regression task and perform basic data error handeling. General data preparation involves:\n",
    "            - transform target variable to data type 'object'.\n",
    "            - update the processed dataframe accordingly and drops not specified columns.\n",
    "            - shuffle the data (rows).\n",
    "        \"\"\"\n",
    "\n",
    "        # USE CASE SPECIFIC DATA HANDLING\n",
    "        self.data = pd.read_csv(self.data_dir, sep='\\t')\n",
    "        # for inference mode, as the target might not be provided in the data,\n",
    "        # ensures pre-processing pipeline completes correctly.\n",
    "        if 'packaging_category' not in self.data.columns:\n",
    "            # Insert an empty column at the end (position=-1)\n",
    "            self.data.insert(len(self.data.columns), 'packaging_category', np.nan)\n",
    "        # select a subset\n",
    "        self.data = self.data[[\n",
    "            'material_number',\n",
    "            'brand',\n",
    "            'product_area',\n",
    "            'core_segment',\n",
    "            'component',\n",
    "            'manufactoring_location',\n",
    "            'characteristic_value',\n",
    "            'material_weight', \n",
    "            'packaging_code',\n",
    "            'packaging_category',\n",
    "        ]]\n",
    "        self.data['material_number'] = self.data['material_number'].astype('object')\n",
    "\n",
    "        # GENERAL DATA HANDLING\n",
    "        self.data = self._prepare_data(self.data)\n",
    "\n",
    "        # shuffle data\n",
    "        if shuffle is True: self.data = self.data.sample(frac=1)\n",
    "\n",
    "        self.n_samples = self.data.shape[0]\n",
    "\n",
    "        self._prepare_data_called = True\n",
    "\n",
    "    \n",
    "    def setup(\n",
    "        self,\n",
    "        test_size: Optional[float] = None,\n",
    "        val_size: Optional[float] = None,\n",
    "        stage_setup: str = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Data Operations (like shuffle, split data, categorical encoding, normalization, etc.) that will be performed multiple times (on each single GPU indipendently), which any dataframe should undergo before feeding into the dataloader.\n",
    "        Since on tabular data, operations like transformations (categorical encoding, normalization, etc.) needs to be performed with respect to all samples (respectively separat per train, val, test split),\n",
    "        most operations are not performed in DDP way. See class docstring for further details regarding tabular data and tensor transformations.\n",
    "\n",
    "        Args:\n",
    "            test_size (Optional[float], optional):\n",
    "                Defines the hold out split that should be used for final performance evaluation. If 'None' no split will be performed and all data is used in 'fit'\n",
    "            val_size (Optional[float], optional):\n",
    "                Defines an additional split on the train data that should be used for model optimization. If 'None' no val split will be performed and all train data is used in 'fit'\n",
    "            stage (Optional[str], optional):\n",
    "                Internal parameter to distinguish between 'fit' and 'inference'. Defaults to None.\n",
    "\n",
    "        TODO: check interaction of 'stage_setup' with Lightning Module inherent use of 'stage'.\n",
    "        \"\"\"\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "\n",
    "        if not self._prepare_data_called:\n",
    "            raise RuntimeError(\"'prepare_data' needs to be called before 'setup'\")\n",
    "\n",
    "        # Define features and target\n",
    "        X = self.data.iloc[:, :-1]\n",
    "        y = self.data.iloc[:, -1]  # the last column is the target, ensured by calling 'prepare_data' upfront\n",
    "\n",
    "        if stage_setup == 'fit':\n",
    "            # Generate train, val and test data splits\n",
    "            if self.test_size is not None:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, test_size=self.test_size, stratify=y, random_state=self.SEED\n",
    "                )\n",
    "                X_train = pd.DataFrame(data=X_train, columns=X.columns)\n",
    "                y_train = pd.DataFrame(data=y_train, columns=[y.name])\n",
    "                X_test = pd.DataFrame(data=X_test, columns=X.columns)\n",
    "                y_test = pd.DataFrame(data=y_test, columns=[y.name])\n",
    "                if (self.val_size is not None) and (self.test_size is not None):\n",
    "                    X_train, X_val, y_train, y_val = train_test_split(\n",
    "                        X_train, y_train, test_size=self.val_size, stratify=y_train, random_state=self.SEED\n",
    "                    )\n",
    "                    X_train = pd.DataFrame(data=X_train, columns=X.columns)\n",
    "                    y_train = pd.DataFrame(data=y_train, columns=[y.name])\n",
    "                    X_val = pd.DataFrame(data=X_val, columns=X.columns)\n",
    "                    y_val = pd.DataFrame(data=y_val, columns=[y.name])\n",
    "            else:\n",
    "                X_train = X\n",
    "                y_train = y\n",
    "        elif stage_setup == 'inference':\n",
    "            X_pred = X\n",
    "            y_pred = y\n",
    "        else:\n",
    "            raise TypeError(\"Missing required argument 'stage_setup', must be 'fit' or 'inference'\")\n",
    "\n",
    "        # pre-process data\n",
    "        if stage_setup == 'fit':\n",
    "            tabular_train = self._preprocessing_pipeline(X_train, y_train, stage='fit')\n",
    "            if self.test_size is not None:\n",
    "                tabular_test = self._preprocessing_pipeline(X_test, y_test, stage='inference')\n",
    "            if (self.val_size is not None) and (self.test_size is not None):\n",
    "                tabular_val = self._preprocessing_pipeline(X_val, y_val, stage='inference')\n",
    "        elif stage_setup == 'inference':\n",
    "            tabular_predict = self._preprocessing_pipeline(X_pred, y_pred, stage='inference')\n",
    "\n",
    "        # create datasets\n",
    "        if stage_setup == 'fit':\n",
    "            self.train_dataset = TabularDataset(\n",
    "                    data=tabular_train,\n",
    "                    continuous_cols=self.continuous_cols,\n",
    "                    categorical_cols=self.categorical_cols,\n",
    "                    target=self.target,\n",
    "                    task='classification'\n",
    "                )\n",
    "            if self.test_size is not None:\n",
    "                self.test_dataset = TabularDataset(\n",
    "                    data=tabular_test,\n",
    "                    continuous_cols=self.continuous_cols,\n",
    "                    categorical_cols=self.categorical_cols,\n",
    "                    target=self.target,\n",
    "                    task='classification'\n",
    "                )\n",
    "            if (self.val_size is not None) and (self.test_size is not None):\n",
    "                self.val_dataset = TabularDataset(\n",
    "                    data=tabular_val,\n",
    "                    continuous_cols=self.continuous_cols,\n",
    "                    categorical_cols=self.categorical_cols,\n",
    "                    target=self.target,\n",
    "                    task='classification'\n",
    "                )\n",
    "        elif stage_setup == 'inference':\n",
    "            self.predict_dataset = TabularDataset(\n",
    "                data=tabular_predict,\n",
    "                continuous_cols=self.continuous_cols,\n",
    "                categorical_cols=self.categorical_cols,\n",
    "                target=self.target,\n",
    "                task='classification'\n",
    "            )\n",
    "    \n",
    "        # self._setup_called = True\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Dataloader that the Trainer fit() method uses.\n",
    "        Args:\n",
    "            batch_size (Optional[int], optional): Batch size. Defaults to `self.batch_size`.\n",
    "        Returns:\n",
    "            DataLoader: Train dataloader\n",
    "        \"\"\"\n",
    "        # if not self._setup_called:\n",
    "        #     raise RuntimeError(\"'setup' needs to be called before 'train_dataloader'\")\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Dataloader that the Trainer fit() and validate() methods uses.\n",
    "        Args:\n",
    "            batch_size (Optional[int], optional): Batch size. Defaults to `self.batch_size`.\n",
    "        Returns:\n",
    "            DataLoader: Validation dataloader\n",
    "        \"\"\"\n",
    "        # if not self._setup_called:\n",
    "        #     raise RuntimeError(\"'setup' needs to be called before 'val_dataloader'\")\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Dataloader that the Trainer test() method uses.\n",
    "        \"\"\"\n",
    "        # if not self._setup_called:\n",
    "        #     raise RuntimeError(\"'setup' needs to be called before 'test_dataloader'\")\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    # if self.stage == 'inference':\n",
    "        # def predict_dataloader(self) -> DataLoader:\n",
    "        #     \"\"\"Dataloader that the Trainer predict() method uses.\n",
    "        #     Used for predictions for data with unknow target (labes) by performing the following:\n",
    "        #     - creates TabularDatasetPACKAGING dataset from csv file. TabularDatasetPACKAGING prepares data for prediction only accordingly to support _preprocessing_pipeline.\n",
    "        #     - _prepare_data\n",
    "        #     - _preprocessing_pipeline\n",
    "        #     \"\"\"\n",
    "        #     return DataLoader(self.predict_dataset, batch_size=self.batch_size_inference, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TabularDataModuleClassificationPACKAGING(\n",
    "    data_dir='../../data/output/df_ml.csv',\n",
    "    continuous_cols=['material_weight'],\n",
    "    categorical_cols=[\n",
    "        'material_number',\n",
    "        'brand',\n",
    "        'product_area',\n",
    "        'core_segment',\n",
    "        'component',\n",
    "        'manufactoring_location',\n",
    "        'characteristic_value',\n",
    "        'packaging_code'\n",
    "    ],\n",
    "    target=['packaging_category'],\n",
    "    batch_size=64,\n",
    "    SEED=SEED # Ensure same data split as in other notebooks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82977 entries, 0 to 82976\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   material_weight         75913 non-null  float32\n",
      " 1   material_number         82977 non-null  object \n",
      " 2   brand                   82977 non-null  object \n",
      " 3   product_area            82977 non-null  object \n",
      " 4   core_segment            82977 non-null  object \n",
      " 5   component               82977 non-null  object \n",
      " 6   manufactoring_location  82977 non-null  object \n",
      " 7   characteristic_value    82977 non-null  object \n",
      " 8   packaging_code          82977 non-null  object \n",
      " 9   packaging_category      82977 non-null  object \n",
      "dtypes: float32(1), object(9)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dm.prepare_data()\n",
    "dm.data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(test_size=0.2, val_size=0.2, stage_setup='fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x147350210>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"train_dataloader: {type(dm.train_dataloader())}\")\n",
    "dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[6], line 96\u001b[0m, in \u001b[0;36mTabularDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03mGenerates one single sample of data of the dataset (row)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03mand applies transformations to that sample if defined.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Tuple[Dict[str, torch.Tensor], torch.Tensor]: x and y for model\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# return {\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#     \"features\": (torch.Tensor(np.concatenate([self.categorical_X[idx], self.continuous_X[idx]], axis=1)) if (self.continuous_cols or self.categorical_cols) else torch.Tensor()),\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m#     \"target\": torch.Tensor(self.target[idx])\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m: (torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous_X[idx]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous_cols \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor()),\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m: (torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_X[idx]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_cols \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor()),\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     97\u001b[0m }\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# TODO: how to access the dict of the dataloader correctly?\n",
    "# check correctness of DataModule\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(dm.train_dataloader()):\n",
    "        if batch_idx >= 3:\n",
    "            break\n",
    "        print(\" Batch index:\", batch_idx, end=\"\")\n",
    "        print(\" | Batch size:\", y.shape[0], end=\"\")\n",
    "        print(\" | x shape:\", x.shape, end=\"\")\n",
    "        print(\" | y shape:\", y.shape)\n",
    "\n",
    "print(\"Labels from current batch:\", y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN without HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchMulticlassMLP(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.all_layers = torch.nn.Sequential(\n",
    "            # 1st hidden layer\n",
    "            torch.nn.Linear(num_features, 50),\n",
    "            torch.nn.ReLU(),\n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(50, 25),\n",
    "            torch.nn.ReLU(),\n",
    "            # output layer\n",
    "            torch.nn.Linear(25, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.flatten(x, start_dim=1)\n",
    "        logits = self.all_layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _shared_step(self, batch):\n",
    "        '''Shared functionalities for train_step, val_step and test_step'''\n",
    "        features, true_labels = batch\n",
    "        logits = self(features)\n",
    "\n",
    "        loss = F.cross_entropy(logits, true_labels)\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        return loss, true_labels, predicted_labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.train_acc(predicted_labels, true_labels)\n",
    "        self.log(\"train_acc\", self.train_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.val_acc(predicted_labels, true_labels)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        self.test_acc(predicted_labels, true_labels)\n",
    "        self.log(\"test_acc\", self.test_acc)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_1 (Dense)            (None, 100)               1000      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 29)                2929      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,329\n",
      "Trainable params: 24,729\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "4149/4149 [==============================] - 7s 2ms/step - loss: 3.2745 - accuracy: 0.0645 - val_loss: 6.2862 - val_accuracy: 0.0962\n",
      "Epoch 2/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 3.0788 - accuracy: 0.0718 - val_loss: 6.4312 - val_accuracy: 0.0539\n",
      "Epoch 3/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 3.0079 - accuracy: 0.0752 - val_loss: 7.1112 - val_accuracy: 0.1002\n",
      "Epoch 4/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 3.0048 - accuracy: 0.0842 - val_loss: 5.3015 - val_accuracy: 0.0951\n",
      "Epoch 5/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.9599 - accuracy: 0.0832 - val_loss: 7.1750 - val_accuracy: 0.0790\n",
      "Epoch 6/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.9023 - accuracy: 0.0834 - val_loss: 8.4877 - val_accuracy: 0.0915\n",
      "Epoch 7/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.8602 - accuracy: 0.0935 - val_loss: 8.5961 - val_accuracy: 0.1010\n",
      "Epoch 8/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.8520 - accuracy: 0.0965 - val_loss: 7.8088 - val_accuracy: 0.0884\n",
      "Epoch 9/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.8638 - accuracy: 0.0966 - val_loss: 12.5667 - val_accuracy: 0.1099\n",
      "Epoch 10/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.8170 - accuracy: 0.0979 - val_loss: 9.3132 - val_accuracy: 0.0785\n",
      "Epoch 11/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.8431 - accuracy: 0.1004 - val_loss: 14.0262 - val_accuracy: 0.1136\n",
      "Epoch 12/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.8087 - accuracy: 0.1037 - val_loss: 11.1353 - val_accuracy: 0.1182\n",
      "Epoch 13/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7920 - accuracy: 0.1021 - val_loss: 10.7481 - val_accuracy: 0.0917\n",
      "Epoch 14/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7646 - accuracy: 0.1008 - val_loss: 11.1427 - val_accuracy: 0.1161\n",
      "Epoch 15/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7378 - accuracy: 0.1073 - val_loss: 16.7542 - val_accuracy: 0.1293\n",
      "Epoch 16/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7706 - accuracy: 0.1105 - val_loss: 13.1294 - val_accuracy: 0.1417\n",
      "Epoch 17/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7410 - accuracy: 0.1098 - val_loss: 10.6703 - val_accuracy: 0.1267\n",
      "Epoch 18/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7463 - accuracy: 0.1131 - val_loss: 12.1383 - val_accuracy: 0.1328\n",
      "Epoch 19/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7450 - accuracy: 0.1120 - val_loss: 17.1507 - val_accuracy: 0.1577\n",
      "Epoch 20/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7225 - accuracy: 0.1153 - val_loss: 15.2237 - val_accuracy: 0.1031\n",
      "Epoch 21/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7230 - accuracy: 0.1096 - val_loss: 13.8221 - val_accuracy: 0.1144\n",
      "Epoch 22/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7454 - accuracy: 0.1103 - val_loss: 13.7920 - val_accuracy: 0.1338\n",
      "Epoch 23/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7157 - accuracy: 0.1174 - val_loss: 20.1862 - val_accuracy: 0.1146\n",
      "Epoch 24/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7180 - accuracy: 0.1119 - val_loss: 15.5201 - val_accuracy: 0.1299\n",
      "Epoch 25/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6914 - accuracy: 0.1169 - val_loss: 11.3901 - val_accuracy: 0.1064\n",
      "Epoch 26/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7259 - accuracy: 0.1136 - val_loss: 23.9361 - val_accuracy: 0.1267\n",
      "Epoch 27/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7253 - accuracy: 0.1122 - val_loss: 45.1577 - val_accuracy: 0.1070\n",
      "Epoch 28/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7548 - accuracy: 0.1114 - val_loss: 16.3823 - val_accuracy: 0.1600\n",
      "Epoch 29/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7187 - accuracy: 0.1144 - val_loss: 16.8182 - val_accuracy: 0.1285\n",
      "Epoch 30/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6964 - accuracy: 0.1185 - val_loss: 19.1584 - val_accuracy: 0.0800\n",
      "Epoch 31/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7309 - accuracy: 0.1158 - val_loss: 10.4054 - val_accuracy: 0.1416\n",
      "Epoch 32/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7281 - accuracy: 0.1190 - val_loss: 7.7447 - val_accuracy: 0.1568\n",
      "Epoch 33/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6843 - accuracy: 0.1212 - val_loss: 8.8358 - val_accuracy: 0.1244\n",
      "Epoch 34/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.7035 - accuracy: 0.1166 - val_loss: 7.3610 - val_accuracy: 0.1588\n",
      "Epoch 35/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6708 - accuracy: 0.1206 - val_loss: 9.2742 - val_accuracy: 0.1294\n",
      "Epoch 36/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6866 - accuracy: 0.1229 - val_loss: 8.1883 - val_accuracy: 0.1207\n",
      "Epoch 37/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6604 - accuracy: 0.1187 - val_loss: 8.5450 - val_accuracy: 0.0808\n",
      "Epoch 38/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6709 - accuracy: 0.1234 - val_loss: 9.1301 - val_accuracy: 0.0994\n",
      "Epoch 39/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6485 - accuracy: 0.1245 - val_loss: 9.5950 - val_accuracy: 0.1229\n",
      "Epoch 40/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6575 - accuracy: 0.1217 - val_loss: 9.0682 - val_accuracy: 0.1557\n",
      "Epoch 41/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6359 - accuracy: 0.1298 - val_loss: 10.3063 - val_accuracy: 0.1250\n",
      "Epoch 42/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6227 - accuracy: 0.1320 - val_loss: 9.5031 - val_accuracy: 0.1460\n",
      "Epoch 43/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6468 - accuracy: 0.1255 - val_loss: 8.4235 - val_accuracy: 0.1578\n",
      "Epoch 44/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6363 - accuracy: 0.1262 - val_loss: 8.5942 - val_accuracy: 0.1378\n",
      "Epoch 45/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6675 - accuracy: 0.1245 - val_loss: 9.6286 - val_accuracy: 0.1468\n",
      "Epoch 46/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6426 - accuracy: 0.1243 - val_loss: 9.2402 - val_accuracy: 0.1305\n",
      "Epoch 47/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6318 - accuracy: 0.1315 - val_loss: 8.8999 - val_accuracy: 0.1391\n",
      "Epoch 48/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6769 - accuracy: 0.1250 - val_loss: 7.4261 - val_accuracy: 0.1456\n",
      "Epoch 49/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6068 - accuracy: 0.1342 - val_loss: 8.1753 - val_accuracy: 0.0958\n",
      "Epoch 50/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6190 - accuracy: 0.1332 - val_loss: 9.1135 - val_accuracy: 0.1361\n",
      "Epoch 51/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5731 - accuracy: 0.1398 - val_loss: 9.0598 - val_accuracy: 0.1589\n",
      "Epoch 52/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5685 - accuracy: 0.1412 - val_loss: 8.9449 - val_accuracy: 0.1943\n",
      "Epoch 53/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5757 - accuracy: 0.1474 - val_loss: 8.7822 - val_accuracy: 0.1511\n",
      "Epoch 54/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5756 - accuracy: 0.1472 - val_loss: 7.5554 - val_accuracy: 0.1427\n",
      "Epoch 55/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6046 - accuracy: 0.1338 - val_loss: 8.2317 - val_accuracy: 0.1540\n",
      "Epoch 56/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5899 - accuracy: 0.1390 - val_loss: 8.8160 - val_accuracy: 0.1794\n",
      "Epoch 57/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6079 - accuracy: 0.1328 - val_loss: 9.1631 - val_accuracy: 0.1760\n",
      "Epoch 58/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.6213 - accuracy: 0.1386 - val_loss: 9.0770 - val_accuracy: 0.1749\n",
      "Epoch 59/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5645 - accuracy: 0.1464 - val_loss: 8.8273 - val_accuracy: 0.1810\n",
      "Epoch 60/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5761 - accuracy: 0.1453 - val_loss: 8.8101 - val_accuracy: 0.1916\n",
      "Epoch 61/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5457 - accuracy: 0.1521 - val_loss: 7.6569 - val_accuracy: 0.1772\n",
      "Epoch 62/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5200 - accuracy: 0.1512 - val_loss: 8.7372 - val_accuracy: 0.1778\n",
      "Epoch 63/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5435 - accuracy: 0.1532 - val_loss: 8.3656 - val_accuracy: 0.1811\n",
      "Epoch 64/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5136 - accuracy: 0.1559 - val_loss: 7.5416 - val_accuracy: 0.1706\n",
      "Epoch 65/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5209 - accuracy: 0.1497 - val_loss: 8.8981 - val_accuracy: 0.2045\n",
      "Epoch 66/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5452 - accuracy: 0.1562 - val_loss: 10.3726 - val_accuracy: 0.1762\n",
      "Epoch 67/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5534 - accuracy: 0.1557 - val_loss: 11.2741 - val_accuracy: 0.1273\n",
      "Epoch 68/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5137 - accuracy: 0.1454 - val_loss: 10.8094 - val_accuracy: 0.1963\n",
      "Epoch 69/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5654 - accuracy: 0.1538 - val_loss: 10.3617 - val_accuracy: 0.1523\n",
      "Epoch 70/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5747 - accuracy: 0.1504 - val_loss: 16.0905 - val_accuracy: 0.1952\n",
      "Epoch 71/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5797 - accuracy: 0.1485 - val_loss: 22.2454 - val_accuracy: 0.1609\n",
      "Epoch 72/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5531 - accuracy: 0.1516 - val_loss: 22.3095 - val_accuracy: 0.2010\n",
      "Epoch 73/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5351 - accuracy: 0.1564 - val_loss: 11.2937 - val_accuracy: 0.2310\n",
      "Epoch 74/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5195 - accuracy: 0.1546 - val_loss: 11.2220 - val_accuracy: 0.2009\n",
      "Epoch 75/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5300 - accuracy: 0.1592 - val_loss: 10.3989 - val_accuracy: 0.1877\n",
      "Epoch 76/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5088 - accuracy: 0.1607 - val_loss: 8.9083 - val_accuracy: 0.1807\n",
      "Epoch 77/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4874 - accuracy: 0.1652 - val_loss: 12.8020 - val_accuracy: 0.0729\n",
      "Epoch 78/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4807 - accuracy: 0.1637 - val_loss: 22.7144 - val_accuracy: 0.1795\n",
      "Epoch 79/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5044 - accuracy: 0.1639 - val_loss: 13.6864 - val_accuracy: 0.1949\n",
      "Epoch 80/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5279 - accuracy: 0.1600 - val_loss: 18.6691 - val_accuracy: 0.1777\n",
      "Epoch 81/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4760 - accuracy: 0.1704 - val_loss: 27.3592 - val_accuracy: 0.1504\n",
      "Epoch 82/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5637 - accuracy: 0.1526 - val_loss: 26.8772 - val_accuracy: 0.1484\n",
      "Epoch 83/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5254 - accuracy: 0.1502 - val_loss: 21.0048 - val_accuracy: 0.2326\n",
      "Epoch 84/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.5252 - accuracy: 0.1734 - val_loss: 21.7146 - val_accuracy: 0.1262\n",
      "Epoch 85/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4806 - accuracy: 0.1688 - val_loss: 9.5988 - val_accuracy: 0.1960\n",
      "Epoch 86/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4956 - accuracy: 0.1673 - val_loss: 9.6868 - val_accuracy: 0.1664\n",
      "Epoch 87/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4640 - accuracy: 0.1596 - val_loss: 9.0131 - val_accuracy: 0.1930\n",
      "Epoch 88/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4519 - accuracy: 0.1746 - val_loss: 8.3809 - val_accuracy: 0.2471\n",
      "Epoch 89/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4632 - accuracy: 0.1834 - val_loss: 11.4203 - val_accuracy: 0.1633\n",
      "Epoch 90/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4387 - accuracy: 0.1756 - val_loss: 7.7401 - val_accuracy: 0.2436\n",
      "Epoch 91/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4562 - accuracy: 0.1718 - val_loss: 19.4220 - val_accuracy: 0.2498\n",
      "Epoch 92/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4550 - accuracy: 0.1785 - val_loss: 14.8776 - val_accuracy: 0.2203\n",
      "Epoch 93/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4879 - accuracy: 0.1735 - val_loss: 32.4582 - val_accuracy: 0.1625\n",
      "Epoch 94/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4993 - accuracy: 0.1690 - val_loss: 11.2910 - val_accuracy: 0.2012\n",
      "Epoch 95/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4789 - accuracy: 0.1672 - val_loss: 13.0305 - val_accuracy: 0.1226\n",
      "Epoch 96/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4778 - accuracy: 0.1641 - val_loss: 11.7474 - val_accuracy: 0.2228\n",
      "Epoch 97/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4519 - accuracy: 0.1788 - val_loss: 33.2056 - val_accuracy: 0.2100\n",
      "Epoch 98/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4713 - accuracy: 0.1754 - val_loss: 13.8450 - val_accuracy: 0.2263\n",
      "Epoch 99/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4558 - accuracy: 0.1731 - val_loss: 19.6835 - val_accuracy: 0.1635\n",
      "Epoch 100/100\n",
      "4149/4149 [==============================] - 6s 1ms/step - loss: 2.4828 - accuracy: 0.1706 - val_loss: 14.2491 - val_accuracy: 0.2530\n"
     ]
    }
   ],
   "source": [
    "# DEFINE MODEL PIPELINE\n",
    "# define model architecture\n",
    "def multi_class_nn(n_features, n_classes, units_per_layer, dropout):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(InputLayer(name='input', input_shape=(n_features,)))\n",
    "    # model.add(normalizer)\n",
    "    \n",
    "    for idx, units in enumerate(units_per_layer):\n",
    "        model.add(Dense(units, name=f'hidden_{idx+1}', activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(units=n_classes, name='output', activation='softmax'))\n",
    "\n",
    "    # compile\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', # sparse for ordinal encoding\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# class_weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight = \"balanced\",\n",
    "    classes = np.unique(y_train.to_numpy()),\n",
    "    y =  y_train.to_numpy()\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# instanciate model\n",
    "nn_clf = multi_class_nn(\n",
    "    n_features = X_train_processed.shape[1],\n",
    "    n_classes = y_train_encoded.shape[1],\n",
    "    units_per_layer = [100, 100, 100],\n",
    "    dropout = 0.2,\n",
    ")\n",
    "\n",
    "print(nn_clf.summary())\n",
    "# print(tf.keras.utils.plot_model(nn_clf, show_shapes=True, show_layer_names=True))\n",
    "\n",
    "# Training\n",
    "# train data\n",
    "onehot_encoder = OneHotEncoder(categories = 'auto')\n",
    "y_train_encoded = pd.DataFrame(onehot_encoder.fit_transform(y_train.values.reshape(-1, 1)).toarray())\n",
    "# Test data\n",
    "X_test_processed = preprocess_pipeline.transform(X_test)\n",
    "y_test_encoded = pd.DataFrame(onehot_encoder.transform(y_test.values.reshape(-1, 1)).toarray())\n",
    "# train\n",
    "history = nn_clf.fit(\n",
    "    X_train_processed,\n",
    "    y_train_encoded,\n",
    "    class_weight=class_weight_dict,\n",
    "    validation_data=(X_test_processed, y_test_encoded),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    shuffle=True, # shuffels data randomly after each epoch\n",
    "    # callbacks=[KerasLearningCurve()],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519/519 [==============================] - 0s 628us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [96], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m nn_clf\u001b[38;5;241m.\u001b[39mpredict(X_test_transformed)\n\u001b[1;32m      4\u001b[0m y_test_transformed \u001b[38;5;241m=\u001b[39m onehot_encoder\u001b[38;5;241m.\u001b[39mtransform(y_test\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_preds\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39_bopt_acpackaging/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2125\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassification_report\u001b[39m(\n\u001b[1;32m   2011\u001b[0m     y_true,\n\u001b[1;32m   2012\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2020\u001b[0m ):\n\u001b[1;32m   2021\u001b[0m     \u001b[39m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m \n\u001b[1;32m   2023\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[39m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2123\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2125\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   2127\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2128\u001b[0m         labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39_bopt_acpackaging/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "X_test_transformed  = preprocess_pipeline.transform(X_test)\n",
    "y_preds = nn_clf.predict(X_test_transformed)\n",
    "\n",
    "y_test_transformed = onehot_encoder.transform(y_test.values.reshape(-1, 1)).toarray()\n",
    "\n",
    "print(classification_report(y_test_transformed, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4.070479</td>\n",
       "      <td>0.008934</td>\n",
       "      <td>1.153754e+10</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4.057920</td>\n",
       "      <td>0.011857</td>\n",
       "      <td>1.108053e+10</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.031371</td>\n",
       "      <td>0.010652</td>\n",
       "      <td>8.056508e+09</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4.060278</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>7.011128e+09</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3.989947</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>9.626664e+09</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy      val_loss  val_accuracy  epochs\n",
       "45  4.070479  0.008934  1.153754e+10      0.000603      45\n",
       "46  4.057920  0.011857  1.108053e+10      0.001386      46\n",
       "47  4.031371  0.010652  8.056508e+09      0.000663      47\n",
       "48  4.060278  0.008783  7.011128e+09      0.001446      48\n",
       "49  3.989947  0.010109  9.626664e+09      0.001326      49"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist = pd.DataFrame(history.history)\n",
    "df_hist['epochs'] = history.epoch\n",
    "df_hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd6ccea45e0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN with HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ml_packaging_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
