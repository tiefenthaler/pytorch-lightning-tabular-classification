{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERAL THOUGHTS:**\n",
    "- ...\n",
    "\n",
    "\n",
    "**DATA PREPROCESSING:**\n",
    "\n",
    "Imbalanced data:\n",
    "- over_sampling for imbalanced data\n",
    "- cost-sensitive learning for imbalanced data\n",
    "\n",
    "categorical data:\n",
    "- Ordinal Data: The categories have an inherent order\n",
    "- Nominal Data: The categories do not have an inherent order\n",
    "\n",
    "\n",
    "\n",
    "**MULTI-CLASS CLASSIFIER:**\n",
    "- Focus on \"Native Multiclass Classifiers\" as a starting point. Might try \"Binary Transformation\" or \"Hierarchical Classification\" later. https://www.projectpro.io/article/multi-class-classification-python-example/547\n",
    "- Overview models to be considered:  \n",
    "  - [X] Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dat/miniconda3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import xgboost as xgb\n",
    "# import lightgbm as lgbm\n",
    "\n",
    "import optuna\n",
    "# from optuna.samplers import TPESampler\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-25_11:14:09\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "clf_name = \"dt_clf\"\n",
    "\n",
    "# Get current date and time\n",
    "now = datetime.now()\n",
    "# Format date and time\n",
    "formatted_date_time = now.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "print(formatted_date_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/output/df_ml.csv', sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline  \n",
    "train model and pipeline on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full dataset (assinged & unassinged SKUs)\n",
    "df_raw = pd.read_csv('../../data/data_showcase.csv', sep='\\t')\n",
    "\n",
    "# data cleaning (data formats, general transformations, \"feature selection\")\n",
    "df_cleaned = df_raw.rename(columns={\n",
    "    'Product Area': 'product_area',\n",
    "    'Core Segment': 'core_segment',\n",
    "    'Brand': 'brand',\n",
    "    'Material Number': 'material_number',\n",
    "    'Material No Text': 'material_number_text',\n",
    "    'Component': 'component',\n",
    "    'Material Description': 'component_text',\n",
    "    'Packaging Code': 'packaging_code',\n",
    "    'Material Characteristic': 'characteristic_value',\n",
    "    'Material Weight': 'material_weight',\n",
    "    'Column 21': 'col_21',\n",
    "    'Weight measure': 'weight_measure',\n",
    "    'Packaging Category': 'packaging_category',\n",
    "    'Manufactoring Location': 'manufactoring_location',\n",
    "    'Column 43': 'col_43'\n",
    "})\n",
    "\n",
    "df_cleaned['material_number'] = df_cleaned['material_number'].astype('object')\n",
    "df_cleaned['packaging_category'] = df_cleaned['packaging_category'].astype('object')\n",
    "\n",
    "df_cleaned['packaging_category'].mask(\n",
    "    df_cleaned['packaging_category'].isin(['-', np.nan]), 'Unassigned', inplace=True\n",
    ")\n",
    "\n",
    "df_cleaned['packaging_category'].mask(\n",
    "    df_cleaned['packaging_category'].isin(['No Packaging']), 'U0 – Unpacked', inplace=True\n",
    ")\n",
    "\n",
    "df_full_sub = df_cleaned[[\n",
    "    'material_number',\n",
    "    'brand',\n",
    "    'product_area',\n",
    "    'core_segment',\n",
    "    'component',\n",
    "    'manufactoring_location',\n",
    "    'characteristic_value',\n",
    "    'material_weight', \n",
    "    'packaging_code',\n",
    "    'packaging_category',\n",
    "]]\n",
    "\n",
    "# TODO(optional): data quality checks (e.g. ensure features have the right format, size of input data, ...)\n",
    "\n",
    "\n",
    "# final training data\n",
    "# split data into \"assigned\" == X, and \"unassinged\" == X_prod\n",
    "df_ml = df_full_sub[df_full_sub.packaging_category != 'Unassigned']\n",
    "# Define features and target\n",
    "X = df_ml.iloc[:, :-1]\n",
    "y = df_ml.iloc[:, -1]  # the last column is the target\n",
    "# NOTE: Oversampling so each class has at least 100 sample; to properly apply CV and evaluation\n",
    "dict_oversmapling = {\n",
    "    'Metal Cassette': 100,\n",
    "    'Carton tube with or w/o': 100,\n",
    "    'Wooden box': 100,\n",
    "    'Fabric packaging': 100,\n",
    "    'Book packaging': 100\n",
    "}\n",
    "# define oversampling strategy\n",
    "oversampler = RandomOverSampler(sampling_strategy=dict_oversmapling, random_state=SEED)\n",
    "# fit and apply the transform\n",
    "X, y = oversampler.fit_resample(X, y)\n",
    "\n",
    "\n",
    "# production data (for inference)\n",
    "df_no_packaging_categories = df_full_sub[df_full_sub.packaging_category == 'Unassigned']\n",
    "# Define features and target\n",
    "X_inf = df_no_packaging_categories.iloc[:, :-1]\n",
    "y_inf = df_no_packaging_categories.iloc[:, -1]  # the last column is the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(class_weight={0: 0.3177111924367185,\n",
       "                                     1: 0.3511206605999326,\n",
       "                                     2: 27.780666666666665, 3: 4.10956607495069,\n",
       "                                     4: 6.945166666666666, 5: 4.260838445807771,\n",
       "                                     6: 27.780666666666665,\n",
       "                                     7: 5.7279725085910655,\n",
       "                                     8: 0.7174758953168044,\n",
       "                                     9: 18.520444444444443,\n",
       "                                     10: 9.417175141242938,\n",
       "                                     11: 27.780666666666665,\n",
       "                                     12: 0.3380054345621933,\n",
       "                                     13: 0.20512934111102907,\n",
       "                                     14: 27.780666666666665,\n",
       "                                     15: 0.7987540732221583,\n",
       "                                     16: 1.863223787167449,\n",
       "                                     17: 1.626502732240437,\n",
       "                                     18: 1.4590686274509803,\n",
       "                                     19: 1.5016576576576577,\n",
       "                                     20: 1.853279964420725, 21: 2.4305045202683,\n",
       "                                     22: 0.33486820957891356,\n",
       "                                     23: 3.45530679933665,\n",
       "                                     24: 1.2696831200487508,\n",
       "                                     25: 6.445630317092034,\n",
       "                                     26: 0.23770571290037362,\n",
       "                                     27: 347.2583333333333,\n",
       "                                     28: 1.9744610281923716,\n",
       "                                     29: 27.780666666666665},\n",
       "                       criterion=&#x27;entropy&#x27;, max_depth=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight={0: 0.3177111924367185,\n",
       "                                     1: 0.3511206605999326,\n",
       "                                     2: 27.780666666666665, 3: 4.10956607495069,\n",
       "                                     4: 6.945166666666666, 5: 4.260838445807771,\n",
       "                                     6: 27.780666666666665,\n",
       "                                     7: 5.7279725085910655,\n",
       "                                     8: 0.7174758953168044,\n",
       "                                     9: 18.520444444444443,\n",
       "                                     10: 9.417175141242938,\n",
       "                                     11: 27.780666666666665,\n",
       "                                     12: 0.3380054345621933,\n",
       "                                     13: 0.20512934111102907,\n",
       "                                     14: 27.780666666666665,\n",
       "                                     15: 0.7987540732221583,\n",
       "                                     16: 1.863223787167449,\n",
       "                                     17: 1.626502732240437,\n",
       "                                     18: 1.4590686274509803,\n",
       "                                     19: 1.5016576576576577,\n",
       "                                     20: 1.853279964420725, 21: 2.4305045202683,\n",
       "                                     22: 0.33486820957891356,\n",
       "                                     23: 3.45530679933665,\n",
       "                                     24: 1.2696831200487508,\n",
       "                                     25: 6.445630317092034,\n",
       "                                     26: 0.23770571290037362,\n",
       "                                     27: 347.2583333333333,\n",
       "                                     28: 1.9744610281923716,\n",
       "                                     29: 27.780666666666665},\n",
       "                       criterion=&#x27;entropy&#x27;, max_depth=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(class_weight={0: 0.3177111924367185,\n",
       "                                     1: 0.3511206605999326,\n",
       "                                     2: 27.780666666666665, 3: 4.10956607495069,\n",
       "                                     4: 6.945166666666666, 5: 4.260838445807771,\n",
       "                                     6: 27.780666666666665,\n",
       "                                     7: 5.7279725085910655,\n",
       "                                     8: 0.7174758953168044,\n",
       "                                     9: 18.520444444444443,\n",
       "                                     10: 9.417175141242938,\n",
       "                                     11: 27.780666666666665,\n",
       "                                     12: 0.3380054345621933,\n",
       "                                     13: 0.20512934111102907,\n",
       "                                     14: 27.780666666666665,\n",
       "                                     15: 0.7987540732221583,\n",
       "                                     16: 1.863223787167449,\n",
       "                                     17: 1.626502732240437,\n",
       "                                     18: 1.4590686274509803,\n",
       "                                     19: 1.5016576576576577,\n",
       "                                     20: 1.853279964420725, 21: 2.4305045202683,\n",
       "                                     22: 0.33486820957891356,\n",
       "                                     23: 3.45530679933665,\n",
       "                                     24: 1.2696831200487508,\n",
       "                                     25: 6.445630317092034,\n",
       "                                     26: 0.23770571290037362,\n",
       "                                     27: 347.2583333333333,\n",
       "                                     28: 1.9744610281923716,\n",
       "                                     29: 27.780666666666665},\n",
       "                       criterion='entropy', max_depth=50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FULL TRAINING PIPELINE\n",
    "\n",
    "# DEFINE PREPROCESSING PIPELINE\n",
    "# define numerical feature processing\n",
    "numerical_features = X.select_dtypes(include='number').columns.tolist()\n",
    "# print(f'There are {len(numerical_features)} numerical features:', '\\n')\n",
    "# print(numerical_features)\n",
    "numeric_feature_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('log_transform', PowerTransformer()),\n",
    "    # ('scale', MinMaxScaler())\n",
    "])\n",
    "# define categorical feature processing\n",
    "categorical_features = X.select_dtypes(exclude='number').columns.tolist()\n",
    "# print(f'There are {len(categorical_features)} categorical features:', '\\n')\n",
    "# print(categorical_features)\n",
    "categorical_feature_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "    # ('one_hot', OneHotEncoder(handle_unknown='ignore', max_categories=None, sparse=False))\n",
    "])\n",
    "# apply both pipeline on seperate columns using \"ColumnTransformer\"\n",
    "preprocess_pipeline = ColumnTransformer(transformers=[\n",
    "    ('number', numeric_feature_pipeline, numerical_features),\n",
    "    ('category', categorical_feature_pipeline, categorical_features)\n",
    "])\n",
    "X_transformed = preprocess_pipeline.fit_transform(X)\n",
    "\n",
    "\n",
    "# TARGET PIPELINE\n",
    "label_ecoder = LabelEncoder()\n",
    "y_transformed = label_ecoder.fit_transform(y)\n",
    "\n",
    "\n",
    "# DEFINE MODEL PIPELINE\n",
    "# calc class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_transformed),\n",
    "    y=y_transformed\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "# model\n",
    "best_params = {\n",
    "    'max_depth': 50,\n",
    "    'criterion': 'entropy'\n",
    "}\n",
    "dt_clf = DecisionTreeClassifier(\n",
    "    # n_estimators=10,\n",
    "    **best_params,\n",
    "    class_weight=class_weight_dict,\n",
    "    # random_state=SEED\n",
    ")\n",
    "# training\n",
    "dt_clf.fit(X_transformed, y_transformed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save pipeline & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pre-processing pipeline\n",
    "\n",
    "# pipeline\n",
    "final_preprocessing_pipeline = preprocess_pipeline\n",
    "\n",
    "# get patch for ml model directory\n",
    "path_ml_pipeline = \"../../ml_pipelines\"\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path_ml_pipeline)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(path_ml_pipeline)\n",
    "\n",
    "pickle.dump(final_preprocessing_pipeline, open(f'{path_ml_pipeline}/final_preprocessing_pipeline_{clf_name}_{formatted_date_time}.pkl', 'wb'))\n",
    "pickle.dump(label_ecoder, open(f'{path_ml_pipeline}/final_label_ecoder_{clf_name}_{formatted_date_time}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "# model\n",
    "best_model = dt_clf\n",
    "\n",
    "# get patch for ml model directory\n",
    "path_ml_pipeline = \"../../ml_pipelines\"\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path_ml_pipeline)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(path_ml_pipeline)\n",
    "\n",
    "# print('Model score:', best_model.score(X_test_scaled, y_test))\n",
    "pickle.dump(best_model, open(f'{path_ml_pipeline}/best_model_{clf_name}_{formatted_date_time}.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference for SKUs with unassigned packaging categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full dataset (assinged & unassinged SKUs)\n",
    "df_raw = pd.read_csv('../../data/data_showcase.csv', sep='\\t')\n",
    "\n",
    "# data cleaning (data formats, general transformations, \"feature selection\")\n",
    "df_cleaned = df_raw.rename(columns={\n",
    "    'Product Area': 'product_area',\n",
    "    'Core Segment': 'core_segment',\n",
    "    'Brand': 'brand',\n",
    "    'Material Number': 'material_number',\n",
    "    'Material No Text': 'material_number_text',\n",
    "    'Component': 'component',\n",
    "    'Material Description': 'component_text',\n",
    "    'Packaging Code': 'packaging_code',\n",
    "    'Material Characteristic': 'characteristic_value',\n",
    "    'Material Weight': 'material_weight',\n",
    "    'Column 21': 'col_21',\n",
    "    'Weight measure': 'weight_measure',\n",
    "    'Packaging Category': 'packaging_category',\n",
    "    'Manufactoring Location': 'manufactoring_location',\n",
    "    'Column 43': 'col_43'\n",
    "})\n",
    "\n",
    "df_cleaned['material_number'] = df_cleaned['material_number'].astype('object')\n",
    "df_cleaned['packaging_category'] = df_cleaned['packaging_category'].astype('object')\n",
    "\n",
    "df_cleaned['packaging_category'].mask(\n",
    "    df_cleaned['packaging_category'].isin(['-', np.nan]), 'Unassigned', inplace=True\n",
    ")\n",
    "\n",
    "df_cleaned['packaging_category'].mask(\n",
    "    df_cleaned['packaging_category'].isin(['No Packaging']), 'U0 – Unpacked', inplace=True\n",
    ")\n",
    "\n",
    "df_full_sub = df_cleaned[[\n",
    "    'material_number',\n",
    "    'brand',\n",
    "    'product_area',\n",
    "    'core_segment',\n",
    "    'component',\n",
    "    'manufactoring_location',\n",
    "    'characteristic_value',\n",
    "    'material_weight', \n",
    "    'packaging_code',\n",
    "    'packaging_category',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inf = df_full_sub[df_full_sub.packaging_category == 'Unassigned']\n",
    "# Define features and target\n",
    "X_inf = df_inf.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement data quality check (corresponding to the pre-pipeline steps)\n",
    "\n",
    "# load pre-processing pipeline\n",
    "loaded_preprocessing_pipeline = pickle.load(open(f'{path_ml_pipeline}/final_preprocessing_pipeline_{clf_name}_{formatted_date_time}.pkl', 'rb'))\n",
    "loaded_lable_encoder = pickle.load(open(f'{path_ml_pipeline}/final_label_ecoder_{clf_name}_{formatted_date_time}.pkl', 'rb'))\n",
    "\n",
    "# load model\n",
    "loaded_model = pickle.load(open(f'{path_ml_pipeline}/best_model_{clf_name}_{formatted_date_time}.pkl', 'rb'))                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "X_inf_transformed = loaded_preprocessing_pipeline.transform(X_inf)\n",
    "preds_y_inf = loaded_model.predict(X_inf_transformed)\n",
    "preds_y_inf_inverse = loaded_lable_encoder.inverse_transform(preds_y_inf)\n",
    "# inference proba\n",
    "preds_y_inf_proba = loaded_model.predict_proba(X_inf_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df only containung unassigned; alternative: create 3 df (output files): 1. full as above (assinged & unassinged), 2. only containing assinged 3. only containung unassigned\n",
    "df_unassigned_SKUs_with_predicted_classes = pd.DataFrame(X_inf.material_number)\n",
    "df_unassigned_SKUs_with_predicted_classes['predected_packaging_categories'] = preds_y_inf_inverse\n",
    "df_unassigned_SKUs_with_predicted_classes['predected_packaging_categories_probabilities'] = preds_y_inf_proba.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material_number</th>\n",
       "      <th>predected_packaging_categories</th>\n",
       "      <th>predected_packaging_categories_probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>77095609</td>\n",
       "      <td>Cardb. Sleeve w - w/o Shr.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>77095609</td>\n",
       "      <td>Unpacked</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>77095609</td>\n",
       "      <td>Shrink film and insert o</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>53683705</td>\n",
       "      <td>Folding carton</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>59950025</td>\n",
       "      <td>Metal Cassette</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     material_number predected_packaging_categories  \\\n",
       "366         77095609     Cardb. Sleeve w - w/o Shr.   \n",
       "367         77095609                       Unpacked   \n",
       "368         77095609       Shrink film and insert o   \n",
       "787         53683705                 Folding carton   \n",
       "800         59950025                 Metal Cassette   \n",
       "\n",
       "     predected_packaging_categories_probabilities  \n",
       "366                                           1.0  \n",
       "367                                           1.0  \n",
       "368                                           1.0  \n",
       "787                                           1.0  \n",
       "800                                           1.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unassigned_SKUs_with_predicted_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  1.0\n",
      "count:  7058\n"
     ]
    }
   ],
   "source": [
    "print('mean: ', df_unassigned_SKUs_with_predicted_classes.predected_packaging_categories_probabilities.mean())\n",
    "print('count: ', df_unassigned_SKUs_with_predicted_classes.predected_packaging_categories_probabilities.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  1.0\n",
      "count:  7058\n"
     ]
    }
   ],
   "source": [
    "print('mean: ',\n",
    "    df_unassigned_SKUs_with_predicted_classes.loc[\n",
    "        df_unassigned_SKUs_with_predicted_classes.predected_packaging_categories_probabilities >= 0.50\n",
    "    ].predected_packaging_categories_probabilities.mean()\n",
    ")\n",
    "print('count: ',\n",
    "    df_unassigned_SKUs_with_predicted_classes.loc[\n",
    "        df_unassigned_SKUs_with_predicted_classes.predected_packaging_categories_probabilities >= 0.50\n",
    "    ].predected_packaging_categories_probabilities.count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  1.0\n",
      "count:  7058\n"
     ]
    }
   ],
   "source": [
    "print('mean: ',\n",
    "    df_unassigned_SKUs_with_predicted_classes.loc[\n",
    "        df_unassigned_SKUs_with_predicted_classes.predected_packaging_categories_probabilities >= 0.95\n",
    "    ].predected_packaging_categories_probabilities.mean()\n",
    ")\n",
    "print('count: ',\n",
    "    df_unassigned_SKUs_with_predicted_classes.loc[\n",
    "        df_unassigned_SKUs_with_predicted_classes.predected_packaging_categories_probabilities >= 0.95\n",
    "    ].predected_packaging_categories_probabilities.count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions for unassigned SKUs as excel\n",
    "# df_unassigned_SKUs_with_predicted_classes.to_excel(f'../../data/output/unassigned_SKUs_with_{clf_name}_{formatted_date_time}_predicted_classes.xlsx', sheet_name='dt_predictions_unassigned_SKUs', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39_bopt_acpackaging')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25500324c997461312d302dc845ff6d6f05c10e502b314035685f7b576362db1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
