{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERAL THOUGHTS:**\n",
    "\n",
    "\n",
    "\n",
    "**DATA PREPROCESSING:**\n",
    "\n",
    "Imbalanced data:\n",
    "- over_sampling for imbalanced data\n",
    "- cost-sensitive learning for imbalanced data\n",
    "\n",
    "continuous data:\n",
    "- Impute missing data: SimpleImputer(strategy='median')\n",
    "- Standardize data: StandardScaler()\n",
    "\n",
    "categorical data:\n",
    "- Impute missing data: SimpleImputer(strategy='most_frequent')\n",
    "- Ordinal & Nominal data encoding: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "- Unknown values ecoding: custom encoder \"OrdinalEncoderExtensionUnknowns()\"\n",
    "\n",
    "target data:\n",
    "- target encoding: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "**MULTI-CLASS CLASSIFIER:**\n",
    "- Overview models to be considered:  \n",
    "  - [X] Neural Net: Multi Layer Perceptron (MLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install optuna==3.5.0\n",
    "    # !pip install optuna.integration\n",
    "    !pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import sys\n",
    "import yaml\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "import torch\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: if used in google colab, upload env_vars_colab.yml to current google colab directory!\n",
    "\n",
    "# get config\n",
    "if colab:\n",
    "    with open('./env_vars_colab.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    # custom imports\n",
    "    sys.path.append(config['project_directory'])\n",
    "else:\n",
    "    with open('../env_vars.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    # custom imports\n",
    "    sys.path.append(config['project_directory'])\n",
    "\n",
    "from src.tabular_lightning import (\n",
    "    TabularDataModuleClassificationPACKAGING,\n",
    "    MulticlassTabularLightningModule,\n",
    "    MulticlassTabularMLP\n",
    ")\n",
    "from src import tabular_lightning_utils as tl_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 # Ensure same data split as in other notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models and Training/HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptunaObjective(object):\n",
    "    \"\"\"Optuna objective for hyperparameter tuning.\"\"\"\n",
    "    def __init__(self, optuna_config) -> None:\n",
    "        self.optuna_config = optuna_config\n",
    "        self.dm = TabularDataModuleClassificationPACKAGING(\n",
    "            data_dir=f\"{config['data_directory']}/output/df_ml.csv\",\n",
    "            continuous_cols=['material_weight'],\n",
    "            categorical_cols=[\n",
    "                'material_number',\n",
    "                'brand',\n",
    "                'product_area',\n",
    "                'core_segment',\n",
    "                'component',\n",
    "                'manufactoring_location',\n",
    "                'characteristic_value',\n",
    "                'packaging_code'\n",
    "            ],\n",
    "            target=['packaging_category'],\n",
    "            oversampling=True,\n",
    "            test_size=0.2,\n",
    "            val_size=0.2,\n",
    "            batch_size=64,\n",
    "            SEED=SEED\n",
    "        )\n",
    "        self.dm.prepare_data()\n",
    "        self.dm.setup(stage='fit')\n",
    "        tl_utils.check_data_consitancy(self.dm)\n",
    "        tl_utils.check_dataloader_output(self.dm, next(iter(self.dm.train_dataloader())))\n",
    "\n",
    "        tabular_data_full = pd.concat([self.dm.train_dataset.get_dataframe, self.dm.val_dataset.get_dataframe, self.dm.test_dataset.get_dataframe], axis=0, ignore_index=True)\n",
    "        self.embedding_sizes_cat_features = tl_utils.get_cat_feature_embedding_sizes(tabular_data_full, categorical_cols=self.dm.categorical_cols)\n",
    "\n",
    "    def __call__(self, trial: optuna.Trial) -> float:\n",
    "\n",
    "        # joblib.dump(study, 'study.pkl')\n",
    "\n",
    "        # Define the hyperparameter search space\n",
    "        hp_space_optuna = {\n",
    "            'hidden_size': trial.suggest_categorical('hidden_size', [8, 16, 32, 64, 128]), # number of neurons in each layer\n",
    "            'n_hidden_layers': trial.suggest_int(\"n_hidden_layers\", 1, 6), # number of layers\n",
    "            'batch_size': trial.suggest_categorical(\"batch_size\", [16, 32, 64]), # number of samples per batch\n",
    "            'dropout': trial.suggest_categorical(\"dropout\", [0.0, 0.1, 0.2, 0.4]), # dropout rate\n",
    "        }\n",
    "        # Create a datamodule\n",
    "        dm = copy.deepcopy(self.dm) # deep copy for distributed training\n",
    "        dm.batch_size = hp_space_optuna['batch_size']\n",
    "        # Create a model\n",
    "        model = MulticlassTabularMLP(\n",
    "            input_size=len(dm.feature_cols),\n",
    "            output_size=dm.n_classes,\n",
    "            hidden_size=hp_space_optuna['hidden_size'],\n",
    "            n_hidden_layers=hp_space_optuna['n_hidden_layers'],\n",
    "            dropout=hp_space_optuna['dropout'],\n",
    "            norm=True,\n",
    "        )\n",
    "        # Create a LightningModule\n",
    "        lightningmodel = MulticlassTabularLightningModule(\n",
    "            model=model,\n",
    "            learning_rate=0.001,\n",
    "            train_acc = MulticlassF1Score(num_classes=dm.n_classes, average='weighted'),\n",
    "            val_acc = MulticlassF1Score(num_classes=dm.n_classes, average='weighted'),\n",
    "            test_acc = MulticlassF1Score(num_classes=dm.n_classes, average='weighted'),\n",
    "        )\n",
    "        # Create a trainer\n",
    "        trainer = L.Trainer(\n",
    "            devices=\"auto\", # (os.cpu_count() / 2)\n",
    "            callbacks=[\n",
    "                PyTorchLightningPruningCallback(trial, monitor=\"val_loss\"),\n",
    "                # EarlyStopping(monitor='val_loss', min_delta=0.00, patience=5),\n",
    "            ],\n",
    "            max_epochs=self.optuna_config[\"trainer_max_epochs\"],\n",
    "            precision='bf16-mixed',\n",
    "            default_root_dir=\"lightning_logs/\",\n",
    "        )\n",
    "        # Create a Tuner\n",
    "        tuner = Tuner(trainer)\n",
    "        lr_finder = tuner.lr_find(lightningmodel, datamodule=dm) # finds learning rate automatically\n",
    "        new_lr = lr_finder.suggestion()\n",
    "        lightningmodel.learning_rate = new_lr # update hparams of the model\n",
    "        trial.set_user_attr(\"learning_rate\", new_lr) # Track learning_rate as a user attribute\n",
    "        # Train the model\n",
    "        trainer.fit(\n",
    "            model=lightningmodel,\n",
    "            train_dataloaders=dm.train_dataloader(),\n",
    "            val_dataloaders=dm.val_dataloader()\n",
    "        )\n",
    "\n",
    "        # score = trainer.test(model=lightningmodel, dataloaders=self.dm.test_dataloader())\n",
    "        # score[0]['test_F1_macro_weighted']\n",
    "\n",
    "        return trainer.callback_metrics[\"val_F1_macro_weighted\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MLP-v2\"\n",
    "optuna_config = {\n",
    "    \"experiment_name\": model_name,\n",
    "    \"study_storage_directory\": config['optuna_storage_directory'],\n",
    "    \"study_n_trials\": 50,\n",
    "    \"study_timeout\": 25000, # 3600 seconds/hour\n",
    "    \"study_n_jobs\": -1,\n",
    "    \"trainer_max_epochs\": 100,\n",
    "}\n",
    "optuna_config[\"storage_name\"] = f\"sqlite:///{optuna_config['study_storage_directory']}/{optuna_config['experiment_name']}.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper-parameter space, model + training, optimization metric via Objective\n",
    "objective = OptunaObjective(optuna_config)\n",
    "\n",
    "# define and run study for optimization\n",
    "study = optuna.create_study(\n",
    "    study_name=optuna_config['experiment_name'],\n",
    "    storage=optuna_config[\"storage_name\"],\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "    pruner=optuna.pruners.MedianPruner()\n",
    ")\n",
    "\n",
    "# define duration of the optimization process by and/or number_of_trails and timeout\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=optuna_config[\"study_n_trials\"],\n",
    "    timeout=optuna_config[\"study_timeout\"],\n",
    "    n_jobs=optuna_config[\"study_n_jobs\"],\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Optuna study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print optimization results\n",
    "try:\n",
    "    study = optuna.load_study(study_name=optuna_config['experiment_name'], storage=optuna_config[\"storage_name\"])\n",
    "except:\n",
    "    print(\"Study not saved to storage. Loading study from memory.\")\n",
    "print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(\"  Performance: \", best_trial.value)\n",
    "print('  Best trial:', best_trial.params)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in best_trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history of all trials\n",
    "hist = study.trials_dataframe()\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performance of all trials\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the parameter relationship concerning performance\n",
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots the interactive visualization of the high-dimensional parameter relationship\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots parameter interactive chart from we can choose which hyperparameter space has to explore\n",
    "optuna.visualization.plot_contour(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define best model\n",
    "\n",
    "best_params = best_trial.params\n",
    "\n",
    "# Evaluate best model on test data again\n",
    "def eval_best_model(best_params, optuna_config) -> None:\n",
    "    # datamodule\n",
    "    dm=TabularDataModuleClassificationPACKAGING(\n",
    "        data_dir=f\"{config['data_directory']}/output/df_ml.csv\",\n",
    "        continuous_cols=['material_weight'],\n",
    "        categorical_cols=[\n",
    "            'material_number',\n",
    "            'brand',\n",
    "            'product_area',\n",
    "            'core_segment',\n",
    "            'component',\n",
    "            'manufactoring_location',\n",
    "            'characteristic_value',\n",
    "            'packaging_code'\n",
    "        ],\n",
    "        target=['packaging_category'],\n",
    "        oversampling=True,\n",
    "        test_size=0.2,\n",
    "        val_size=0.2,\n",
    "        batch_size=best_params['batch_size'],\n",
    "        SEED=SEED\n",
    "    )\n",
    "    dm.prepare_data()\n",
    "    dm.setup(stage='fit')\n",
    "    # model\n",
    "    best_model = MulticlassTabularMLP(\n",
    "        input_size=len(dm.feature_cols),\n",
    "        output_size=dm.n_classes,\n",
    "        hidden_size=best_params['hidden_size'],\n",
    "        n_hidden_layers=best_params['n_hidden_layers'],\n",
    "        dropout=best_params['dropout'],\n",
    "        norm=True,\n",
    "    )\n",
    "    # lightningmodel\n",
    "    lightningmodel = MulticlassTabularLightningModule(\n",
    "        model=best_model,\n",
    "        learning_rate=0.001,\n",
    "        train_acc = MulticlassF1Score(num_classes=dm.n_classes, average='weighted'),\n",
    "        val_acc = MulticlassF1Score(num_classes=dm.n_classes, average='weighted'),\n",
    "        test_acc = MulticlassF1Score(num_classes=dm.n_classes, average='weighted'),\n",
    "    )\n",
    "    # trainer\n",
    "    trainer = L.Trainer(\n",
    "        devices=\"auto\", # (os.cpu_count() / 2)\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', min_delta=0.00, patience=5),\n",
    "            ModelCheckpoint(\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"min\",\n",
    "                save_top_k=1,\n",
    "                every_n_epochs=3,\n",
    "                enable_version_counter=False,\n",
    "                dirpath=f\"lightning_logs/checkpoints/{optuna_config['experiment_name']}\",\n",
    "                filename=f\"best_model_{optuna_config['experiment_name']}\",\n",
    "            ),\n",
    "        ],\n",
    "        logger=CSVLogger(save_dir=\"logs/\", name=optuna_config['experiment_name']),\n",
    "        max_epochs=100,\n",
    "        precision='bf16-mixed',\n",
    "        default_root_dir=\"lightning_logs/\",\n",
    "    )\n",
    "    # find learning rate\n",
    "    tuner = Tuner(trainer)\n",
    "    lr_finder = tuner.lr_find(lightningmodel, datamodule=dm) # finds learning rate automatically\n",
    "    new_lr = lr_finder.suggestion()\n",
    "    fig_lr = lr_finder.plot(suggest=True)\n",
    "    lightningmodel.learning_rate = new_lr # update hparams of the model\n",
    "    # train model\n",
    "    trainer.fit(\n",
    "        model=lightningmodel,\n",
    "        train_dataloaders=dm.train_dataloader(),\n",
    "        val_dataloaders=dm.val_dataloader()\n",
    "    )\n",
    "    fig_lr.savefig(f\"lightning_logs/checkpoints/{optuna_config['experiment_name']}/learning_rate_best_model_{optuna_config['experiment_name']}.pdf\")\n",
    "    # plot training metrics\n",
    "    metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "    tl_utils.plot_training_metrics(metrics)\n",
    "    # evaluate model on test data\n",
    "    score = trainer.test(model=lightningmodel, dataloaders=dm.test_dataloader())\n",
    "    print(f\"test_F1_macro_weighted: {score[0]['test_F1_macro_weighted']}\")\n",
    "\n",
    "    return lightningmodel.parameters, lightningmodel.learning_rate\n",
    "\n",
    "# Evaluate best model on test data\n",
    "lm_parameters, lm_learning_rate = eval_best_model(best_params, optuna_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model from checkpoint and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_predict(\n",
    "    study: optuna.Study = None,\n",
    "    checkpoint_path: str = None,\n",
    ") -> None:\n",
    "    \"\"\"Loads the best model from the checkpoint and predicts on the test set.\n",
    "    Args:\n",
    "        study (optuna.Study): The study object of optuna.\n",
    "        checkpoint_path (str): The path to the checkpoint.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # datamodule\n",
    "    dm=TabularDataModuleClassificationPACKAGING(\n",
    "        data_dir=f\"{config['data_directory']}/output/df_ml.csv\",\n",
    "        continuous_cols=['material_weight'],\n",
    "        categorical_cols=[\n",
    "            'material_number',\n",
    "            'brand',\n",
    "            'product_area',\n",
    "            'core_segment',\n",
    "            'component',\n",
    "            'manufactoring_location',\n",
    "            'characteristic_value',\n",
    "            'packaging_code'\n",
    "        ],\n",
    "        target=['packaging_category'],\n",
    "        oversampling=True,\n",
    "        test_size=0.2,\n",
    "        val_size=0.2,\n",
    "        batch_size=best_params['batch_size'],\n",
    "        SEED=SEED\n",
    "    )\n",
    "    dm.prepare_data()\n",
    "    dm.setup(stage='fit')\n",
    "    # model\n",
    "    best_model = MulticlassTabularMLP(\n",
    "        input_size=len(dm.feature_cols),\n",
    "        output_size=dm.n_classes,\n",
    "        hidden_size=study.best_trial.params['hidden_size'],\n",
    "        n_hidden_layers=study.best_trial.params['n_hidden_layers'],\n",
    "        dropout=study.best_trial.params['dropout'],\n",
    "        norm=True,\n",
    "    )\n",
    "    # Parameters that were not tracked (excluded), they need to be provided at the time of loading\n",
    "    # NOTE: Those parameters are either complicated to track or were excluded to reduce logging of those parameters during training\n",
    "    lighning_model_args = {\n",
    "        \"model\": best_model,\n",
    "        \"learning_rate\": study.best_trial.user_attrs[\"learning_rate\"],\n",
    "        # \"train_acc\": MulticlassF1Score(num_classes=dm.n_classes, average='weighted'),\n",
    "        # \"val_acc\": MulticlassF1Score(num_classes=dm.n_classes, average='weighted'),\n",
    "        # \"test_acc\": MulticlassF1Score(num_classes=dm.n_classes, average='weighted'),\n",
    "    }\n",
    "    # lighning_model_args[\"optimizer\"] = torch.optim.Adam  # For compatibility. Not Used\n",
    "    # lighning_model_args[\"loss\"] = F.cross_entropy  # For compatibility. Not Used\n",
    "    # lighning_model_args[\"optimizer_params\"] = {}  # For compatibility. Not Used\n",
    "    # lightning model\n",
    "    best_trained_lightning_model = MulticlassTabularLightningModule.load_from_checkpoint(\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        # map_location=torch.device('cpu'),\n",
    "        strict=True,\n",
    "        **lighning_model_args,\n",
    "    )\n",
    "    # trainer\n",
    "    trainer = L.Trainer(\n",
    "        devices=\"auto\", # (os.cpu_count() / 2)\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', min_delta=0.00, patience=5),\n",
    "        ],\n",
    "        precision='bf16-mixed',\n",
    "        default_root_dir=\"lightning_logs/\",\n",
    "    )\n",
    "    # predict\n",
    "    preds_y_test = torch.cat(trainer.predict(model=best_trained_lightning_model, dataloaders=dm.test_dataloader()))\n",
    "    preds_y_test = dm.label_encoder_target.inverse_transform(preds_y_test.reshape(-1, 1))\n",
    "    y_test = dm.label_encoder_target.inverse_transform(dm.test_dataset.get_dataframe.iloc[:, -1].values.reshape(-1, 1))\n",
    "    # calculate classification report\n",
    "    print(classification_report(y_test, preds_y_test))\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# configs to load model from checkpoint\n",
    "load_config = {\n",
    "    \"experiment_name\": model_name,\n",
    "    \"study_storage_directory\": config['optuna_storage_directory'],\n",
    "}\n",
    "load_config[\"storage_name\"] = f\"sqlite:///{load_config['study_storage_directory']}/{load_config['experiment_name']}.db\"\n",
    "\n",
    "load_model_and_predict(\n",
    "    study=optuna.load_study(study_name=load_config['experiment_name'], storage=load_config[\"storage_name\"]),\n",
    "    checkpoint_path=f\"lightning_logs/checkpoints/{load_config['experiment_name']}/best_model_{load_config['experiment_name']}.ckpt\",\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ml_packaging_classification_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
