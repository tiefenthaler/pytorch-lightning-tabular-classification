{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERAL THOUGHTS:**  \n",
    "Use AutoML (AutoGluon.Tabular) as a general way to investigate which algorithm, pre-processing, feature engineering options are (well) suited for the given tasks, as well as to investigate the potential performance based on a (large) varity of configurations of those options.\n",
    "The notebook includes multiple scenarios of using AutoML:\n",
    "- including and excluding custom data pre-processing (see below)\n",
    "- including auto pre-processing by AutoGluon.Tabular\n",
    "- including auto feature engineering by AutoGluon.Tabular\n",
    "https://auto.gluon.ai/stable/tutorials/tabular/tabular-feature-engineering.html\n",
    "- including multiple classifiers by using:\n",
    "  - multiple ml algorithms\n",
    "  - \"standard\" HPO for each algorithm defined by AutoGluon.Tabular\n",
    "  - ensables of algorithms (bagging and stacking with possible multiple layers)\n",
    "\n",
    "**CUSTOM DATA PREPROCESSING:**\n",
    "\n",
    "Imbalanced data:\n",
    "- over_sampling for imbalanced data\n",
    "- cost-sensitive learning for imbalanced data\n",
    "\n",
    "numeric data:\n",
    "- data imputation: SimpleImputer(strategy='median')\n",
    "- data scaling: PowerTransformer() using 'log_transform'\n",
    "\n",
    "categorical data:\n",
    "- data imputation: SimpleImputer(strategy='most_frequent')\n",
    "- categorical data encoding: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "\n",
    "**AUTOML MULTI-CLASS CLASSIFIERS:**\n",
    "- Overview of models to be considered using AutoML (AutoGluon.Tabular):  \n",
    "  - [X] RandomForest\n",
    "  - [X] ExtraTrees\n",
    "  - [X] XGBoost\n",
    "  - [X] LightGBM\n",
    "  - [X] KNeighbors\n",
    "  - [X] CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # Import the library to mount Google Drive\n",
    "    from google.colab import drive\n",
    "    # Mount the Google Drive at /content/drive\n",
    "    drive.mount('/content/drive')\n",
    "    # Verify by listing the files in the drive\n",
    "    # !ls /content/drive/My\\ Drive/\n",
    "    # current dir in colab\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install --upgrade autogluon.tabular\n",
    "    !pip install --upgrade mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: if used in google colab, upload env_vars_colab.yml to current google colab directory!\n",
    "\n",
    "# get config\n",
    "if colab:\n",
    "    with open('./env_vars_colab.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "else:\n",
    "    with open('../env_vars.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "# custom imports\n",
    "sys.path.append(config['project_directory'])\n",
    "\n",
    "# from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-13_10:28:02\n"
     ]
    }
   ],
   "source": [
    "# General settings within the data science workflow\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# NOTE: for dev only\n",
    "subsample = False\n",
    "subsample_size = 100  # subsample subset of data for faster demo or development\n",
    "\n",
    "experiment_time_limit = 5*60*60 #3*60*60\n",
    "\n",
    "# Get current date and time\n",
    "now = datetime.datetime.now()\n",
    "formatted_date_time = now.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "print(formatted_date_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{config['data_directory']}/output/df_ml.csv\", sep='\\t')\n",
    "\n",
    "df['material_number'] = df['material_number'].astype('object')\n",
    "\n",
    "df_sub = df[[\n",
    "    'material_number',\n",
    "    'brand',\n",
    "    'product_area',\n",
    "    'core_segment',\n",
    "    'component',\n",
    "    'manufactoring_location',\n",
    "    'characteristic_value',\n",
    "    'material_weight', \n",
    "    'packaging_code',\n",
    "    'packaging_category',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML: without custom pre-processing; restricted selection of models including HPO and model ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df_sub.iloc[:, :-1]\n",
    "y = df_sub.iloc[:, -1]  # the last column is the target\n",
    "\n",
    "# Generate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to AutoML data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(df_train)\n",
    "if subsample is True:\n",
    "    train_data = train_data.sample(n=subsample_size, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 08:20:37,001\tINFO timeout.py:54 -- Reached timeout of 38.87046658198039 seconds. Stopping all trials.\n",
      "2024-11-13 08:20:37,039\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/dat/Library/CloudStorage/GoogleDrive-tiefenthaler.david@googlemail.com/My Drive/GitRepositories/AutomatedPackagingCategories_Showcase/ml_packaging_classification/notebooks/AutogluonModels/ag-20241113_002120/models/NeuralNetTorch_r89_BAG_L2' in 0.0302s.\n",
      "2024-11-13 08:20:47,098\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
      "- eeb4fc55: FileNotFoundError('Could not fetch metrics for eeb4fc55: both result.json and progress.csv were not found at /Users/dat/Library/CloudStorage/GoogleDrive-tiefenthaler.david@googlemail.com/My Drive/GitRepositories/AutomatedPackagingCategories_Showcase/ml_packaging_classification/notebooks/AutogluonModels/ag-20241113_002120/models/NeuralNetTorch_r89_BAG_L2/eeb4fc55')\n",
      "- 36442558: FileNotFoundError('Could not fetch metrics for 36442558: both result.json and progress.csv were not found at /Users/dat/Library/CloudStorage/GoogleDrive-tiefenthaler.david@googlemail.com/My Drive/GitRepositories/AutomatedPackagingCategories_Showcase/ml_packaging_classification/notebooks/AutogluonModels/ag-20241113_002120/models/NeuralNetTorch_r89_BAG_L2/36442558')\n",
      "No model was trained during hyperparameter tuning NeuralNetTorch_r89_BAG_L2... Skipping this model.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 466.44s of the -7179.1s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_r98_BAG_L2': 0.52, 'XGBoost_r194_BAG_L2': 0.2, 'LightGBM_r161_BAG_L2': 0.08, 'ExtraTreesGini_BAG_L2': 0.04, 'LightGBMLarge_BAG_L2': 0.04, 'XGBoost_r49_BAG_L2': 0.04, 'XGBoost_r31_BAG_L2': 0.04, 'XGBoost_r95_BAG_L2': 0.04}\n",
      "\t0.8591\t = Validation score   (f1_macro)\n",
      "\t42.04s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19705.08s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 11.7 rows/s (8297 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241113_002120\")\n"
     ]
    }
   ],
   "source": [
    "label = 'packaging_category'\n",
    "automl_predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    problem_type='multiclass',\n",
    "    eval_metric='f1_macro',\n",
    "    sample_weight='balance_weight'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    tuning_data=None, # If tuning_data = None, fit() will automatically hold out some random validation examples from train_data.\n",
    "    holdout_frac=0.2, # Default value (if None) is selected based on the number of rows in the training data.\n",
    "    time_limit=experiment_time_limit, # 3*60*60\n",
    "    presets=['medium_quality'], # ['high_quality'] # default = ['medium_quality'], any user-specified arguments in fit() will override the values used by presets.\n",
    "    # auto_stack=False, # Whether AutoGluon should automatically utilize bagging and multi-layer stack ensembling to boost predictive accuracy.\n",
    "    # included_model_types=['LR', 'KNN', 'RF', 'XT', 'GBM', 'XGB', 'CAT', 'NN'],\n",
    "    # excluded_model_types=['FASTAI', 'AG_AUTOMM'],\n",
    "    hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified. Searchspaces are provided for some models, but not for all. Where no searchspace is provided, a fixed set of hyper-parameters is defined. (see /searchspace under each model: https://github.com/autogluon/autogluon/tree/master/tabular/src/autogluon/tabular/models).\n",
    "        # 'num_trials': 15, # try at most n different hyperparameter configurations for each type of model\n",
    "        'scheduler' : 'local',\n",
    "        'searcher': 'auto', # ‘auto’: Perform bayesian optimization search on NN_TORCH and FASTAI models. Perform random search on other models.\n",
    "    }  # Refer to TabularPredictor.fit docstring for all valid values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.859076</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1188.566702</td>\n",
       "      <td>6820.678373</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>42.044546</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.819919</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1140.665690</td>\n",
       "      <td>5161.254293</td>\n",
       "      <td>40.693184</td>\n",
       "      <td>80.217303</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees_r126_BAG_L2</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1143.839039</td>\n",
       "      <td>5163.883235</td>\n",
       "      <td>43.866533</td>\n",
       "      <td>82.846245</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_r194_BAG_L2</td>\n",
       "      <td>0.816081</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1103.829203</td>\n",
       "      <td>5284.588265</td>\n",
       "      <td>3.856698</td>\n",
       "      <td>203.551275</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees_r49_BAG_L2</td>\n",
       "      <td>0.813140</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1130.381731</td>\n",
       "      <td>5138.845068</td>\n",
       "      <td>30.409225</td>\n",
       "      <td>57.808078</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>CatBoost_r60_BAG_L2</td>\n",
       "      <td>0.111131</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.568627</td>\n",
       "      <td>5237.745740</td>\n",
       "      <td>1.596121</td>\n",
       "      <td>156.708750</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>CatBoost_r137_BAG_L2</td>\n",
       "      <td>0.086546</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.468116</td>\n",
       "      <td>5202.956067</td>\n",
       "      <td>1.495610</td>\n",
       "      <td>121.919077</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>CatBoost_r50_BAG_L2</td>\n",
       "      <td>0.080389</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.629409</td>\n",
       "      <td>5218.065786</td>\n",
       "      <td>1.656903</td>\n",
       "      <td>137.028796</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>CatBoost_r6_BAG_L2</td>\n",
       "      <td>0.080389</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.632979</td>\n",
       "      <td>5209.795149</td>\n",
       "      <td>1.660473</td>\n",
       "      <td>128.758159</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>CatBoost_r49_BAG_L2</td>\n",
       "      <td>0.067516</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.304781</td>\n",
       "      <td>5197.243922</td>\n",
       "      <td>1.332276</td>\n",
       "      <td>116.206932</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val eval_metric  pred_time_val  \\\n",
       "0       WeightedEnsemble_L3   0.859076    f1_macro    1188.566702   \n",
       "1     ExtraTreesGini_BAG_L2   0.819919    f1_macro    1140.665690   \n",
       "2    ExtraTrees_r126_BAG_L2   0.817493    f1_macro    1143.839039   \n",
       "3       XGBoost_r194_BAG_L2   0.816081    f1_macro    1103.829203   \n",
       "4     ExtraTrees_r49_BAG_L2   0.813140    f1_macro    1130.381731   \n",
       "..                      ...        ...         ...            ...   \n",
       "103     CatBoost_r60_BAG_L2   0.111131    f1_macro    1101.568627   \n",
       "104    CatBoost_r137_BAG_L2   0.086546    f1_macro    1101.468116   \n",
       "105     CatBoost_r50_BAG_L2   0.080389    f1_macro    1101.629409   \n",
       "106      CatBoost_r6_BAG_L2   0.080389    f1_macro    1101.632979   \n",
       "107     CatBoost_r49_BAG_L2   0.067516    f1_macro    1101.304781   \n",
       "\n",
       "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0    6820.678373                0.046121          42.044546            3   \n",
       "1    5161.254293               40.693184          80.217303            2   \n",
       "2    5163.883235               43.866533          82.846245            2   \n",
       "3    5284.588265                3.856698         203.551275            2   \n",
       "4    5138.845068               30.409225          57.808078            2   \n",
       "..           ...                     ...                ...          ...   \n",
       "103  5237.745740                1.596121         156.708750            2   \n",
       "104  5202.956067                1.495610         121.919077            2   \n",
       "105  5218.065786                1.656903         137.028796            2   \n",
       "106  5209.795149                1.660473         128.758159            2   \n",
       "107  5197.243922                1.332276         116.206932            2   \n",
       "\n",
       "     can_infer  fit_order  \n",
       "0         True        108  \n",
       "1         True         64  \n",
       "2         True        103  \n",
       "3         True         77  \n",
       "4         True         87  \n",
       "..         ...        ...  \n",
       "103       True         97  \n",
       "104       True         71  \n",
       "105       True         76  \n",
       "106       True        100  \n",
       "107       True         86  \n",
       "\n",
       "[108 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of models on training data\n",
    "automl_predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate AutoML experiment and best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.795750</td>\n",
       "      <td>0.859076</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>280.823390</td>\n",
       "      <td>1188.566702</td>\n",
       "      <td>6820.678373</td>\n",
       "      <td>0.064283</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>42.044546</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.793289</td>\n",
       "      <td>0.770915</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>232.414696</td>\n",
       "      <td>1102.842265</td>\n",
       "      <td>5402.890837</td>\n",
       "      <td>5.511735</td>\n",
       "      <td>2.869759</td>\n",
       "      <td>321.853848</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees_r49_BAG_L2</td>\n",
       "      <td>0.785937</td>\n",
       "      <td>0.813140</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>228.219033</td>\n",
       "      <td>1130.381731</td>\n",
       "      <td>5138.845068</td>\n",
       "      <td>1.316072</td>\n",
       "      <td>30.409225</td>\n",
       "      <td>57.808078</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.784021</td>\n",
       "      <td>0.819919</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>228.352076</td>\n",
       "      <td>1140.665690</td>\n",
       "      <td>5161.254293</td>\n",
       "      <td>1.449115</td>\n",
       "      <td>40.693184</td>\n",
       "      <td>80.217303</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees_r126_BAG_L2</td>\n",
       "      <td>0.779704</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>228.390524</td>\n",
       "      <td>1143.839039</td>\n",
       "      <td>5163.883235</td>\n",
       "      <td>1.487563</td>\n",
       "      <td>43.866533</td>\n",
       "      <td>82.846245</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_r161_BAG_L2</td>\n",
       "      <td>0.772103</td>\n",
       "      <td>0.758902</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>230.255658</td>\n",
       "      <td>1102.791656</td>\n",
       "      <td>5266.127891</td>\n",
       "      <td>3.352697</td>\n",
       "      <td>2.819150</td>\n",
       "      <td>185.090901</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_r143_BAG_L2</td>\n",
       "      <td>0.771631</td>\n",
       "      <td>0.758595</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>230.610279</td>\n",
       "      <td>1102.714723</td>\n",
       "      <td>5274.867135</td>\n",
       "      <td>3.707318</td>\n",
       "      <td>2.742217</td>\n",
       "      <td>193.830145</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost_r194_BAG_L2</td>\n",
       "      <td>0.769743</td>\n",
       "      <td>0.816081</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>229.520288</td>\n",
       "      <td>1103.829203</td>\n",
       "      <td>5284.588265</td>\n",
       "      <td>2.617327</td>\n",
       "      <td>3.856698</td>\n",
       "      <td>203.551275</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost_r98_BAG_L2</td>\n",
       "      <td>0.767747</td>\n",
       "      <td>0.791508</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>229.617231</td>\n",
       "      <td>1103.124689</td>\n",
       "      <td>5296.424059</td>\n",
       "      <td>2.714270</td>\n",
       "      <td>3.152184</td>\n",
       "      <td>215.387069</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2</td>\n",
       "      <td>0.764335</td>\n",
       "      <td>0.789718</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>229.280277</td>\n",
       "      <td>1170.114186</td>\n",
       "      <td>5202.825697</td>\n",
       "      <td>2.377316</td>\n",
       "      <td>70.141680</td>\n",
       "      <td>121.788707</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0     WeightedEnsemble_L3    0.795750   0.859076    f1_macro      280.823390   \n",
       "1    LightGBMLarge_BAG_L2    0.793289   0.770915    f1_macro      232.414696   \n",
       "2   ExtraTrees_r49_BAG_L2    0.785937   0.813140    f1_macro      228.219033   \n",
       "3   ExtraTreesGini_BAG_L2    0.784021   0.819919    f1_macro      228.352076   \n",
       "4  ExtraTrees_r126_BAG_L2    0.779704   0.817493    f1_macro      228.390524   \n",
       "5    LightGBM_r161_BAG_L2    0.772103   0.758902    f1_macro      230.255658   \n",
       "6    LightGBM_r143_BAG_L2    0.771631   0.758595    f1_macro      230.610279   \n",
       "7     XGBoost_r194_BAG_L2    0.769743   0.816081    f1_macro      229.520288   \n",
       "8      XGBoost_r98_BAG_L2    0.767747   0.791508    f1_macro      229.617231   \n",
       "9   ExtraTreesEntr_BAG_L2    0.764335   0.789718    f1_macro      229.280277   \n",
       "\n",
       "   pred_time_val     fit_time  pred_time_test_marginal  \\\n",
       "0    1188.566702  6820.678373                 0.064283   \n",
       "1    1102.842265  5402.890837                 5.511735   \n",
       "2    1130.381731  5138.845068                 1.316072   \n",
       "3    1140.665690  5161.254293                 1.449115   \n",
       "4    1143.839039  5163.883235                 1.487563   \n",
       "5    1102.791656  5266.127891                 3.352697   \n",
       "6    1102.714723  5274.867135                 3.707318   \n",
       "7    1103.829203  5284.588265                 2.617327   \n",
       "8    1103.124689  5296.424059                 2.714270   \n",
       "9    1170.114186  5202.825697                 2.377316   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.046121          42.044546            3       True   \n",
       "1                2.869759         321.853848            2       True   \n",
       "2               30.409225          57.808078            2       True   \n",
       "3               40.693184          80.217303            2       True   \n",
       "4               43.866533          82.846245            2       True   \n",
       "5                2.819150         185.090901            2       True   \n",
       "6                2.742217         193.830145            2       True   \n",
       "7                3.856698         203.551275            2       True   \n",
       "8                3.152184         215.387069            2       True   \n",
       "9               70.141680         121.788707            2       True   \n",
       "\n",
       "   fit_order  \n",
       "0        108  \n",
       "1         66  \n",
       "2         87  \n",
       "3         64  \n",
       "4        103  \n",
       "5         79  \n",
       "6         88  \n",
       "7         77  \n",
       "8         83  \n",
       "9         65  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of models on test data\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "test_data = TabularDataset(df_test)\n",
    "\n",
    "automl_std_leaderboard_testdata = automl_predictor.leaderboard(test_data)\n",
    "automl_std_leaderboard_testdata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model to be evaluated: WeightedEnsemble_L3\n",
      "Predictions:   ['Blister and Insert Card', 'Corrugated carton', 'Plastic bag with header', 'Tube', 'Shrink film and insert o']\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "   Blister and Insert Card       0.90      0.88      0.89      1749\n",
      "  Blister and sealed blist       0.87      0.83      0.85      1582\n",
      "            Book packaging       0.00      0.00      0.00         2\n",
      "Cardb. Sleeve w - w/o Shr.       0.75      0.71      0.73       135\n",
      "  Cardboard hanger w/o bag       1.00      0.84      0.91        80\n",
      "    Carton cover (Lid box)       0.63      0.63      0.63       130\n",
      "   Carton tube with or w/o       1.00      0.67      0.80         9\n",
      "                      Case       0.72      0.92      0.81        97\n",
      "         Corrugated carton       0.81      0.84      0.82       774\n",
      "        Countertop display       1.00      0.97      0.98        30\n",
      "                  Envelope       0.95      0.98      0.97        59\n",
      "          Fabric packaging       1.00      0.33      0.50         3\n",
      "            Folding carton       0.86      0.82      0.84      1644\n",
      "              Hanger/ Clip       0.95      0.95      0.95      2709\n",
      "            Metal Cassette       0.73      0.80      0.76        10\n",
      "          Paperboard pouch       0.82      0.91      0.86       696\n",
      "               Plastic Box       0.92      0.93      0.93       298\n",
      "          Plastic Cassette       0.89      0.85      0.87       342\n",
      "             Plastic Pouch       0.87      0.85      0.86       381\n",
      "   Plastic bag with header       0.70      0.78      0.74       370\n",
      "  Shrink film and insert o       0.81      0.88      0.84       300\n",
      "                  Skincard       0.81      0.93      0.86       229\n",
      "                 TightPack       0.93      0.91      0.92      1659\n",
      "                 Trap Card       0.99      1.00      0.99       161\n",
      "         Trap Folding Card       0.70      0.94      0.81       438\n",
      "               Tray Packer       0.65      0.92      0.76        86\n",
      "                      Tube       0.95      0.88      0.91      2337\n",
      "                  Unpacked       0.75      0.80      0.77       283\n",
      "                Wooden box       1.00      0.33      0.50         3\n",
      "\n",
      "                  accuracy                           0.88     16596\n",
      "                 macro avg       0.83      0.80      0.80     16596\n",
      "              weighted avg       0.88      0.88      0.88     16596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For a single specified model: make predictions and perform detailed evaluation on hold out test data\n",
    "# i = -1  # index of model to use\n",
    "# model_to_use = automl_predictor.model_names()[i]\n",
    "model_to_use = automl_std_leaderboard_testdata.iloc[0, 0] # use best model from leaderboard\n",
    "print(f\"Model to be evaluated: {model_to_use}\")\n",
    "preds_y_test = automl_predictor.predict(X_test, model=model_to_use)\n",
    "print(\"Predictions:  \", list(preds_y_test)[:5])\n",
    "\n",
    "print(classification_report(y_test, preds_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML: custom pre-processing; restricted selection of models including HPO and model ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define features and target, performe oversampling, split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversmapling\n",
      "{'Hanger/ Clip': 13543, 'Tube': 11687, 'Blister and Insert Card': 8744, 'TightPack': 8296, 'Folding carton': 8219, 'Blister and sealed blist': 7912, 'Corrugated carton': 3872, 'Paperboard pouch': 3478, 'Trap Folding Card': 2188, 'Plastic Pouch': 1904, 'Plastic bag with header': 1850, 'Plastic Cassette': 1708, 'Shrink film and insert o': 1499, 'Plastic Box': 1491, 'Unpacked': 1415, 'Skincard': 1143, 'Trap Card': 804, 'Cardb. Sleeve w - w/o Shr.': 676, 'Carton cover (Lid box)': 652, 'Case': 485, 'Tray Packer': 431, 'Cardboard hanger w/o bag': 400, 'Envelope': 295, 'Countertop display': 150, 'Metal Cassette': 50, 'Carton tube with or w/o': 44, 'Wooden box': 16, 'Fabric packaging': 15, 'Book packaging': 10}\n",
      "Class distribution after oversmapling\n",
      "{'Hanger/ Clip': 13543, 'Tube': 11687, 'Blister and Insert Card': 8744, 'TightPack': 8296, 'Folding carton': 8219, 'Blister and sealed blist': 7912, 'Corrugated carton': 3872, 'Paperboard pouch': 3478, 'Trap Folding Card': 2188, 'Plastic Pouch': 1904, 'Plastic bag with header': 1850, 'Plastic Cassette': 1708, 'Shrink film and insert o': 1499, 'Plastic Box': 1491, 'Unpacked': 1415, 'Skincard': 1143, 'Trap Card': 804, 'Cardb. Sleeve w - w/o Shr.': 676, 'Carton cover (Lid box)': 652, 'Case': 485, 'Tray Packer': 431, 'Cardboard hanger w/o bag': 400, 'Envelope': 295, 'Countertop display': 150, 'Carton tube with or w/o': 100, 'Wooden box': 100, 'Metal Cassette': 100, 'Book packaging': 100, 'Fabric packaging': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "X = df_sub.iloc[:, :-1]\n",
    "y = df_sub.iloc[:, -1]  # the last column is the target\n",
    "\n",
    "# Oversampling\n",
    "distribution_classes = y.value_counts()\n",
    "print('Class distribution before oversmapling')\n",
    "print(distribution_classes.to_dict())\n",
    "# NOTE: Oversampling so each class has at least 100 sample; to properly apply CV and evaluation\n",
    "dict_oversmapling = {\n",
    "    'Metal Cassette': 100,\n",
    "    'Carton tube with or w/o': 100,\n",
    "    'Wooden box': 100,\n",
    "    'Fabric packaging': 100,\n",
    "    'Book packaging': 100\n",
    "}\n",
    "# define oversampling strategy\n",
    "oversampler = RandomOverSampler(sampling_strategy=dict_oversmapling, random_state=SEED)\n",
    "# fit and apply the transform\n",
    "X_oversample, y_oversample = oversampler.fit_resample(X, y)\n",
    "print('Class distribution after oversmapling')\n",
    "print(y_oversample.value_counts().to_dict())\n",
    "\n",
    "# Generate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_oversample, y_oversample, test_size=0.2, stratify=y_oversample,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE & EXECUTE PIPELINE\n",
    "\n",
    "# define feature processing pipeline\n",
    "# define numerical feature processing\n",
    "numerical_features = X_train.select_dtypes(include='number').columns.tolist()\n",
    "# print(f'There are {len(numerical_features)} numerical features:', '\\n')\n",
    "# print(numerical_features)\n",
    "numeric_feature_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('log_transform', PowerTransformer()),\n",
    "    # ('scale', MinMaxScaler())\n",
    "])\n",
    "# define categorical feature processing\n",
    "categorical_features = X_train.select_dtypes(exclude='number').columns.tolist()\n",
    "# print(f'There are {len(categorical_features)} categorical features:', '\\n')\n",
    "# print(categorical_features)\n",
    "categorical_feature_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)),\n",
    "    # ('one_hot', OneHotEncoder(handle_unknown='ignore', max_categories=None, sparse=False))\n",
    "])\n",
    "# apply both pipeline on seperate columns using \"ColumnTransformer\"\n",
    "preprocess_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('number', numeric_feature_pipeline, numerical_features),\n",
    "        ('category', categorical_feature_pipeline, categorical_features)\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform=\"pandas\")\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)\n",
    "\n",
    "# encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_transformed = label_encoder.fit_transform(y_train)\n",
    "y_train_transformed = pd.Series(data=y_train_transformed, index=y_train.index, name=y_train.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to AutoML data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train_transformed, y_train_transformed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(df_train)\n",
    "if subsample is True:\n",
    "    train_data = train_data.sample(n=subsample_size, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.6.0: Thu Sep  5 20:48:48 PDT 2024; root:xnu-8796.141.3.708.1~1/RELEASE_X86_64\n",
      "CPU Count:          4\n",
      "Memory Avail:       6.62 GB / 16.00 GB (41.4%)\n",
      "Disk Space Avail:   274.54 GB / 465.63 GB (59.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 4500s of the 18000s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20241113_073313/ds_sub_fit/sub_fit_ho\"\n"
     ]
    }
   ],
   "source": [
    "label = 'packaging_category'\n",
    "automl_predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    problem_type='multiclass',\n",
    "    eval_metric='f1_macro',\n",
    "    sample_weight='balance_weight'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    tuning_data=None, # If tuning_data = None, fit() will automatically hold out some random validation examples from train_data.\n",
    "    holdout_frac=0.2, # Default value (if None) is selected based on the number of rows in the training data.\n",
    "    time_limit=experiment_time_limit, # 3*60*60\n",
    "    presets=['medium_quality'], # ['high_quality'] # default = ['medium_quality'], any user-specified arguments in fit() will override the values used by presets.\n",
    "    # auto_stack=False, # Whether AutoGluon should automatically utilize bagging and multi-layer stack ensembling to boost predictive accuracy.\n",
    "    # included_model_types=['LR', 'KNN', 'RF', 'XT', 'GBM', 'XGB', 'CAT', 'NN'], \n",
    "    # excluded_model_types=['FASTAI', 'AG_AUTOMM'],\n",
    "    hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified. Searchspaces are provided for some models, but not for all. Where no searchspace is provided, a fixed set of hyper-parameters is defined. (see /searchspace under each model: https://github.com/autogluon/autogluon/tree/master/tabular/src/autogluon/tabular/models).\n",
    "        # 'num_trials': 15, # try at most n different hyperparameter configurations for each type of model\n",
    "        'scheduler' : 'local',\n",
    "        'searcher': 'auto', # ‘auto’: Perform bayesian optimization search on NN_TORCH and FASTAI models. Perform random search on other models.\n",
    "    }  # Refer to TabularPredictor.fit docstring for all valid values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.859076</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1188.566702</td>\n",
       "      <td>6820.678373</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>42.044546</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.819919</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1140.665690</td>\n",
       "      <td>5161.254293</td>\n",
       "      <td>40.693184</td>\n",
       "      <td>80.217303</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees_r126_BAG_L2</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1143.839039</td>\n",
       "      <td>5163.883235</td>\n",
       "      <td>43.866533</td>\n",
       "      <td>82.846245</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_r194_BAG_L2</td>\n",
       "      <td>0.816081</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1103.829203</td>\n",
       "      <td>5284.588265</td>\n",
       "      <td>3.856698</td>\n",
       "      <td>203.551275</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees_r49_BAG_L2</td>\n",
       "      <td>0.813140</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1130.381731</td>\n",
       "      <td>5138.845068</td>\n",
       "      <td>30.409225</td>\n",
       "      <td>57.808078</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>CatBoost_r60_BAG_L2</td>\n",
       "      <td>0.111131</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.568627</td>\n",
       "      <td>5237.745740</td>\n",
       "      <td>1.596121</td>\n",
       "      <td>156.708750</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>CatBoost_r137_BAG_L2</td>\n",
       "      <td>0.086546</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.468116</td>\n",
       "      <td>5202.956067</td>\n",
       "      <td>1.495610</td>\n",
       "      <td>121.919077</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>CatBoost_r50_BAG_L2</td>\n",
       "      <td>0.080389</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.629409</td>\n",
       "      <td>5218.065786</td>\n",
       "      <td>1.656903</td>\n",
       "      <td>137.028796</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>CatBoost_r6_BAG_L2</td>\n",
       "      <td>0.080389</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.632979</td>\n",
       "      <td>5209.795149</td>\n",
       "      <td>1.660473</td>\n",
       "      <td>128.758159</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>CatBoost_r49_BAG_L2</td>\n",
       "      <td>0.067516</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.304781</td>\n",
       "      <td>5197.243922</td>\n",
       "      <td>1.332276</td>\n",
       "      <td>116.206932</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val eval_metric  pred_time_val  \\\n",
       "0       WeightedEnsemble_L3   0.859076    f1_macro    1188.566702   \n",
       "1     ExtraTreesGini_BAG_L2   0.819919    f1_macro    1140.665690   \n",
       "2    ExtraTrees_r126_BAG_L2   0.817493    f1_macro    1143.839039   \n",
       "3       XGBoost_r194_BAG_L2   0.816081    f1_macro    1103.829203   \n",
       "4     ExtraTrees_r49_BAG_L2   0.813140    f1_macro    1130.381731   \n",
       "..                      ...        ...         ...            ...   \n",
       "103     CatBoost_r60_BAG_L2   0.111131    f1_macro    1101.568627   \n",
       "104    CatBoost_r137_BAG_L2   0.086546    f1_macro    1101.468116   \n",
       "105     CatBoost_r50_BAG_L2   0.080389    f1_macro    1101.629409   \n",
       "106      CatBoost_r6_BAG_L2   0.080389    f1_macro    1101.632979   \n",
       "107     CatBoost_r49_BAG_L2   0.067516    f1_macro    1101.304781   \n",
       "\n",
       "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0    6820.678373                0.046121          42.044546            3   \n",
       "1    5161.254293               40.693184          80.217303            2   \n",
       "2    5163.883235               43.866533          82.846245            2   \n",
       "3    5284.588265                3.856698         203.551275            2   \n",
       "4    5138.845068               30.409225          57.808078            2   \n",
       "..           ...                     ...                ...          ...   \n",
       "103  5237.745740                1.596121         156.708750            2   \n",
       "104  5202.956067                1.495610         121.919077            2   \n",
       "105  5218.065786                1.656903         137.028796            2   \n",
       "106  5209.795149                1.660473         128.758159            2   \n",
       "107  5197.243922                1.332276         116.206932            2   \n",
       "\n",
       "     can_infer  fit_order  \n",
       "0         True        108  \n",
       "1         True         64  \n",
       "2         True        103  \n",
       "3         True         77  \n",
       "4         True         87  \n",
       "..         ...        ...  \n",
       "103       True         97  \n",
       "104       True         71  \n",
       "105       True         76  \n",
       "106       True        100  \n",
       "107       True         86  \n",
       "\n",
       "[108 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of models on training data\n",
    "automl_predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate AutoML experiment and best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of models on test data\n",
    "\n",
    "# NOTE: Load a TabularPredictor object previously produced by fit() from file and returns this object.\n",
    "try:\n",
    "    # NOTE: set the directory to the saved model\n",
    "    specific_path = 'AutogluonModels/ag-20241113_002120' # Default: None ; Path fromat: 'AutogluonModels/ag-20241113_002120'\n",
    "    autogluon_saved_model_path = specific_path if specific_path else automl_predictor.path\n",
    "    automl_predictor = TabularPredictor.load(f\"{config['autogluon_exp_storage_directory']}/{autogluon_saved_model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Model could not be loaded. An error occurred: {e}\")\n",
    "\n",
    "# process X_test for evaluation and predictions\n",
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "# evaluate models on test data\n",
    "y_test_transformed = label_encoder.transform(y_test)\n",
    "y_test_transformed = pd.Series(data=y_test_transformed, index=y_test.index, name=y_test.name)\n",
    "df_test = pd.concat([X_test_transformed, y_test_transformed], axis=1)\n",
    "test_data = TabularDataset(df_test)\n",
    "\n",
    "automl_custom_leaderboard_testdata = automl_predictor.leaderboard(test_data)\n",
    "automl_custom_leaderboard_testdata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model to be evaluated: WeightedEnsemble_L2\n",
      "Predictions:   [3, 0, 5, 26, 26]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "   Blister and Insert Card       0.41      0.38      0.40      1749\n",
      "  Blister and sealed blist       0.40      0.42      0.41      1582\n",
      "            Book packaging       0.00      0.00      0.00        20\n",
      "Cardb. Sleeve w - w/o Shr.       0.02      0.06      0.03       135\n",
      "  Cardboard hanger w/o bag       0.00      0.00      0.00        80\n",
      "    Carton cover (Lid box)       0.01      0.02      0.01       130\n",
      "   Carton tube with or w/o       0.00      0.00      0.00        20\n",
      "                      Case       0.00      0.00      0.00        97\n",
      "         Corrugated carton       0.31      0.66      0.42       774\n",
      "        Countertop display       0.00      0.00      0.00        30\n",
      "                  Envelope       0.00      0.00      0.00        59\n",
      "          Fabric packaging       0.00      0.00      0.00        20\n",
      "            Folding carton       0.32      0.22      0.26      1644\n",
      "              Hanger/ Clip       0.58      0.45      0.51      2709\n",
      "            Metal Cassette       0.00      0.00      0.00        20\n",
      "          Paperboard pouch       0.40      0.18      0.24       696\n",
      "               Plastic Box       0.00      0.00      0.00       298\n",
      "          Plastic Cassette       0.08      0.08      0.08       342\n",
      "             Plastic Pouch       0.04      0.07      0.05       381\n",
      "   Plastic bag with header       0.12      0.31      0.18       370\n",
      "  Shrink film and insert o       0.00      0.00      0.00       300\n",
      "                  Skincard       0.16      0.29      0.20       229\n",
      "                 TightPack       0.66      0.58      0.62      1659\n",
      "                 Trap Card       0.00      0.00      0.00       161\n",
      "         Trap Folding Card       0.60      0.38      0.46       438\n",
      "               Tray Packer       0.00      0.00      0.00        86\n",
      "                      Tube       0.35      0.51      0.41      2337\n",
      "                  Unpacked       0.00      0.00      0.00       283\n",
      "                Wooden box       0.00      0.00      0.00        20\n",
      "\n",
      "                  accuracy                           0.37     16669\n",
      "                 macro avg       0.15      0.16      0.15     16669\n",
      "              weighted avg       0.38      0.37      0.36     16669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For a single specified model: make predictions and perform detailed evaluation on hold out test data\n",
    "# i = -1  # index of model to use\n",
    "# model_to_use = automl_predictor.model_names()[i]\n",
    "# model_to_use = automl_custom_leaderboard_testdata.iloc[0, 0] # use best model from leaderboard\n",
    "model_to_use = automl_predictor.model_best\n",
    "print(f\"Model to be evaluated: {model_to_use}\")\n",
    "preds_y_test = automl_predictor.predict(X_test_transformed, model=model_to_use)\n",
    "print(\"Predictions:  \", list(preds_y_test)[:5])\n",
    "\n",
    "preds_y_test_inverse = label_encoder.inverse_transform(preds_y_test)\n",
    "\n",
    "# print classification report for holdout test data\n",
    "print(classification_report(y_test, preds_y_test_inverse))\n",
    "report = classification_report(y_test, preds_y_test_inverse, output_dict=True)\n",
    "f1_score = report['accuracy']\n",
    "f1_macro = report['macro avg']['f1-score']\n",
    "\n",
    "# get best model parameters\n",
    "trainer = automl_predictor._trainer\n",
    "best_model = trainer.load_model(trainer.model_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track performance using MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Change to a meaningful name\n",
    "EXPERIMENT_NAME = \"AutoPackagingCategories\"\n",
    "RUN_NAME = \"run_AutoML_AutoGluonTabular\"\n",
    "\n",
    "with open('../env_vars.yml', 'r') as file:\n",
    "    env_vars = yaml.safe_load(file)\n",
    "\n",
    "project_dir = env_vars['project_directory']\n",
    "os.makedirs(project_dir + '/mlruns', exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(\"file://\" + project_dir + \"/mlruns\")\n",
    "\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    EXPERIMENT_ID = experiment.experiment_id\n",
    "except AttributeError:\n",
    "    EXPERIMENT_ID = mlflow.create_experiment(\n",
    "        EXPERIMENT_NAME,\n",
    "        # mlflow.set_artifact_uri(\"file://\" + project_dir + \"/artifacts/\")\n",
    "    )\n",
    "\n",
    "current_time = datetime.datetime.now()\n",
    "time_stamp = str(current_time)\n",
    "# NOTE: Change to a meaningful name for the single trial\n",
    "# exp_run_name = f\"run_MeaningfulTrialName_{time_stamp}\"\n",
    "exp_run_name = f\"{RUN_NAME}_{time_stamp}\"\n",
    "\n",
    "# Start MLflow\n",
    "with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=exp_run_name) as run:\n",
    "\n",
    "    # Retrieve run id\n",
    "    RUN_ID = run.info.run_id\n",
    "\n",
    "    # Track parameters\n",
    "    # track pipeline configs: preprocessing_pipeline\n",
    "    mlflow.log_dict(\n",
    "        {'oversampler': type(oversampler), 'label_encoder': type(label_encoder)} | preprocess_pipeline.named_transformers_,\n",
    "        \"preprocessing_pipeline.json\"\n",
    "    )\n",
    "\n",
    "    # mode specfic parameters\n",
    "    mlflow.log_param('model', f'{type(best_model)}: {best_model.base_model_names}')\n",
    "    mlflow.log_param('model_configs', best_model.get_trained_params())\n",
    "    \n",
    "    # mode specfic parameters\n",
    "    \n",
    "    # Track metrics\n",
    "    # mlflow.log_metric(\"Train_f1_macro\", train_f1_macro)\n",
    "    # mlflow.log_metric(\"TestVal_f1_macro\", test_f1_macro)\n",
    "    mlflow.log_dict(report, \"classification_report.json\")\n",
    "    mlflow.log_metric(\"Report_Test_f1_score\", f1_score)\n",
    "    mlflow.log_metric(\"Report_Test_f1_macro\", f1_macro)\n",
    "\n",
    "    # Track model\n",
    "    # mlflow.sklearn.log_model(clf, \"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ml_packaging_classification_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
