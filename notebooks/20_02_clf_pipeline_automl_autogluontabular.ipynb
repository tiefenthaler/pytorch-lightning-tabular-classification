{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERAL THOUGHTS:**  \n",
    "Use AutoML (AutoGluon.Tabular) as a general way to investigate which algorithm, pre-processing, feature engineering options are (well) suited for the given tasks, as well as to investigate the potential performance based on a (large) varity of configurations of those options.\n",
    "The notebook includes multiple scenarios of using AutoML:\n",
    "- including and excluding custom data pre-processing (see below)\n",
    "- including auto pre-processing by AutoGluon.Tabular\n",
    "- including auto feature engineering by AutoGluon.Tabular\n",
    "https://auto.gluon.ai/stable/tutorials/tabular/tabular-feature-engineering.html\n",
    "- including multiple classifiers by using:\n",
    "  - multiple ml algorithms\n",
    "  - \"standard\" HPO for each algorithm defined by AutoGluon.Tabular\n",
    "  - ensables of algorithms (bagging and stacking with possible multiple layers)\n",
    "\n",
    "**DATA PREPROCESSING:**  \n",
    "Imbalanced data:\n",
    "- over_sampling for imbalanced data.\n",
    "- cost-sensitive learning for imbalanced data.\n",
    "\n",
    "continuous data:\n",
    "- Impute missing data: SimpleImputer(strategy='median').\n",
    "- Standardize data: StandardScaler().\n",
    "\n",
    "categorical data:\n",
    "- Impute missing data: SimpleImputer(strategy='most_frequent').\n",
    "- Ordinal & Nominal data encoding: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1).\n",
    "- Unknown values ecoding and reordering of ordinal encoding: custom encoder \"OrdinalEncoderExtensionUnknowns()\".\n",
    "\n",
    "target data:\n",
    "- target encoding: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "**AUTOML MULTI-CLASS CLASSIFIERS:**\n",
    "- Overview of models to be considered using AutoML (AutoGluon.Tabular):  \n",
    "  - [X] RandomForest\n",
    "  - [X] ExtraTrees\n",
    "  - [X] XGBoost\n",
    "  - [X] LightGBM\n",
    "  - [X] KNeighbors\n",
    "  - [X] CatBoost\n",
    "  - [X] Multiple Neural Nets\n",
    "\n",
    "**FINAL MODEL PERFORMANCE:**  \n",
    "- Evaluation of the best model from AutoML, including Experiment checkpointing.\n",
    "- Loading final model from checkpoint for prediction on test set for evaluation based on classification report\n",
    "- Tracking of the best model with MLFlow for performance benchmarking with other approaches (Baseline, PyCaret, PyTorch, ...) within the Repository.\n",
    "\n",
    "**Configurations for running the notebook**  \n",
    "Set the following configurations befor running the notebook under the section [OVERVIEW](#overview):\n",
    "- Infrastructure to run the notebook on: local, colab, cloud (azure)\n",
    "- Provide related directory config.yml file for your infrastructure:\n",
    "  - project_directory\n",
    "  - data_directory (source data)\n",
    "  - optuna_storage_directory\n",
    "  - pycaret_exp_storage_directory\n",
    "  - autogluon_exp_storage_directory\n",
    "- General settings for experiments (SEED, time_limit, data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "compute: Literal[None, \"colab\", \"azure\"] = \"colab\" # Dafault None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute == \"colab\":\n",
    "    # Import the library to mount Google Drive\n",
    "    from google.colab import drive\n",
    "    # Mount the Google Drive at /content/drive\n",
    "    drive.mount('/content/drive')\n",
    "    # Verify by listing the files in the drive\n",
    "    # !ls /content/drive/My\\ Drive/\n",
    "    # current dir in colab\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute == \"colab\":\n",
    "    !pip install --upgrade autogluon.tabular\n",
    "    !pip install --upgrade mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get config\n",
    "if compute == \"colab\":\n",
    "    # NOTE: if used in Google Colab, upload env_vars_colab.yml to the current Google Colab directory.\n",
    "    try:\n",
    "        with open('./env_vars_colab.yml', 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: './env_vars_colab.yml' not found. Please upload it to the current Google Colab directory.\")\n",
    "\n",
    "elif compute == \"azure\":\n",
    "    try:\n",
    "        with open('../env_vars_azureml_compute.yml', 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: '../env_vars_azureml_compute.yml' not found.\")\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        with open('../env_vars.yml', 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: '../env_vars.yml' not found.\")\n",
    "\n",
    "# custom imports of local modules\n",
    "sys.path.append(config['project_directory'])\n",
    "\n",
    "# from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-13_23:49:28\n"
     ]
    }
   ],
   "source": [
    "# General settings within the data science workflow\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# NOTE: for dev only\n",
    "subsample = False\n",
    "subsample_size = 100  # subsample subset of data for faster demo or development\n",
    "\n",
    "experiment_time_limit = 8*60*60 #3*60*60\n",
    "\n",
    "# Get current date and time\n",
    "now = datetime.datetime.now()\n",
    "formatted_date_time = now.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "print(formatted_date_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{config['data_directory']}/output/df_ml.csv\", sep='\\t')\n",
    "\n",
    "df['material_number'] = df['material_number'].astype('object')\n",
    "\n",
    "df_sub = df[[\n",
    "    'material_number',\n",
    "    'brand',\n",
    "    'product_area',\n",
    "    'core_segment',\n",
    "    'component',\n",
    "    'manufactoring_location',\n",
    "    'characteristic_value',\n",
    "    'material_weight', \n",
    "    'packaging_code',\n",
    "    'packaging_category',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML: without custom pre-processing; restricted selection of models including HPO and model ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df_sub.iloc[:, :-1]\n",
    "y = df_sub.iloc[:, -1]  # the last column is the target\n",
    "\n",
    "# Generate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to AutoML data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(df_train)\n",
    "if subsample is True:\n",
    "    train_data = train_data.sample(n=subsample_size, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 08:20:37,001\tINFO timeout.py:54 -- Reached timeout of 38.87046658198039 seconds. Stopping all trials.\n",
      "2024-11-13 08:20:37,039\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/dat/Library/CloudStorage/GoogleDrive-tiefenthaler.david@googlemail.com/My Drive/GitRepositories/AutomatedPackagingCategories_Showcase/ml_packaging_classification/notebooks/AutogluonModels/ag-20241113_002120/models/NeuralNetTorch_r89_BAG_L2' in 0.0302s.\n",
      "2024-11-13 08:20:47,098\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
      "- eeb4fc55: FileNotFoundError('Could not fetch metrics for eeb4fc55: both result.json and progress.csv were not found at /Users/dat/Library/CloudStorage/GoogleDrive-tiefenthaler.david@googlemail.com/My Drive/GitRepositories/AutomatedPackagingCategories_Showcase/ml_packaging_classification/notebooks/AutogluonModels/ag-20241113_002120/models/NeuralNetTorch_r89_BAG_L2/eeb4fc55')\n",
      "- 36442558: FileNotFoundError('Could not fetch metrics for 36442558: both result.json and progress.csv were not found at /Users/dat/Library/CloudStorage/GoogleDrive-tiefenthaler.david@googlemail.com/My Drive/GitRepositories/AutomatedPackagingCategories_Showcase/ml_packaging_classification/notebooks/AutogluonModels/ag-20241113_002120/models/NeuralNetTorch_r89_BAG_L2/36442558')\n",
      "No model was trained during hyperparameter tuning NeuralNetTorch_r89_BAG_L2... Skipping this model.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 466.44s of the -7179.1s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_r98_BAG_L2': 0.52, 'XGBoost_r194_BAG_L2': 0.2, 'LightGBM_r161_BAG_L2': 0.08, 'ExtraTreesGini_BAG_L2': 0.04, 'LightGBMLarge_BAG_L2': 0.04, 'XGBoost_r49_BAG_L2': 0.04, 'XGBoost_r31_BAG_L2': 0.04, 'XGBoost_r95_BAG_L2': 0.04}\n",
      "\t0.8591\t = Validation score   (f1_macro)\n",
      "\t42.04s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19705.08s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 11.7 rows/s (8297 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241113_002120\")\n"
     ]
    }
   ],
   "source": [
    "label = 'packaging_category'\n",
    "automl_predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    problem_type='multiclass',\n",
    "    eval_metric='f1_macro',\n",
    "    sample_weight='balance_weight'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    tuning_data=None, # If tuning_data = None, fit() will automatically hold out some random validation examples from train_data.\n",
    "    holdout_frac=0.2, # Default value (if None) is selected based on the number of rows in the training data.\n",
    "    time_limit=experiment_time_limit, # 3*60*60\n",
    "    presets=['high_quality'], # ['high_quality'] # default = ['medium_quality'], any user-specified arguments in fit() will override the values used by presets.\n",
    "    # auto_stack=False, # Whether AutoGluon should automatically utilize bagging and multi-layer stack ensembling to boost predictive accuracy.\n",
    "    # included_model_types=['LR', 'KNN', 'RF', 'XT', 'GBM', 'XGB', 'CAT', 'NN'],\n",
    "    # excluded_model_types=['FASTAI', 'AG_AUTOMM'],\n",
    "    hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified. Searchspaces are provided for some models, but not for all. Where no searchspace is provided, a fixed set of hyper-parameters is defined. (see /searchspace under each model: https://github.com/autogluon/autogluon/tree/master/tabular/src/autogluon/tabular/models).\n",
    "        # 'num_trials': 15, # try at most n different hyperparameter configurations for each type of model\n",
    "        'scheduler' : 'local',\n",
    "        'searcher': 'auto', # ‘auto’: Perform bayesian optimization search on NN_TORCH and FASTAI models. Perform random search on other models.\n",
    "    }  # Refer to TabularPredictor.fit docstring for all valid values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.859076</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1188.566702</td>\n",
       "      <td>6820.678373</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>42.044546</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.819919</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1140.665690</td>\n",
       "      <td>5161.254293</td>\n",
       "      <td>40.693184</td>\n",
       "      <td>80.217303</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees_r126_BAG_L2</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1143.839039</td>\n",
       "      <td>5163.883235</td>\n",
       "      <td>43.866533</td>\n",
       "      <td>82.846245</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_r194_BAG_L2</td>\n",
       "      <td>0.816081</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1103.829203</td>\n",
       "      <td>5284.588265</td>\n",
       "      <td>3.856698</td>\n",
       "      <td>203.551275</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees_r49_BAG_L2</td>\n",
       "      <td>0.813140</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1130.381731</td>\n",
       "      <td>5138.845068</td>\n",
       "      <td>30.409225</td>\n",
       "      <td>57.808078</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>CatBoost_r60_BAG_L2</td>\n",
       "      <td>0.111131</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.568627</td>\n",
       "      <td>5237.745740</td>\n",
       "      <td>1.596121</td>\n",
       "      <td>156.708750</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>CatBoost_r137_BAG_L2</td>\n",
       "      <td>0.086546</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.468116</td>\n",
       "      <td>5202.956067</td>\n",
       "      <td>1.495610</td>\n",
       "      <td>121.919077</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>CatBoost_r50_BAG_L2</td>\n",
       "      <td>0.080389</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.629409</td>\n",
       "      <td>5218.065786</td>\n",
       "      <td>1.656903</td>\n",
       "      <td>137.028796</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>CatBoost_r6_BAG_L2</td>\n",
       "      <td>0.080389</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.632979</td>\n",
       "      <td>5209.795149</td>\n",
       "      <td>1.660473</td>\n",
       "      <td>128.758159</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>CatBoost_r49_BAG_L2</td>\n",
       "      <td>0.067516</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.304781</td>\n",
       "      <td>5197.243922</td>\n",
       "      <td>1.332276</td>\n",
       "      <td>116.206932</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val eval_metric  pred_time_val  \\\n",
       "0       WeightedEnsemble_L3   0.859076    f1_macro    1188.566702   \n",
       "1     ExtraTreesGini_BAG_L2   0.819919    f1_macro    1140.665690   \n",
       "2    ExtraTrees_r126_BAG_L2   0.817493    f1_macro    1143.839039   \n",
       "3       XGBoost_r194_BAG_L2   0.816081    f1_macro    1103.829203   \n",
       "4     ExtraTrees_r49_BAG_L2   0.813140    f1_macro    1130.381731   \n",
       "..                      ...        ...         ...            ...   \n",
       "103     CatBoost_r60_BAG_L2   0.111131    f1_macro    1101.568627   \n",
       "104    CatBoost_r137_BAG_L2   0.086546    f1_macro    1101.468116   \n",
       "105     CatBoost_r50_BAG_L2   0.080389    f1_macro    1101.629409   \n",
       "106      CatBoost_r6_BAG_L2   0.080389    f1_macro    1101.632979   \n",
       "107     CatBoost_r49_BAG_L2   0.067516    f1_macro    1101.304781   \n",
       "\n",
       "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0    6820.678373                0.046121          42.044546            3   \n",
       "1    5161.254293               40.693184          80.217303            2   \n",
       "2    5163.883235               43.866533          82.846245            2   \n",
       "3    5284.588265                3.856698         203.551275            2   \n",
       "4    5138.845068               30.409225          57.808078            2   \n",
       "..           ...                     ...                ...          ...   \n",
       "103  5237.745740                1.596121         156.708750            2   \n",
       "104  5202.956067                1.495610         121.919077            2   \n",
       "105  5218.065786                1.656903         137.028796            2   \n",
       "106  5209.795149                1.660473         128.758159            2   \n",
       "107  5197.243922                1.332276         116.206932            2   \n",
       "\n",
       "     can_infer  fit_order  \n",
       "0         True        108  \n",
       "1         True         64  \n",
       "2         True        103  \n",
       "3         True         77  \n",
       "4         True         87  \n",
       "..         ...        ...  \n",
       "103       True         97  \n",
       "104       True         71  \n",
       "105       True         76  \n",
       "106       True        100  \n",
       "107       True         86  \n",
       "\n",
       "[108 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of models on training data\n",
    "automl_predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate AutoML experiment and best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.795750</td>\n",
       "      <td>0.859076</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>280.823390</td>\n",
       "      <td>1188.566702</td>\n",
       "      <td>6820.678373</td>\n",
       "      <td>0.064283</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>42.044546</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.793289</td>\n",
       "      <td>0.770915</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>232.414696</td>\n",
       "      <td>1102.842265</td>\n",
       "      <td>5402.890837</td>\n",
       "      <td>5.511735</td>\n",
       "      <td>2.869759</td>\n",
       "      <td>321.853848</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees_r49_BAG_L2</td>\n",
       "      <td>0.785937</td>\n",
       "      <td>0.813140</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>228.219033</td>\n",
       "      <td>1130.381731</td>\n",
       "      <td>5138.845068</td>\n",
       "      <td>1.316072</td>\n",
       "      <td>30.409225</td>\n",
       "      <td>57.808078</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.784021</td>\n",
       "      <td>0.819919</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>228.352076</td>\n",
       "      <td>1140.665690</td>\n",
       "      <td>5161.254293</td>\n",
       "      <td>1.449115</td>\n",
       "      <td>40.693184</td>\n",
       "      <td>80.217303</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees_r126_BAG_L2</td>\n",
       "      <td>0.779704</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>228.390524</td>\n",
       "      <td>1143.839039</td>\n",
       "      <td>5163.883235</td>\n",
       "      <td>1.487563</td>\n",
       "      <td>43.866533</td>\n",
       "      <td>82.846245</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_r161_BAG_L2</td>\n",
       "      <td>0.772103</td>\n",
       "      <td>0.758902</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>230.255658</td>\n",
       "      <td>1102.791656</td>\n",
       "      <td>5266.127891</td>\n",
       "      <td>3.352697</td>\n",
       "      <td>2.819150</td>\n",
       "      <td>185.090901</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_r143_BAG_L2</td>\n",
       "      <td>0.771631</td>\n",
       "      <td>0.758595</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>230.610279</td>\n",
       "      <td>1102.714723</td>\n",
       "      <td>5274.867135</td>\n",
       "      <td>3.707318</td>\n",
       "      <td>2.742217</td>\n",
       "      <td>193.830145</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost_r194_BAG_L2</td>\n",
       "      <td>0.769743</td>\n",
       "      <td>0.816081</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>229.520288</td>\n",
       "      <td>1103.829203</td>\n",
       "      <td>5284.588265</td>\n",
       "      <td>2.617327</td>\n",
       "      <td>3.856698</td>\n",
       "      <td>203.551275</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost_r98_BAG_L2</td>\n",
       "      <td>0.767747</td>\n",
       "      <td>0.791508</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>229.617231</td>\n",
       "      <td>1103.124689</td>\n",
       "      <td>5296.424059</td>\n",
       "      <td>2.714270</td>\n",
       "      <td>3.152184</td>\n",
       "      <td>215.387069</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2</td>\n",
       "      <td>0.764335</td>\n",
       "      <td>0.789718</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>229.280277</td>\n",
       "      <td>1170.114186</td>\n",
       "      <td>5202.825697</td>\n",
       "      <td>2.377316</td>\n",
       "      <td>70.141680</td>\n",
       "      <td>121.788707</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0     WeightedEnsemble_L3    0.795750   0.859076    f1_macro      280.823390   \n",
       "1    LightGBMLarge_BAG_L2    0.793289   0.770915    f1_macro      232.414696   \n",
       "2   ExtraTrees_r49_BAG_L2    0.785937   0.813140    f1_macro      228.219033   \n",
       "3   ExtraTreesGini_BAG_L2    0.784021   0.819919    f1_macro      228.352076   \n",
       "4  ExtraTrees_r126_BAG_L2    0.779704   0.817493    f1_macro      228.390524   \n",
       "5    LightGBM_r161_BAG_L2    0.772103   0.758902    f1_macro      230.255658   \n",
       "6    LightGBM_r143_BAG_L2    0.771631   0.758595    f1_macro      230.610279   \n",
       "7     XGBoost_r194_BAG_L2    0.769743   0.816081    f1_macro      229.520288   \n",
       "8      XGBoost_r98_BAG_L2    0.767747   0.791508    f1_macro      229.617231   \n",
       "9   ExtraTreesEntr_BAG_L2    0.764335   0.789718    f1_macro      229.280277   \n",
       "\n",
       "   pred_time_val     fit_time  pred_time_test_marginal  \\\n",
       "0    1188.566702  6820.678373                 0.064283   \n",
       "1    1102.842265  5402.890837                 5.511735   \n",
       "2    1130.381731  5138.845068                 1.316072   \n",
       "3    1140.665690  5161.254293                 1.449115   \n",
       "4    1143.839039  5163.883235                 1.487563   \n",
       "5    1102.791656  5266.127891                 3.352697   \n",
       "6    1102.714723  5274.867135                 3.707318   \n",
       "7    1103.829203  5284.588265                 2.617327   \n",
       "8    1103.124689  5296.424059                 2.714270   \n",
       "9    1170.114186  5202.825697                 2.377316   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.046121          42.044546            3       True   \n",
       "1                2.869759         321.853848            2       True   \n",
       "2               30.409225          57.808078            2       True   \n",
       "3               40.693184          80.217303            2       True   \n",
       "4               43.866533          82.846245            2       True   \n",
       "5                2.819150         185.090901            2       True   \n",
       "6                2.742217         193.830145            2       True   \n",
       "7                3.856698         203.551275            2       True   \n",
       "8                3.152184         215.387069            2       True   \n",
       "9               70.141680         121.788707            2       True   \n",
       "\n",
       "   fit_order  \n",
       "0        108  \n",
       "1         66  \n",
       "2         87  \n",
       "3         64  \n",
       "4        103  \n",
       "5         79  \n",
       "6         88  \n",
       "7         77  \n",
       "8         83  \n",
       "9         65  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of models on test data\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "test_data = TabularDataset(df_test)\n",
    "\n",
    "automl_std_leaderboard_testdata = automl_predictor.leaderboard(test_data)\n",
    "automl_std_leaderboard_testdata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model to be evaluated: WeightedEnsemble_L3\n",
      "Predictions:   ['Blister and Insert Card', 'Corrugated carton', 'Plastic bag with header', 'Tube', 'Shrink film and insert o']\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "   Blister and Insert Card       0.90      0.88      0.89      1749\n",
      "  Blister and sealed blist       0.87      0.83      0.85      1582\n",
      "            Book packaging       0.00      0.00      0.00         2\n",
      "Cardb. Sleeve w - w/o Shr.       0.75      0.71      0.73       135\n",
      "  Cardboard hanger w/o bag       1.00      0.84      0.91        80\n",
      "    Carton cover (Lid box)       0.63      0.63      0.63       130\n",
      "   Carton tube with or w/o       1.00      0.67      0.80         9\n",
      "                      Case       0.72      0.92      0.81        97\n",
      "         Corrugated carton       0.81      0.84      0.82       774\n",
      "        Countertop display       1.00      0.97      0.98        30\n",
      "                  Envelope       0.95      0.98      0.97        59\n",
      "          Fabric packaging       1.00      0.33      0.50         3\n",
      "            Folding carton       0.86      0.82      0.84      1644\n",
      "              Hanger/ Clip       0.95      0.95      0.95      2709\n",
      "            Metal Cassette       0.73      0.80      0.76        10\n",
      "          Paperboard pouch       0.82      0.91      0.86       696\n",
      "               Plastic Box       0.92      0.93      0.93       298\n",
      "          Plastic Cassette       0.89      0.85      0.87       342\n",
      "             Plastic Pouch       0.87      0.85      0.86       381\n",
      "   Plastic bag with header       0.70      0.78      0.74       370\n",
      "  Shrink film and insert o       0.81      0.88      0.84       300\n",
      "                  Skincard       0.81      0.93      0.86       229\n",
      "                 TightPack       0.93      0.91      0.92      1659\n",
      "                 Trap Card       0.99      1.00      0.99       161\n",
      "         Trap Folding Card       0.70      0.94      0.81       438\n",
      "               Tray Packer       0.65      0.92      0.76        86\n",
      "                      Tube       0.95      0.88      0.91      2337\n",
      "                  Unpacked       0.75      0.80      0.77       283\n",
      "                Wooden box       1.00      0.33      0.50         3\n",
      "\n",
      "                  accuracy                           0.88     16596\n",
      "                 macro avg       0.83      0.80      0.80     16596\n",
      "              weighted avg       0.88      0.88      0.88     16596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For a single specified model: make predictions and perform detailed evaluation on hold out test data\n",
    "# i = -1  # index of model to use\n",
    "# model_to_use = automl_predictor.model_names()[i]\n",
    "model_to_use = automl_std_leaderboard_testdata.iloc[0, 0] # use best model from leaderboard\n",
    "print(f\"Model to be evaluated: {model_to_use}\")\n",
    "preds_y_test = automl_predictor.predict(X_test, model=model_to_use)\n",
    "print(\"Predictions:  \", list(preds_y_test)[:5])\n",
    "\n",
    "print(classification_report(y_test, preds_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML: custom pre-processing; restricted selection of models including HPO and model ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define features and target, performe oversampling, split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversmapling\n",
      "{'Hanger/ Clip': 13543, 'Tube': 11687, 'Blister and Insert Card': 8744, 'TightPack': 8296, 'Folding carton': 8219, 'Blister and sealed blist': 7912, 'Corrugated carton': 3872, 'Paperboard pouch': 3478, 'Trap Folding Card': 2188, 'Plastic Pouch': 1904, 'Plastic bag with header': 1850, 'Plastic Cassette': 1708, 'Shrink film and insert o': 1499, 'Plastic Box': 1491, 'Unpacked': 1415, 'Skincard': 1143, 'Trap Card': 804, 'Cardb. Sleeve w - w/o Shr.': 676, 'Carton cover (Lid box)': 652, 'Case': 485, 'Tray Packer': 431, 'Cardboard hanger w/o bag': 400, 'Envelope': 295, 'Countertop display': 150, 'Metal Cassette': 50, 'Carton tube with or w/o': 44, 'Wooden box': 16, 'Fabric packaging': 15, 'Book packaging': 10}\n",
      "Class distribution after oversmapling\n",
      "{'Hanger/ Clip': 13543, 'Tube': 11687, 'Blister and Insert Card': 8744, 'TightPack': 8296, 'Folding carton': 8219, 'Blister and sealed blist': 7912, 'Corrugated carton': 3872, 'Paperboard pouch': 3478, 'Trap Folding Card': 2188, 'Plastic Pouch': 1904, 'Plastic bag with header': 1850, 'Plastic Cassette': 1708, 'Shrink film and insert o': 1499, 'Plastic Box': 1491, 'Unpacked': 1415, 'Skincard': 1143, 'Trap Card': 804, 'Cardb. Sleeve w - w/o Shr.': 676, 'Carton cover (Lid box)': 652, 'Case': 485, 'Tray Packer': 431, 'Cardboard hanger w/o bag': 400, 'Envelope': 295, 'Countertop display': 150, 'Carton tube with or w/o': 100, 'Wooden box': 100, 'Metal Cassette': 100, 'Book packaging': 100, 'Fabric packaging': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "X = df_sub.iloc[:, :-1]\n",
    "y = df_sub.iloc[:, -1]  # the last column is the target\n",
    "\n",
    "# Oversampling\n",
    "distribution_classes = y.value_counts()\n",
    "print('Class distribution before oversmapling')\n",
    "print(distribution_classes.to_dict())\n",
    "# NOTE: Oversampling so each class has at least 100 sample; to properly apply CV and evaluation\n",
    "dict_oversmapling = {\n",
    "    'Metal Cassette': 100,\n",
    "    'Carton tube with or w/o': 100,\n",
    "    'Wooden box': 100,\n",
    "    'Fabric packaging': 100,\n",
    "    'Book packaging': 100\n",
    "}\n",
    "# define oversampling strategy\n",
    "oversampler = RandomOverSampler(sampling_strategy=dict_oversmapling, random_state=SEED)\n",
    "# fit and apply the transform\n",
    "X_oversample, y_oversample = oversampler.fit_resample(X, y)\n",
    "print('Class distribution after oversmapling')\n",
    "print(y_oversample.value_counts().to_dict())\n",
    "\n",
    "# Generate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_oversample, y_oversample, test_size=0.2, stratify=y_oversample,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE & EXECUTE PIPELINE\n",
    "# Define pipeline\n",
    "numerical_features = X_train.select_dtypes(include='number').columns.tolist()\n",
    "numeric_feature_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('log_transform', PowerTransformer()),\n",
    "    # ('scale', MinMaxScaler())\n",
    "])\n",
    "categorical_features = X_train.select_dtypes(exclude='number').columns.tolist()\n",
    "categorical_feature_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "])\n",
    "preprocess_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('number', numeric_feature_pipeline, numerical_features),\n",
    "        ('category', categorical_feature_pipeline, categorical_features)\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform=\"pandas\")\n",
    "# transform data\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)\n",
    "\n",
    "# encode target variable\n",
    "label_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, encoded_missing_value=-1)\n",
    "y_train_transformed = label_encoder.fit_transform(y_train.to_frame())\n",
    "y_train_transformed = pd.DataFrame(data=y_train_transformed, index=y_train.index, columns=[y_train.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to AutoML data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train_transformed, y_train_transformed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(df_train)\n",
    "if subsample is True:\n",
    "    train_data = train_data.sample(n=subsample_size, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was trained during hyperparameter tuning NeuralNetTorch... Skipping this model.\n",
      "Fitting model: LightGBMLarge ... Training model for up to 1993.81s of the 17758.43s of remaining time.\n",
      "\t0.7914\t = Validation score   (f1_macro)\n",
      "\t144.01s\t = Training   runtime\n",
      "\t55.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 2879.95s of the 17532.49s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMLarge': 0.357, 'KNeighborsDist': 0.214, 'RandomForestGini': 0.143, 'RandomForestEntr': 0.143, 'KNeighborsUnif': 0.071, 'ExtraTreesGini': 0.071}\n",
      "\t0.7983\t = Validation score   (f1_macro)\n",
      "\t3.17s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11271.22s ... Best model: WeightedEnsemble_L2\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241113_225037\")\n"
     ]
    }
   ],
   "source": [
    "label = 'packaging_category'\n",
    "automl_predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    problem_type='multiclass',\n",
    "    eval_metric='f1_macro',\n",
    "    sample_weight='balance_weight'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    tuning_data=None, # If tuning_data = None, fit() will automatically hold out some random validation examples from train_data.\n",
    "    holdout_frac=0.2, # Default value (if None) is selected based on the number of rows in the training data.\n",
    "    time_limit=experiment_time_limit, # 3*60*60\n",
    "    presets=['high_quality'], # ['high_quality'] # default = ['medium_quality'], any user-specified arguments in fit() will override the values used by presets.\n",
    "    # auto_stack=False, # Whether AutoGluon should automatically utilize bagging and multi-layer stack ensembling to boost predictive accuracy.\n",
    "    # included_model_types=['LR', 'KNN', 'RF', 'XT', 'GBM', 'XGB', 'CAT', 'NN'], \n",
    "    # excluded_model_types=['FASTAI', 'AG_AUTOMM'],\n",
    "    hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified. Searchspaces are provided for some models, but not for all. Where no searchspace is provided, a fixed set of hyper-parameters is defined. (see /searchspace under each model: https://github.com/autogluon/autogluon/tree/master/tabular/src/autogluon/tabular/models).\n",
    "        # 'num_trials': 15, # try at most n different hyperparameter configurations for each type of model\n",
    "        'scheduler' : 'local',\n",
    "        'searcher': 'auto', # ‘auto’: Perform bayesian optimization search on NN_TORCH and FASTAI models. Perform random search on other models.\n",
    "    }  # Refer to TabularPredictor.fit docstring for all valid values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.798341</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>63.077952</td>\n",
       "      <td>194.487381</td>\n",
       "      <td>0.218747</td>\n",
       "      <td>3.174761</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.791435</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>55.271506</td>\n",
       "      <td>144.005281</td>\n",
       "      <td>55.271506</td>\n",
       "      <td>144.005281</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.763345</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>2.218809</td>\n",
       "      <td>15.697407</td>\n",
       "      <td>2.218809</td>\n",
       "      <td>15.697407</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.761439</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>2.849804</td>\n",
       "      <td>26.464896</td>\n",
       "      <td>2.849804</td>\n",
       "      <td>26.464896</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.759531</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1.834237</td>\n",
       "      <td>5.276078</td>\n",
       "      <td>1.834237</td>\n",
       "      <td>5.276078</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.758739</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1.936817</td>\n",
       "      <td>4.777079</td>\n",
       "      <td>1.936817</td>\n",
       "      <td>4.777079</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.437977</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.298646</td>\n",
       "      <td>0.236018</td>\n",
       "      <td>0.298646</td>\n",
       "      <td>0.236018</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.321687</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.283623</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>0.283623</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val eval_metric  pred_time_val    fit_time  \\\n",
       "0  WeightedEnsemble_L2   0.798341    f1_macro      63.077952  194.487381   \n",
       "1        LightGBMLarge   0.791435    f1_macro      55.271506  144.005281   \n",
       "2     RandomForestGini   0.763345    f1_macro       2.218809   15.697407   \n",
       "3     RandomForestEntr   0.761439    f1_macro       2.849804   26.464896   \n",
       "4       ExtraTreesEntr   0.759531    f1_macro       1.834237    5.276078   \n",
       "5       ExtraTreesGini   0.758739    f1_macro       1.936817    4.777079   \n",
       "6       KNeighborsDist   0.437977    f1_macro       0.298646    0.236018   \n",
       "7       KNeighborsUnif   0.321687    f1_macro       0.283623    0.131939   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.218747           3.174761            2       True   \n",
       "1               55.271506         144.005281            1       True   \n",
       "2                2.218809          15.697407            1       True   \n",
       "3                2.849804          26.464896            1       True   \n",
       "4                1.834237           5.276078            1       True   \n",
       "5                1.936817           4.777079            1       True   \n",
       "6                0.298646           0.236018            1       True   \n",
       "7                0.283623           0.131939            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          8  \n",
       "1          7  \n",
       "2          3  \n",
       "3          4  \n",
       "4          6  \n",
       "5          5  \n",
       "6          2  \n",
       "7          1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of models on training data\n",
    "automl_predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate AutoML experiment and best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: AutogluonModels/ag-20241113_225037\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.740478</td>\n",
       "      <td>0.798341</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>91.967577</td>\n",
       "      <td>63.077952</td>\n",
       "      <td>194.487381</td>\n",
       "      <td>0.152463</td>\n",
       "      <td>0.218747</td>\n",
       "      <td>3.174761</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.739120</td>\n",
       "      <td>0.758739</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>3.753227</td>\n",
       "      <td>1.936817</td>\n",
       "      <td>4.777079</td>\n",
       "      <td>3.753227</td>\n",
       "      <td>1.936817</td>\n",
       "      <td>4.777079</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.734841</td>\n",
       "      <td>0.759531</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>3.846254</td>\n",
       "      <td>1.834237</td>\n",
       "      <td>5.276078</td>\n",
       "      <td>3.846254</td>\n",
       "      <td>1.834237</td>\n",
       "      <td>5.276078</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.734640</td>\n",
       "      <td>0.791435</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>76.845919</td>\n",
       "      <td>55.271506</td>\n",
       "      <td>144.005281</td>\n",
       "      <td>76.845919</td>\n",
       "      <td>55.271506</td>\n",
       "      <td>144.005281</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.728181</td>\n",
       "      <td>0.761439</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>6.205621</td>\n",
       "      <td>2.849804</td>\n",
       "      <td>26.464896</td>\n",
       "      <td>6.205621</td>\n",
       "      <td>2.849804</td>\n",
       "      <td>26.464896</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.725460</td>\n",
       "      <td>0.763345</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>4.805619</td>\n",
       "      <td>2.218809</td>\n",
       "      <td>15.697407</td>\n",
       "      <td>4.805619</td>\n",
       "      <td>2.218809</td>\n",
       "      <td>15.697407</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.405158</td>\n",
       "      <td>0.437977</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.104866</td>\n",
       "      <td>0.298646</td>\n",
       "      <td>0.236018</td>\n",
       "      <td>0.104866</td>\n",
       "      <td>0.298646</td>\n",
       "      <td>0.236018</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.301214</td>\n",
       "      <td>0.321687</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.099862</td>\n",
       "      <td>0.283623</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>0.099862</td>\n",
       "      <td>0.283623</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0  WeightedEnsemble_L2    0.740478   0.798341    f1_macro       91.967577   \n",
       "1       ExtraTreesGini    0.739120   0.758739    f1_macro        3.753227   \n",
       "2       ExtraTreesEntr    0.734841   0.759531    f1_macro        3.846254   \n",
       "3        LightGBMLarge    0.734640   0.791435    f1_macro       76.845919   \n",
       "4     RandomForestEntr    0.728181   0.761439    f1_macro        6.205621   \n",
       "5     RandomForestGini    0.725460   0.763345    f1_macro        4.805619   \n",
       "6       KNeighborsDist    0.405158   0.437977    f1_macro        0.104866   \n",
       "7       KNeighborsUnif    0.301214   0.321687    f1_macro        0.099862   \n",
       "\n",
       "   pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0      63.077952  194.487381                 0.152463                0.218747   \n",
       "1       1.936817    4.777079                 3.753227                1.936817   \n",
       "2       1.834237    5.276078                 3.846254                1.834237   \n",
       "3      55.271506  144.005281                76.845919               55.271506   \n",
       "4       2.849804   26.464896                 6.205621                2.849804   \n",
       "5       2.218809   15.697407                 4.805619                2.218809   \n",
       "6       0.298646    0.236018                 0.104866                0.298646   \n",
       "7       0.283623    0.131939                 0.099862                0.283623   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           3.174761            2       True          8  \n",
       "1           4.777079            1       True          5  \n",
       "2           5.276078            1       True          6  \n",
       "3         144.005281            1       True          7  \n",
       "4          26.464896            1       True          4  \n",
       "5          15.697407            1       True          3  \n",
       "6           0.236018            1       True          2  \n",
       "7           0.131939            1       True          1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of models on test data\n",
    "\n",
    "# NOTE: Load a TabularPredictor object previously produced by fit() from file and returns this object.\n",
    "try:\n",
    "    # NOTE: set the directory to the saved model\n",
    "    specific_path = None # Default: None ; Path fromat: 'AutogluonModels/ag-20241113_002120'\n",
    "    autogluon_saved_model_path = specific_path if specific_path else automl_predictor.path\n",
    "    automl_predictor = automl_predictor if automl_predictor else TabularPredictor.load(f\"{config['autogluon_exp_storage_directory']}/{autogluon_saved_model_path}\")\n",
    "    print(f\"Model loaded from: {automl_predictor.path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Model could not be loaded. An error occurred: {e}\")\n",
    "\n",
    "# process X_test for evaluation and predictions\n",
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "# evaluate models on test data\n",
    "y_test_transformed = label_encoder.transform(y_test.to_frame())\n",
    "y_test_transformed = pd.DataFrame(data=y_test_transformed, index=y_test.index, columns=[y_test.name])\n",
    "df_test = pd.concat([X_test_transformed, y_test_transformed], axis=1)\n",
    "test_data = TabularDataset(df_test)\n",
    "\n",
    "automl_custom_leaderboard_testdata = automl_predictor.leaderboard(test_data)\n",
    "automl_custom_leaderboard_testdata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WeightedEnsemble_L2', 'ExtraTreesGini', 'ExtraTreesEntr',\n",
       "       'LightGBMLarge', 'RandomForestEntr', 'RandomForestGini',\n",
       "       'KNeighborsDist', 'KNeighborsUnif'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_custom_leaderboard_testdata.model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.739069</td>\n",
       "      <td>0.758777</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>3.120127</td>\n",
       "      <td>3.023791</td>\n",
       "      <td>9.571872</td>\n",
       "      <td>3.120127</td>\n",
       "      <td>3.023791</td>\n",
       "      <td>9.571872</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "1  ExtraTreesGini    0.739069   0.758777    f1_macro        3.120127   \n",
       "\n",
       "   pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "1       3.023791  9.571872                 3.120127                3.023791   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "1           9.571872            1       True          5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_custom_leaderboard_testdata[automl_custom_leaderboard_testdata['model'].str.contains('ExtraTreesGini')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model to be evaluated: WeightedEnsemble_L2\n",
      "Predictions:   [23.0, 0.0, 1.0, 26.0, 26.0]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "   Blister and Insert Card       0.77      0.85      0.81      1749\n",
      "  Blister and sealed blist       0.78      0.77      0.78      1582\n",
      "            Book packaging       0.91      1.00      0.95        20\n",
      "Cardb. Sleeve w - w/o Shr.       0.59      0.41      0.49       135\n",
      "  Cardboard hanger w/o bag       0.49      0.39      0.43        80\n",
      "    Carton cover (Lid box)       0.55      0.54      0.54       130\n",
      "   Carton tube with or w/o       0.68      0.85      0.76        20\n",
      "                      Case       0.65      0.53      0.58        97\n",
      "         Corrugated carton       0.77      0.75      0.76       774\n",
      "        Countertop display       0.81      0.73      0.77        30\n",
      "                  Envelope       0.94      0.86      0.90        59\n",
      "          Fabric packaging       0.95      1.00      0.98        20\n",
      "            Folding carton       0.80      0.69      0.74      1644\n",
      "              Hanger/ Clip       0.88      0.95      0.91      2709\n",
      "            Metal Cassette       1.00      0.75      0.86        20\n",
      "          Paperboard pouch       0.78      0.83      0.81       696\n",
      "               Plastic Box       0.92      0.76      0.83       298\n",
      "          Plastic Cassette       0.81      0.52      0.63       342\n",
      "             Plastic Pouch       0.72      0.70      0.71       381\n",
      "   Plastic bag with header       0.72      0.69      0.70       370\n",
      "  Shrink film and insert o       0.67      0.65      0.66       300\n",
      "                  Skincard       0.48      0.86      0.62       229\n",
      "                 TightPack       0.90      0.85      0.87      1659\n",
      "                 Trap Card       0.65      0.78      0.71       161\n",
      "         Trap Folding Card       0.73      0.76      0.74       438\n",
      "               Tray Packer       0.34      0.31      0.33        86\n",
      "                      Tube       0.87      0.87      0.87      2337\n",
      "                  Unpacked       0.75      0.72      0.74       283\n",
      "                Wooden box       1.00      1.00      1.00        20\n",
      "\n",
      "                  accuracy                           0.80     16669\n",
      "                 macro avg       0.76      0.74      0.74     16669\n",
      "              weighted avg       0.81      0.80      0.80     16669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For a single specified model: make predictions and perform detailed evaluation on hold out test data\n",
    "# i = -1  # index of model to use\n",
    "# model_to_use = automl_predictor.model_names()[i]\n",
    "# model_to_use = automl_custom_leaderboard_testdata.iloc[0, 0] # use best model from leaderboard\n",
    "model_to_use = automl_predictor.model_best\n",
    "print(f\"Model to be evaluated: {model_to_use}\")\n",
    "preds_y_test = automl_predictor.predict(X_test_transformed, model=model_to_use)\n",
    "print(\"Predictions:  \", list(preds_y_test)[:5])\n",
    "\n",
    "preds_y_test_inverse = label_encoder.inverse_transform(preds_y_test.to_frame())\n",
    "\n",
    "# print classification report for holdout test data\n",
    "print(classification_report(y_test, preds_y_test_inverse))\n",
    "report = classification_report(y_test, preds_y_test_inverse, output_dict=True)\n",
    "f1_score = report['accuracy']\n",
    "f1_macro = report['macro avg']['f1-score']\n",
    "\n",
    "# get best model parameters for mlflow tracking\n",
    "trainer = automl_predictor._trainer\n",
    "best_model = trainer.load_model(trainer.model_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track performance using MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Change to a meaningful name\n",
    "EXPERIMENT_NAME = \"AutoPackagingCategories\"\n",
    "RUN_NAME = \"run_AutoML_AutoGluonTabular\"\n",
    "\n",
    "with open('../env_vars.yml', 'r') as file:\n",
    "    env_vars = yaml.safe_load(file)\n",
    "\n",
    "project_dir = env_vars['project_directory']\n",
    "os.makedirs(project_dir + '/mlruns', exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(\"file://\" + project_dir + \"/mlruns\")\n",
    "\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    EXPERIMENT_ID = experiment.experiment_id\n",
    "except AttributeError:\n",
    "    EXPERIMENT_ID = mlflow.create_experiment(\n",
    "        EXPERIMENT_NAME,\n",
    "        # mlflow.set_artifact_uri(\"file://\" + project_dir + \"/artifacts/\")\n",
    "    )\n",
    "\n",
    "current_time = datetime.datetime.now()\n",
    "time_stamp = str(current_time)\n",
    "# NOTE: Change to a meaningful name for the single trial\n",
    "# exp_run_name = f\"run_MeaningfulTrialName_{time_stamp}\"\n",
    "exp_run_name = f\"{RUN_NAME}_{time_stamp}\"\n",
    "\n",
    "# Start MLflow\n",
    "with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=exp_run_name) as run:\n",
    "\n",
    "    # Retrieve run id\n",
    "    RUN_ID = run.info.run_id\n",
    "\n",
    "    # Track parameters\n",
    "    # track pipeline configs: preprocessing_pipeline\n",
    "    mlflow.log_dict(\n",
    "        {'oversampler': type(oversampler), 'label_encoder': type(label_encoder)} | preprocess_pipeline.named_transformers_,\n",
    "        \"preprocessing_pipeline.json\"\n",
    "    )\n",
    "\n",
    "    # mode specfic parameters\n",
    "    mlflow.log_param('model', f'{type(best_model)}: {best_model.base_model_names}')\n",
    "    mlflow.log_param('model_configs', best_model.get_trained_params())\n",
    "\n",
    "    # Track metrics\n",
    "    mlflow.log_dict(report, \"classification_report.json\")\n",
    "    mlflow.log_metric(\"Report_Test_f1_score\", f1_score)\n",
    "    mlflow.log_metric(\"Report_Test_f1_macro\", f1_macro)\n",
    "    \n",
    "    # Track model\n",
    "    # mlflow.sklearn.log_model(clf, \"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ml_packaging_classification_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
