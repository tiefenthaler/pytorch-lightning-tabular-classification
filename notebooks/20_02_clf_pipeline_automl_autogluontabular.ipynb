{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERAL THOUGHTS:**  \n",
    "Use AutoML (AutoGluon.Tabular) as a general way to investigate which algorithm, pre-processing, feature engineering options are (well) suited for the given tasks, as well as to investigate the potential performance based on a (large) varity of configurations of those options.\n",
    "The notebook includes multiple scenarios of using AutoML:\n",
    "- including and excluding custom data pre-processing (see below)\n",
    "- including auto pre-processing by AutoGluon.Tabular\n",
    "- including auto feature engineering by AutoGluon.Tabular\n",
    "https://auto.gluon.ai/stable/tutorials/tabular/tabular-feature-engineering.html\n",
    "- including multiple classifiers by using:\n",
    "  - multiple ml algorithms\n",
    "  - \"standard\" HPO for each algorithm defined by AutoGluon.Tabular\n",
    "  - ensables of algorithms (bagging and stacking with possible multiple layers)\n",
    "\n",
    "**DATA PREPROCESSING:**  \n",
    "Imbalanced data:\n",
    "- over_sampling for imbalanced data.\n",
    "- cost-sensitive learning for imbalanced data.\n",
    "\n",
    "continuous data:\n",
    "- Impute missing data: SimpleImputer(strategy='median').\n",
    "- Standardize data: StandardScaler().\n",
    "\n",
    "categorical data:\n",
    "- Impute missing data: SimpleImputer(strategy='most_frequent').\n",
    "- Ordinal & Nominal data encoding: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1).\n",
    "- Unknown values ecoding and reordering of ordinal encoding: custom encoder \"OrdinalEncoderExtensionUnknowns()\".\n",
    "\n",
    "target data:\n",
    "- target encoding: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "**AUTOML MULTI-CLASS CLASSIFIERS:**\n",
    "- Overview of models to be considered using AutoML (AutoGluon.Tabular):  \n",
    "  - [X] RandomForest\n",
    "  - [X] ExtraTrees\n",
    "  - [X] XGBoost\n",
    "  - [X] LightGBM\n",
    "  - [X] KNeighbors\n",
    "  - [X] CatBoost\n",
    "  - [X] Multiple Neural Nets\n",
    "\n",
    "**FINAL MODEL PERFORMANCE:**  \n",
    "- Evaluation of the best model from AutoML, including Experiment checkpointing.\n",
    "- Loading final model from checkpoint for prediction on test set for evaluation based on classification report\n",
    "- Tracking of the best model with MLFlow for performance benchmarking with other approaches (Baseline, PyCaret, PyTorch, ...) within the Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False\n",
    "azure = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    # Import the library to mount Google Drive\n",
    "    from google.colab import drive\n",
    "    # Mount the Google Drive at /content/drive\n",
    "    drive.mount('/content/drive')\n",
    "    # Verify by listing the files in the drive\n",
    "    # !ls /content/drive/My\\ Drive/\n",
    "    # current dir in colab\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install --upgrade autogluon.tabular\n",
    "    !pip install --upgrade mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: if used in google colab, upload env_vars_colab.yml to current google colab directory!\n",
    "\n",
    "# get config\n",
    "if colab:\n",
    "    with open('./env_vars_colab.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "elif azure:\n",
    "    with open('../env_vars_azureml_compute.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "else:\n",
    "    with open('../env_vars.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "# custom imports\n",
    "sys.path.append(config['project_directory'])\n",
    "\n",
    "# from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-14_21:50:31\n"
     ]
    }
   ],
   "source": [
    "# General settings within the data science workflow\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# NOTE: for dev only\n",
    "subsample = False\n",
    "subsample_size = 100  # subsample subset of data for faster demo or development\n",
    "\n",
    "experiment_time_limit = 8*60*60 #3*60*60\n",
    "\n",
    "# Get current date and time\n",
    "now = datetime.datetime.now()\n",
    "formatted_date_time = now.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "print(formatted_date_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{config['data_directory']}/output/df_ml.csv\", sep='\\t')\n",
    "\n",
    "df['material_number'] = df['material_number'].astype('object')\n",
    "\n",
    "df_sub = df[[\n",
    "    'material_number',\n",
    "    'brand',\n",
    "    'product_area',\n",
    "    'core_segment',\n",
    "    'component',\n",
    "    'manufactoring_location',\n",
    "    'characteristic_value',\n",
    "    'material_weight', \n",
    "    'packaging_code',\n",
    "    'packaging_category',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML: without custom pre-processing; restricted selection of models including HPO and model ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df_sub.iloc[:, :-1]\n",
    "y = df_sub.iloc[:, -1]  # the last column is the target\n",
    "\n",
    "# Generate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to AutoML data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(df_train)\n",
    "if subsample is True:\n",
    "    train_data = train_data.sample(n=subsample_size, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241114_215127\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #82~20.04.1-Ubuntu SMP Tue Sep 3 12:27:43 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       28.42 GB / 31.34 GB (90.7%)\n",
      "Disk Space Avail:   102399.87 GB / 102400.00 GB (100.0%)\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 7200s of the 28800s of remaining time (25%).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-11-14 21:51:30,321\tINFO worker.py:1777 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Using predefined sample weighting strategy: balance_weight. Evaluation metrics will ignore sample weights, specify weight_evaluation=True to instead report weighted metrics.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Beginning AutoGluon training ... Time limit = 7197s\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Train Data Rows:    59005\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Train Data Columns: 9\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Label Column:       packaging_category\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Problem Type:       multiclass\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 28 out of 29 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9998813659859334\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Assigning sample weights to balance differences in frequency of classes.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Train Data Class Count: 28\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tAvailable Memory:                    28113.79 MB\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tTrain Data (Original)  Memory Usage: 28.93 MB (0.1% of available memory)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t\t('float', [])  : 1 | ['material_weight']\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t\t('object', []) : 8 | ['material_number', 'brand', 'product_area', 'core_segment', 'component', ...]\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t\t('category', []) : 8 | ['material_number', 'brand', 'product_area', 'core_segment', 'component', ...]\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t\t('float', [])    : 1 | ['material_weight']\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.3s = Fit runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t9 features in original data used to generate 9 features in processed data.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tTrain Data (Processed) Memory Usage: 1.07 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Data preprocessing and feature engineering runtime = 0.36s ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitting 110 L1 models ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: KNeighborsUnif_BAG_L1 ... Tuning model for up to 39.24s of the 7196.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for KNeighborsUnif_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: KNeighborsUnif_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.2893\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t1.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t1.56s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: KNeighborsDist_BAG_L1 ... Tuning model for up to 39.24s of the 7193.54s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for KNeighborsDist_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: KNeighborsDist_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.2967\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t1.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t1.43s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_BAG_L1 ... Tuning model for up to 39.24s of the 7191.62s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╭───────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Configuration for experiment     NeuralNetFastAI_BAG_L1   │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ├───────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Search algorithm                 SearchGenerator          │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Scheduler                        FIFOScheduler            │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Number of trials                 1000                     │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╰───────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m View detailed results here: /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(model_trial pid=15653)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=15701, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m \n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m \n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=15701, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=15701, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m \n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m \n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=15701, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(model_trial pid=15653)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621106.816961   15477 chttp2_transport.cc:1161] ipv4:10.0.0.4:36699: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T21:51:46.816940386+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=16041, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m \n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m \n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=16041, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m \n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m \n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=16041, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m ModuleNotFoundError: No module named 'fastai'\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m During handling of the above exception, another exception occurred:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     out = self._fit(**kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     try_import_fastai()\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16041, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=15845)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=16390, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=16390, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16390, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=16390, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m ModuleNotFoundError: No module named 'fastai'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m During handling of the above exception, another exception occurred:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     out = self._fit(**kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     try_import_fastai()\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16202)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=16671, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=16671, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=16671, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16671, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m ModuleNotFoundError: No module named 'fastai'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m During handling of the above exception, another exception occurred:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     out = self._fit(**kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     try_import_fastai()\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16538)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=17005, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=17005, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17005, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m \n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=17005, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m ModuleNotFoundError: No module named 'fastai'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m During handling of the above exception, another exception occurred:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     out = self._fit(**kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     try_import_fastai()\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=16824)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=17320, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m \n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m \n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=17320, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m \n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m \n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=17320, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17320, ip=10.0.0.4)\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m ModuleNotFoundError: No module named 'fastai'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m During handling of the above exception, another exception occurred:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     out = self._fit(**kwargs)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     try_import_fastai()\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=17148)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Reached timeout of 39.24433434375741 seconds. Stopping all trials.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Wrote the latest version of all result files and experiment state to '/mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1' in 0.1070s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m Failed to fetch metrics for 8 trial(s):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - dd4bfdaa: FileNotFoundError('Could not fetch metrics for dd4bfdaa: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/dd4bfdaa')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 3e8c7824: FileNotFoundError('Could not fetch metrics for 3e8c7824: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/3e8c7824')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - b0fcf057: FileNotFoundError('Could not fetch metrics for b0fcf057: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/b0fcf057')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 4faf1a7f: FileNotFoundError('Could not fetch metrics for 4faf1a7f: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/4faf1a7f')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - a7e4bdb5: FileNotFoundError('Could not fetch metrics for a7e4bdb5: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/a7e4bdb5')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - b65020ee: FileNotFoundError('Could not fetch metrics for b65020ee: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/b65020ee')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - b4655a96: FileNotFoundError('Could not fetch metrics for b4655a96: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/b4655a96')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 0b91a2ed: FileNotFoundError('Could not fetch metrics for 0b91a2ed: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetFastAI_BAG_L1/0b91a2ed')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning NeuralNetFastAI_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: LightGBMXT_BAG_L1 ... Tuning model for up to 39.24s of the 7151.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return metric(y, y_pred, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fbeta_score(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     _, _, f, _ = precision_recall_fscore_support(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ValueError(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ValueError: Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tStopping HPO to satisfy time limit...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning LightGBMXT_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 39.24s of the 7110.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[33m(raylet)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[33m(raylet)\u001b[0m I0000 00:00:1731621200.968491   15309 chttp2_transport.cc:1161] ipv4:10.0.0.4:33623: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T21:53:20.968436263+00:00\"}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return metric(y, y_pred, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fbeta_score(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     _, _, f, _ = precision_recall_fscore_support(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ValueError(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ValueError: Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tStopping HPO to satisfy time limit...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning LightGBM_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: RandomForestGini_BAG_L1 ... Tuning model for up to 39.24s of the 7068.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for RandomForestGini_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: RandomForestGini_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.7042\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t18.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t2.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: RandomForestEntr_BAG_L1 ... Tuning model for up to 39.24s of the 7049.1s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for RandomForestEntr_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: RandomForestEntr_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.7007\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t22.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t2.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: CatBoost_BAG_L1 ... Tuning model for up to 39.24s of the 7026.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return metric(y, y_pred, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fbeta_score(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     _, _, f, _ = precision_recall_fscore_support(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ValueError(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ValueError: Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tStopping HPO to satisfy time limit...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning CatBoost_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: ExtraTreesGini_BAG_L1 ... Tuning model for up to 39.24s of the 6921.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for ExtraTreesGini_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: ExtraTreesGini_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.7035\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t17.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t2.41s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: ExtraTreesEntr_BAG_L1 ... Tuning model for up to 39.24s of the 6902.83s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for ExtraTreesEntr_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: ExtraTreesEntr_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.7057\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t18.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t2.41s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: XGBoost_BAG_L1 ... Tuning model for up to 39.24s of the 6884.07s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=19857, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(AxisError): \u001b[36mray::_ray_fit()\u001b[39m (pid=19857, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=20042, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(AxisError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20042, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=20044, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=20215, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(AxisError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20215, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=20397, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(AxisError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20397, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=20571, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(AxisError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20571, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=20755, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(AxisError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20755, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621432.702853   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:44925: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T21:57:12.702833556+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=20928, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(AxisError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20928, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621441.793397   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:37619: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T21:57:21.793379241+00:00\"}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=21101, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(AxisError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21101, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._Booster = train(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                     ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/training.py\", line 182, in train\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/core.py\", line 2225, in eval_set\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     feval_ret = feval(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                 ^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/xgboost/sklearn.py\", line 151, in inner\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func.__name__, func(y_true, y_score)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 42, in custom_metric\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     y_hat = y_hat.argmax(axis=1)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m numpy.exceptions.AxisError: axis 1 is out of bounds for array of dimension 1\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tStopping HPO to satisfy time limit...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning XGBoost_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 39.24s of the 6847.55s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╭──────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Configuration for experiment     NeuralNetTorch_BAG_L1   │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ├──────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Search algorithm                 SearchGenerator         │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Scheduler                        FIFOScheduler           │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Number of trials                 1000                    │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╰──────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m View detailed results here: /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621444.511914   15475 chttp2_transport.cc:1161] ipv4:10.0.0.4:38731: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T21:57:24.511306387+00:00\"}\n",
      "\u001b[36m(_ray_fit pid=21334)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=21334)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=21576)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=21576)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     return metric(y, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     return fbeta_score(\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     _, _, f, _ = precision_recall_fscore_support(\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m     raise ValueError(\n",
      "\u001b[36m(model_trial pid=21292)\u001b[0m ValueError: Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[33m(raylet)\u001b[0m I0000 00:00:1731621479.374584   15308 chttp2_transport.cc:1161] ipv4:10.0.0.4:37767: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T21:57:59.374563696+00:00\"}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Reached timeout of 39.24433434375741 seconds. Stopping all trials.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Wrote the latest version of all result files and experiment state to '/mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1' in 0.0538s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m Failed to fetch metrics for 2 trial(s):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 37ce378b: FileNotFoundError('Could not fetch metrics for 37ce378b: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/37ce378b')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - e1902f61: FileNotFoundError('Could not fetch metrics for e1902f61: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/e1902f61')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 39.24s of the 6807.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.6491\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t41.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t28.08s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=21682)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=21682)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: CatBoost_r177_BAG_L1 ... Tuning model for up to 39.24s of the 6760.3s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r177_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621563.272779   15477 chttp2_transport.cc:1161] ipv4:10.0.0.4:46555: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T21:59:23.272763488+00:00\"}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: CatBoost_r177_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.2016\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t47.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.32s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r79_BAG_L1 ... Tuning model for up to 39.24s of the 6712.23s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r79_BAG_L1   │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Search algorithm                 SearchGenerator             │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Scheduler                        FIFOScheduler               │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Number of trials                 1000                        │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m View detailed results here: /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=22923)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=22923)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=23169)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=23169)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m I0000 00:00:1731621614.623844   22904 chttp2_transport.cc:1161] ipv4:10.0.0.4:36783: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:00:14.623816917+00:00\"}\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     return metric(y, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     return fbeta_score(\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     _, _, f, _ = precision_recall_fscore_support(\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m     raise ValueError(\n",
      "\u001b[36m(model_trial pid=22878)\u001b[0m ValueError: Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Reached timeout of 39.24433434375741 seconds. Stopping all trials.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Wrote the latest version of all result files and experiment state to '/mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L1' in 0.0527s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m Failed to fetch metrics for 2 trial(s):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 68235dcc: FileNotFoundError('Could not fetch metrics for 68235dcc: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L1/68235dcc')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - f2305926: FileNotFoundError('Could not fetch metrics for f2305926: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r79_BAG_L1/f2305926')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r79_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: LightGBM_r131_BAG_L1 ... Tuning model for up to 39.24s of the 6672.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r131_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_ray_fit pid=23171)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=23171)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621641.539342   15483 chttp2_transport.cc:1161] ipv4:10.0.0.4:36609: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:00:41.539326526+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: LightGBM_r131_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.6085\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t47.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t27.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r191_BAG_L1 ... Tuning model for up to 39.24s of the 6624.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r191_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Warning: Exception caused NeuralNetFastAI_r191_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/hpo/executors.py\", line 352, in validate_search_space\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23930, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=23930, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=23930, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=23930, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: CatBoost_r9_BAG_L1 ... Tuning model for up to 39.24s of the 6621.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r9_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621698.790608   15477 chttp2_transport.cc:1161] ipv4:10.0.0.4:43799: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:01:38.790586223+00:00\"}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: CatBoost_r9_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.3155\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t45.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.49s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: LightGBM_r96_BAG_L1 ... Tuning model for up to 39.24s of the 6575.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=23931, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=23931, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r96_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621736.967969   15613 chttp2_transport.cc:1161] ipv4:10.0.0.4:36317: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:02:16.967951732+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621736.994509   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:44669: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:02:16.994486219+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621759.385078   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:44129: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:02:39.385064042+00:00\"}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: LightGBM_r96_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.5472\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t45.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t25.39s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r22_BAG_L1 ... Tuning model for up to 39.24s of the 6529.76s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r22_BAG_L1   │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Search algorithm                 SearchGenerator             │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Scheduler                        FIFOScheduler               │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Number of trials                 1000                        │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m View detailed results here: /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=25082)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=25082)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=25312)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=25312)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m I0000 00:00:1731621795.320402   25080 chttp2_transport.cc:1161] ipv4:10.0.0.4:36059: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:03:15.320216187+00:00\"}\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m I0000 00:00:1731621795.473974   25061 chttp2_transport.cc:1161] ipv4:10.0.0.4:42961: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:03:15.473959231+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     return metric(y, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     return fbeta_score(\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     _, _, f, _ = precision_recall_fscore_support(\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m     raise ValueError(\n",
      "\u001b[36m(model_trial pid=25036)\u001b[0m ValueError: Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Reached timeout of 39.24433434375741 seconds. Stopping all trials.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Wrote the latest version of all result files and experiment state to '/mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L1' in 0.0700s.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Failed to fetch metrics for 3 trial(s):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 5f876b23: FileNotFoundError('Could not fetch metrics for 5f876b23: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L1/5f876b23')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 870945d3: FileNotFoundError('Could not fetch metrics for 870945d3: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L1/870945d3')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - cad2a14e: FileNotFoundError('Could not fetch metrics for cad2a14e: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r22_BAG_L1/cad2a14e')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r22_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: XGBoost_r33_BAG_L1 ... Tuning model for up to 39.24s of the 6489.84s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r33_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\u001b[36m(_ray_fit pid=25327)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=25327)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621819.149292   15477 chttp2_transport.cc:1161] ipv4:10.0.0.4:39677: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:03:39.149274237+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621837.707342   15483 chttp2_transport.cc:1161] ipv4:10.0.0.4:40985: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:03:57.707326234+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: XGBoost_r33_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.5601\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t38.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t8.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: ExtraTrees_r42_BAG_L1 ... Tuning model for up to 39.24s of the 6451.38s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r42_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: ExtraTrees_r42_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.7051\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t17.9s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t2.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: CatBoost_r137_BAG_L1 ... Tuning model for up to 39.24s of the 6433.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r137_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621878.506911   15477 chttp2_transport.cc:1161] ipv4:10.0.0.4:41369: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:04:38.506890507+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: CatBoost_r137_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.1065\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t31.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.28s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r102_BAG_L1 ... Tuning model for up to 39.24s of the 6401.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r102_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Warning: Exception caused NeuralNetFastAI_r102_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/hpo/executors.py\", line 352, in validate_search_space\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=26512, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=26512, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=26512, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=26512, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731621890.069490   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:38845: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:04:50.069472267+00:00\"}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: CatBoost_r13_BAG_L1 ... Tuning model for up to 39.24s of the 6399.28s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r13_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: CatBoost_r13_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.2743\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t73.58s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.3s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: RandomForest_r195_BAG_L1 ... Tuning model for up to 39.24s of the 6325.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r195_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: RandomForest_r195_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.7108\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t24.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t2.21s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: LightGBM_r188_BAG_L1 ... Tuning model for up to 39.24s of the 6300.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r188_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[33m(raylet)\u001b[0m I0000 00:00:1731622011.817707   15278 chttp2_transport.cc:1161] ipv4:10.0.0.4:35905: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:06:51.817687542+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622034.906544   15477 chttp2_transport.cc:1161] ipv4:10.0.0.4:35311: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:07:14.906525102+00:00\", http2_error:2, grpc_status:14}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: LightGBM_r188_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.6003\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t46.33s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t24.56s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r145_BAG_L1 ... Tuning model for up to 39.24s of the 6254.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r145_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Warning: Exception caused NeuralNetFastAI_r145_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/hpo/executors.py\", line 352, in validate_search_space\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=27852, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=27852, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=27852, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=27852, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: XGBoost_r89_BAG_L1 ... Tuning model for up to 39.24s of the 6252.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r89_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622073.522200   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:45493: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:07:53.52218062+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: XGBoost_r89_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.5327\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t36.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t3.63s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r30_BAG_L1 ... Tuning model for up to 39.24s of the 6215.57s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=27851, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=27851, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r30_BAG_L1   │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Search algorithm                 SearchGenerator             │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Scheduler                        FIFOScheduler               │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Number of trials                 1000                        │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m View detailed results here: /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=28472)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=28472)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=28704)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=28704)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m I0000 00:00:1731622108.554741   28458 chttp2_transport.cc:1161] ipv4:10.0.0.4:44891: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:08:28.554709857+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m I0000 00:00:1731622109.005375   28456 chttp2_transport.cc:1161] ipv4:10.0.0.4:35055: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:08:29.00536128+00:00\"}\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m I0000 00:00:1731622110.321526   28456 chttp2_transport.cc:1161] ipv4:10.0.0.4:36865: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:08:30.321506134+00:00\"}\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     return metric(y, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     return fbeta_score(\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     _, _, f, _ = precision_recall_fscore_support(\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m     raise ValueError(\n",
      "\u001b[36m(model_trial pid=28409)\u001b[0m ValueError: Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Reached timeout of 39.24433434375741 seconds. Stopping all trials.\n",
      "\u001b[36m(_ray_fit pid=28701)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=28701)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Wrote the latest version of all result files and experiment state to '/mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L1' in 0.0818s.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Failed to fetch metrics for 3 trial(s):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - fe30254b: FileNotFoundError('Could not fetch metrics for fe30254b: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L1/fe30254b')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 79f7fadc: FileNotFoundError('Could not fetch metrics for 79f7fadc: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L1/79f7fadc')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 37b5f69c: FileNotFoundError('Could not fetch metrics for 37b5f69c: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r30_BAG_L1/37b5f69c')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r30_BAG_L1... Skipping this model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: LightGBM_r130_BAG_L1 ... Tuning model for up to 39.24s of the 6175.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r130_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[33m(raylet)\u001b[0m I0000 00:00:1731622139.396096   15309 chttp2_transport.cc:1161] ipv4:10.0.0.4:41731: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:08:59.396074893+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622163.425690   15613 chttp2_transport.cc:1161] ipv4:10.0.0.4:40467: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:09:23.425669605+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: LightGBM_r130_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.6585\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t49.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t29.43s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r86_BAG_L1 ... Tuning model for up to 39.24s of the 6125.63s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r86_BAG_L1   │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Search algorithm                 SearchGenerator             │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Scheduler                        FIFOScheduler               │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Number of trials                 1000                        │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m View detailed results here: /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=29553)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=29553)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m I0000 00:00:1731622185.668268   29532 chttp2_transport.cc:1161] ipv4:10.0.0.4:41029: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:09:45.668243268+00:00\"}\n",
      "\u001b[36m(_ray_fit pid=29792)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29792)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m I0000 00:00:1731622201.417430   29534 chttp2_transport.cc:1161] ipv4:10.0.0.4:43065: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:10:01.417412242+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     return metric(y, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     return fbeta_score(\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     _, _, f, _ = precision_recall_fscore_support(\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m     raise ValueError(\n",
      "\u001b[36m(model_trial pid=29509)\u001b[0m ValueError: Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Reached timeout of 39.24433434375741 seconds. Stopping all trials.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Wrote the latest version of all result files and experiment state to '/mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L1' in 0.0525s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m Failed to fetch metrics for 2 trial(s):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 9fb30edb: FileNotFoundError('Could not fetch metrics for 9fb30edb: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L1/9fb30edb')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 48f7ce84: FileNotFoundError('Could not fetch metrics for 48f7ce84: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r86_BAG_L1/48f7ce84')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r86_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: CatBoost_r50_BAG_L1 ... Tuning model for up to 39.24s of the 6085.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r50_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=29842)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29842)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622220.511154   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:36447: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:10:20.51113871+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622228.011203   15477 chttp2_transport.cc:1161] ipv4:10.0.0.4:42027: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:10:28.011185605+00:00\"}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: CatBoost_r50_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.1526\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t23.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r11_BAG_L1 ... Tuning model for up to 39.24s of the 6061.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r11_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622230.116607   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:36219: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:10:30.116588565+00:00\"}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Warning: Exception caused NeuralNetFastAI_r11_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/hpo/executors.py\", line 352, in validate_search_space\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=30463, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=30463, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=30463, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=30463, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: XGBoost_r194_BAG_L1 ... Tuning model for up to 39.24s of the 6059.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r194_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622250.142864   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:40463: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:10:50.142844415+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622267.744243   15477 chttp2_transport.cc:1161] ipv4:10.0.0.4:36537: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:11:07.74422327+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: XGBoost_r194_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.7544\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t37.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t1.58s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: ExtraTrees_r172_BAG_L1 ... Tuning model for up to 39.24s of the 6021.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for ExtraTrees_r172_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: ExtraTrees_r172_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.6384\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t9.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t1.89s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: CatBoost_r69_BAG_L1 ... Tuning model for up to 39.24s of the 6011.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r69_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622315.632667   15477 chttp2_transport.cc:1161] ipv4:10.0.0.4:34001: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:11:55.632650478+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: CatBoost_r69_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.159\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t51.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r103_BAG_L1 ... Tuning model for up to 39.24s of the 5959.58s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r103_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Warning: Exception caused NeuralNetFastAI_r103_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/hpo/executors.py\", line 352, in validate_search_space\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=31542, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=31542, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=31542, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=31542, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r14_BAG_L1 ... Tuning model for up to 39.24s of the 5957.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r14_BAG_L1   │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Search algorithm                 SearchGenerator             │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Scheduler                        FIFOScheduler               │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Number of trials                 1000                        │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m View detailed results here: /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=31764)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=31764)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=32003)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=32003)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     return metric(y, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     return fbeta_score(\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     _, _, f, _ = precision_recall_fscore_support(\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m     raise ValueError(\n",
      "\u001b[36m(model_trial pid=31719)\u001b[0m ValueError: Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Reached timeout of 39.24433434375741 seconds. Stopping all trials.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Wrote the latest version of all result files and experiment state to '/mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L1' in 0.0482s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m Failed to fetch metrics for 2 trial(s):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - f20f9b59: FileNotFoundError('Could not fetch metrics for f20f9b59: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L1/f20f9b59')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - c7306935: FileNotFoundError('Could not fetch metrics for c7306935: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r14_BAG_L1/c7306935')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r14_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: LightGBM_r161_BAG_L1 ... Tuning model for up to 39.24s of the 5917.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r161_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622398.327713   15473 chttp2_transport.cc:1161] ipv4:10.0.0.4:33549: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:13:18.32768957+00:00\"}\n",
      "\u001b[36m(_ray_fit pid=32071)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=32071)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: LightGBM_r161_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.5937\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t48.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t28.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r143_BAG_L1 ... Tuning model for up to 39.24s of the 5867.49s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r143_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Warning: Exception caused NeuralNetFastAI_r143_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/hpo/executors.py\", line 352, in validate_search_space\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=32755, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=32755, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=32755, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=32755, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: CatBoost_r70_BAG_L1 ... Tuning model for up to 39.24s of the 5865.52s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r70_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622446.991483   15483 chttp2_transport.cc:1161] ipv4:10.0.0.4:36097: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:14:06.991461673+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622447.129518   15477 chttp2_transport.cc:1161] ipv4:10.0.0.4:36445: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:14:07.129491134+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: CatBoost_r70_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.2519\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t33.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.31s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r156_BAG_L1 ... Tuning model for up to 39.24s of the 5831.52s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r156_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Warning: Exception caused NeuralNetFastAI_r156_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/hpo/executors.py\", line 352, in validate_search_space\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=33293, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=33293, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=33293, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=33293, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: LightGBM_r196_BAG_L1 ... Tuning model for up to 39.24s of the 5829.57s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r196_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622505.744333   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:41007: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:15:05.744311886+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: LightGBM_r196_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.5145\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t45.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t25.45s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: RandomForest_r39_BAG_L1 ... Tuning model for up to 39.24s of the 5783.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for RandomForest_r39_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: RandomForest_r39_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.704\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t19.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t2.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: CatBoost_r167_BAG_L1 ... Tuning model for up to 39.24s of the 5763.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r167_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622587.844693   15613 chttp2_transport.cc:1161] ipv4:10.0.0.4:34109: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:16:27.844674076+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: CatBoost_r167_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.2437\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t82.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r95_BAG_L1 ... Tuning model for up to 39.24s of the 5680.5s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r95_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Warning: Exception caused NeuralNetFastAI_r95_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/hpo/executors.py\", line 352, in validate_search_space\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=34593, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=34593, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=34593, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=34593, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622610.794834   15613 chttp2_transport.cc:1161] ipv4:10.0.0.4:39279: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:16:50.794808492+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622610.794924   15483 chttp2_transport.cc:1161] ipv4:10.0.0.4:43739: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:16:50.794912211+00:00\"}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r41_BAG_L1 ... Tuning model for up to 39.24s of the 5678.56s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=34595, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=34595, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╭──────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r41_BAG_L1   │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ├──────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Search algorithm                 SearchGenerator             │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Scheduler                        FIFOScheduler               │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Number of trials                 1000                        │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╰──────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m View detailed results here: /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622613.668391   15477 chttp2_transport.cc:1161] ipv4:10.0.0.4:44125: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:16:53.668375477+00:00\"}\n",
      "\u001b[36m(_ray_fit pid=34819)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=34819)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=35054)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=35054)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m I0000 00:00:1731622647.819526   34786 chttp2_transport.cc:1161] ipv4:10.0.0.4:33801: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:\"2024-11-14T22:17:27.81950196+00:00\"}\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     return metric(y, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     return fbeta_score(\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     _, _, f, _ = precision_recall_fscore_support(\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m     raise ValueError(\n",
      "\u001b[36m(model_trial pid=34775)\u001b[0m ValueError: Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Reached timeout of 39.24433434375741 seconds. Stopping all trials.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Wrote the latest version of all result files and experiment state to '/mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L1' in 0.0521s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m Failed to fetch metrics for 2 trial(s):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 12619ac9: FileNotFoundError('Could not fetch metrics for 12619ac9: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L1/12619ac9')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 97dbf835: FileNotFoundError('Could not fetch metrics for 97dbf835: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r41_BAG_L1/97dbf835')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r41_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: XGBoost_r98_BAG_L1 ... Tuning model for up to 39.24s of the 5638.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for XGBoost_r98_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "\u001b[36m(_ray_fit pid=35112)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=35112)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622687.644769   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:45619: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:18:07.644755439+00:00\", http2_error:2, grpc_status:14}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: XGBoost_r98_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.5745\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t36.15s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t2.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: LightGBM_r15_BAG_L1 ... Tuning model for up to 39.24s of the 5601.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for LightGBM_r15_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: LightGBM_r15_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.6238\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t46.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t23.83s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r158_BAG_L1 ... Tuning model for up to 39.24s of the 5555.0s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r158_BAG_L1   │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Search algorithm                 SearchGenerator              │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Scheduler                        FIFOScheduler                │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Number of trials                 1000                         │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m View detailed results here: /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622736.510150   15613 chttp2_transport.cc:1161] ipv4:10.0.0.4:46781: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:18:56.510127004+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_ray_fit pid=36251)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=36251)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=36489)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=36489)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m I0000 00:00:1731622771.199640   36232 chttp2_transport.cc:1161] ipv4:10.0.0.4:46339: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:19:31.19961515+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m Classification metrics can't handle a mix of unknown and multiclass targets\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 37, in model_trial\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     model = fit_and_save_model(\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m             ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 104, in fit_and_save_model\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     model.val_score = model.score_with_y_pred_proba(y=fit_args[\"y\"], y_pred_proba=oof_pred_proba)\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     return metric(y, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1271, in f1_score\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     return fbeta_score(\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1463, in fbeta_score\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     _, _, f, _ = precision_recall_fscore_support(\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1767, in precision_recall_fscore_support\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 1539, in _check_set_wise_labels\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 94, in _check_targets\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m     raise ValueError(\n",
      "\u001b[36m(model_trial pid=36207)\u001b[0m ValueError: Classification metrics can't handle a mix of unknown and multiclass targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m Reached timeout of 39.24433434375741 seconds. Stopping all trials.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Wrote the latest version of all result files and experiment state to '/mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L1' in 0.0744s.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Failed to fetch metrics for 3 trial(s):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - bea413ae: FileNotFoundError('Could not fetch metrics for bea413ae: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L1/bea413ae')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - c02fb007: FileNotFoundError('Could not fetch metrics for c02fb007: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L1/c02fb007')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m - 9bf24064: FileNotFoundError('Could not fetch metrics for 9bf24064: both result.json and progress.csv were not found at /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r158_BAG_L1/9bf24064')\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m No model was trained during hyperparameter tuning NeuralNetTorch_r158_BAG_L1... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: CatBoost_r86_BAG_L1 ... Tuning model for up to 39.24s of the 5515.07s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for CatBoost_r86_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_ray_fit pid=36496)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=36496)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m I0000 00:00:1731622849.365607   15478 chttp2_transport.cc:1161] ipv4:10.0.0.4:34031: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {created_time:\"2024-11-14T22:20:49.365585654+00:00\", http2_error:2, grpc_status:14}\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Fitted model: CatBoost_r86_BAG_L1 ...\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.2757\t = Validation score   (f1_macro)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t102.21s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \t0.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetFastAI_r37_BAG_L1 ... Tuning model for up to 39.24s of the 5412.5s of remaining time.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tNo hyperparameter search space specified for NeuralNetFastAI_r37_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Warning: Exception caused NeuralNetFastAI_r37_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1333, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_executor.validate_search_space(search_space, self.name)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/hpo/executors.py\", line 352, in validate_search_space\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m autogluon.core.hpo.exceptions.EmptySearchSpace\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2221, in _train_single_full\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1501, in hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 184, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1335, in _hyperparameter_tune\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return skip_hpo(X=X, y=y, X_val=X_val, y_val=y_val, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 122, in skip_hpo\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fit_and_save_model(model=model, fit_args=fit_model_args, predict_proba_args=predict_proba_args, y_val=y_val, time_start=time.time(), time_limit=time_limit)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/model_trial.py\", line 96, in fit_and_save_model\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     model.fit(**fit_args, time_limit=time_left)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 2691, in get\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/ray/_private/worker.py\", line 871, in get_objects\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ray.exceptions.RayTaskError(ImportError): \u001b[36mray::_ray_fit()\u001b[39m (pid=37517, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=37517, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=37517, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=37517, ip=10.0.0.4)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m   File \"/home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/common/utils/try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Hyperparameter tuning model: NeuralNetTorch_r197_BAG_L1 ... Tuning model for up to 39.24s of the 5410.57s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╭───────────────────────────────────────────────────────────────╮\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Configuration for experiment     NeuralNetTorch_r197_BAG_L1   │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ├───────────────────────────────────────────────────────────────┤\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Search algorithm                 SearchGenerator              │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Scheduler                        FIFOScheduler                │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m │ Number of trials                 1000                         │\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m ╰───────────────────────────────────────────────────────────────╯\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m \n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m View detailed results here: /mnt/batch/tasks/shared/LS_root/mounts/clusters/packaginge4dsv5/code/Users/david.tiefenthaler/ml_packaging_classification/notebooks/AutogluonModels/ag-20241114_215127/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_r197_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=15333)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_ray_fit pid=37746)\u001b[0m /home/azureuser/miniforge3/envs/py_ml_packaging_classification/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=37746)\u001b[0m   self.model = torch.load(net_filename)\n"
     ]
    }
   ],
   "source": [
    "label = 'packaging_category'\n",
    "automl_predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    problem_type='multiclass',\n",
    "    eval_metric='f1_macro',\n",
    "    sample_weight='balance_weight'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    tuning_data=None, # If tuning_data = None, fit() will automatically hold out some random validation examples from train_data.\n",
    "    holdout_frac=0.2, # Default value (if None) is selected based on the number of rows in the training data.\n",
    "    time_limit=experiment_time_limit, # 3*60*60\n",
    "    presets=['high_quality'], # ['high_quality'] # default = ['medium_quality'], any user-specified arguments in fit() will override the values used by presets.\n",
    "    # auto_stack=False, # Whether AutoGluon should automatically utilize bagging and multi-layer stack ensembling to boost predictive accuracy.\n",
    "    # included_model_types=['LR', 'KNN', 'RF', 'XT', 'GBM', 'XGB', 'CAT', 'NN'],\n",
    "    # excluded_model_types=['FASTAI', 'AG_AUTOMM'],\n",
    "    hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified. Searchspaces are provided for some models, but not for all. Where no searchspace is provided, a fixed set of hyper-parameters is defined. (see /searchspace under each model: https://github.com/autogluon/autogluon/tree/master/tabular/src/autogluon/tabular/models).\n",
    "        # 'num_trials': 15, # try at most n different hyperparameter configurations for each type of model\n",
    "        'scheduler' : 'local',\n",
    "        'searcher': 'auto', # ‘auto’: Perform bayesian optimization search on NN_TORCH and FASTAI models. Perform random search on other models.\n",
    "    }  # Refer to TabularPredictor.fit docstring for all valid values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.859076</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1188.566702</td>\n",
       "      <td>6820.678373</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>42.044546</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.819919</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1140.665690</td>\n",
       "      <td>5161.254293</td>\n",
       "      <td>40.693184</td>\n",
       "      <td>80.217303</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees_r126_BAG_L2</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1143.839039</td>\n",
       "      <td>5163.883235</td>\n",
       "      <td>43.866533</td>\n",
       "      <td>82.846245</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_r194_BAG_L2</td>\n",
       "      <td>0.816081</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1103.829203</td>\n",
       "      <td>5284.588265</td>\n",
       "      <td>3.856698</td>\n",
       "      <td>203.551275</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees_r49_BAG_L2</td>\n",
       "      <td>0.813140</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1130.381731</td>\n",
       "      <td>5138.845068</td>\n",
       "      <td>30.409225</td>\n",
       "      <td>57.808078</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>CatBoost_r60_BAG_L2</td>\n",
       "      <td>0.111131</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.568627</td>\n",
       "      <td>5237.745740</td>\n",
       "      <td>1.596121</td>\n",
       "      <td>156.708750</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>CatBoost_r137_BAG_L2</td>\n",
       "      <td>0.086546</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.468116</td>\n",
       "      <td>5202.956067</td>\n",
       "      <td>1.495610</td>\n",
       "      <td>121.919077</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>CatBoost_r50_BAG_L2</td>\n",
       "      <td>0.080389</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.629409</td>\n",
       "      <td>5218.065786</td>\n",
       "      <td>1.656903</td>\n",
       "      <td>137.028796</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>CatBoost_r6_BAG_L2</td>\n",
       "      <td>0.080389</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.632979</td>\n",
       "      <td>5209.795149</td>\n",
       "      <td>1.660473</td>\n",
       "      <td>128.758159</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>CatBoost_r49_BAG_L2</td>\n",
       "      <td>0.067516</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1101.304781</td>\n",
       "      <td>5197.243922</td>\n",
       "      <td>1.332276</td>\n",
       "      <td>116.206932</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val eval_metric  pred_time_val  \\\n",
       "0       WeightedEnsemble_L3   0.859076    f1_macro    1188.566702   \n",
       "1     ExtraTreesGini_BAG_L2   0.819919    f1_macro    1140.665690   \n",
       "2    ExtraTrees_r126_BAG_L2   0.817493    f1_macro    1143.839039   \n",
       "3       XGBoost_r194_BAG_L2   0.816081    f1_macro    1103.829203   \n",
       "4     ExtraTrees_r49_BAG_L2   0.813140    f1_macro    1130.381731   \n",
       "..                      ...        ...         ...            ...   \n",
       "103     CatBoost_r60_BAG_L2   0.111131    f1_macro    1101.568627   \n",
       "104    CatBoost_r137_BAG_L2   0.086546    f1_macro    1101.468116   \n",
       "105     CatBoost_r50_BAG_L2   0.080389    f1_macro    1101.629409   \n",
       "106      CatBoost_r6_BAG_L2   0.080389    f1_macro    1101.632979   \n",
       "107     CatBoost_r49_BAG_L2   0.067516    f1_macro    1101.304781   \n",
       "\n",
       "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0    6820.678373                0.046121          42.044546            3   \n",
       "1    5161.254293               40.693184          80.217303            2   \n",
       "2    5163.883235               43.866533          82.846245            2   \n",
       "3    5284.588265                3.856698         203.551275            2   \n",
       "4    5138.845068               30.409225          57.808078            2   \n",
       "..           ...                     ...                ...          ...   \n",
       "103  5237.745740                1.596121         156.708750            2   \n",
       "104  5202.956067                1.495610         121.919077            2   \n",
       "105  5218.065786                1.656903         137.028796            2   \n",
       "106  5209.795149                1.660473         128.758159            2   \n",
       "107  5197.243922                1.332276         116.206932            2   \n",
       "\n",
       "     can_infer  fit_order  \n",
       "0         True        108  \n",
       "1         True         64  \n",
       "2         True        103  \n",
       "3         True         77  \n",
       "4         True         87  \n",
       "..         ...        ...  \n",
       "103       True         97  \n",
       "104       True         71  \n",
       "105       True         76  \n",
       "106       True        100  \n",
       "107       True         86  \n",
       "\n",
       "[108 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of models on training data\n",
    "automl_predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate AutoML experiment and best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.795750</td>\n",
       "      <td>0.859076</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>280.823390</td>\n",
       "      <td>1188.566702</td>\n",
       "      <td>6820.678373</td>\n",
       "      <td>0.064283</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>42.044546</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.793289</td>\n",
       "      <td>0.770915</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>232.414696</td>\n",
       "      <td>1102.842265</td>\n",
       "      <td>5402.890837</td>\n",
       "      <td>5.511735</td>\n",
       "      <td>2.869759</td>\n",
       "      <td>321.853848</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees_r49_BAG_L2</td>\n",
       "      <td>0.785937</td>\n",
       "      <td>0.813140</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>228.219033</td>\n",
       "      <td>1130.381731</td>\n",
       "      <td>5138.845068</td>\n",
       "      <td>1.316072</td>\n",
       "      <td>30.409225</td>\n",
       "      <td>57.808078</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.784021</td>\n",
       "      <td>0.819919</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>228.352076</td>\n",
       "      <td>1140.665690</td>\n",
       "      <td>5161.254293</td>\n",
       "      <td>1.449115</td>\n",
       "      <td>40.693184</td>\n",
       "      <td>80.217303</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees_r126_BAG_L2</td>\n",
       "      <td>0.779704</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>228.390524</td>\n",
       "      <td>1143.839039</td>\n",
       "      <td>5163.883235</td>\n",
       "      <td>1.487563</td>\n",
       "      <td>43.866533</td>\n",
       "      <td>82.846245</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_r161_BAG_L2</td>\n",
       "      <td>0.772103</td>\n",
       "      <td>0.758902</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>230.255658</td>\n",
       "      <td>1102.791656</td>\n",
       "      <td>5266.127891</td>\n",
       "      <td>3.352697</td>\n",
       "      <td>2.819150</td>\n",
       "      <td>185.090901</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_r143_BAG_L2</td>\n",
       "      <td>0.771631</td>\n",
       "      <td>0.758595</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>230.610279</td>\n",
       "      <td>1102.714723</td>\n",
       "      <td>5274.867135</td>\n",
       "      <td>3.707318</td>\n",
       "      <td>2.742217</td>\n",
       "      <td>193.830145</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost_r194_BAG_L2</td>\n",
       "      <td>0.769743</td>\n",
       "      <td>0.816081</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>229.520288</td>\n",
       "      <td>1103.829203</td>\n",
       "      <td>5284.588265</td>\n",
       "      <td>2.617327</td>\n",
       "      <td>3.856698</td>\n",
       "      <td>203.551275</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost_r98_BAG_L2</td>\n",
       "      <td>0.767747</td>\n",
       "      <td>0.791508</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>229.617231</td>\n",
       "      <td>1103.124689</td>\n",
       "      <td>5296.424059</td>\n",
       "      <td>2.714270</td>\n",
       "      <td>3.152184</td>\n",
       "      <td>215.387069</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2</td>\n",
       "      <td>0.764335</td>\n",
       "      <td>0.789718</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>229.280277</td>\n",
       "      <td>1170.114186</td>\n",
       "      <td>5202.825697</td>\n",
       "      <td>2.377316</td>\n",
       "      <td>70.141680</td>\n",
       "      <td>121.788707</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0     WeightedEnsemble_L3    0.795750   0.859076    f1_macro      280.823390   \n",
       "1    LightGBMLarge_BAG_L2    0.793289   0.770915    f1_macro      232.414696   \n",
       "2   ExtraTrees_r49_BAG_L2    0.785937   0.813140    f1_macro      228.219033   \n",
       "3   ExtraTreesGini_BAG_L2    0.784021   0.819919    f1_macro      228.352076   \n",
       "4  ExtraTrees_r126_BAG_L2    0.779704   0.817493    f1_macro      228.390524   \n",
       "5    LightGBM_r161_BAG_L2    0.772103   0.758902    f1_macro      230.255658   \n",
       "6    LightGBM_r143_BAG_L2    0.771631   0.758595    f1_macro      230.610279   \n",
       "7     XGBoost_r194_BAG_L2    0.769743   0.816081    f1_macro      229.520288   \n",
       "8      XGBoost_r98_BAG_L2    0.767747   0.791508    f1_macro      229.617231   \n",
       "9   ExtraTreesEntr_BAG_L2    0.764335   0.789718    f1_macro      229.280277   \n",
       "\n",
       "   pred_time_val     fit_time  pred_time_test_marginal  \\\n",
       "0    1188.566702  6820.678373                 0.064283   \n",
       "1    1102.842265  5402.890837                 5.511735   \n",
       "2    1130.381731  5138.845068                 1.316072   \n",
       "3    1140.665690  5161.254293                 1.449115   \n",
       "4    1143.839039  5163.883235                 1.487563   \n",
       "5    1102.791656  5266.127891                 3.352697   \n",
       "6    1102.714723  5274.867135                 3.707318   \n",
       "7    1103.829203  5284.588265                 2.617327   \n",
       "8    1103.124689  5296.424059                 2.714270   \n",
       "9    1170.114186  5202.825697                 2.377316   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.046121          42.044546            3       True   \n",
       "1                2.869759         321.853848            2       True   \n",
       "2               30.409225          57.808078            2       True   \n",
       "3               40.693184          80.217303            2       True   \n",
       "4               43.866533          82.846245            2       True   \n",
       "5                2.819150         185.090901            2       True   \n",
       "6                2.742217         193.830145            2       True   \n",
       "7                3.856698         203.551275            2       True   \n",
       "8                3.152184         215.387069            2       True   \n",
       "9               70.141680         121.788707            2       True   \n",
       "\n",
       "   fit_order  \n",
       "0        108  \n",
       "1         66  \n",
       "2         87  \n",
       "3         64  \n",
       "4        103  \n",
       "5         79  \n",
       "6         88  \n",
       "7         77  \n",
       "8         83  \n",
       "9         65  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of models on test data\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "test_data = TabularDataset(df_test)\n",
    "\n",
    "automl_std_leaderboard_testdata = automl_predictor.leaderboard(test_data)\n",
    "automl_std_leaderboard_testdata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model to be evaluated: WeightedEnsemble_L3\n",
      "Predictions:   ['Blister and Insert Card', 'Corrugated carton', 'Plastic bag with header', 'Tube', 'Shrink film and insert o']\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "   Blister and Insert Card       0.90      0.88      0.89      1749\n",
      "  Blister and sealed blist       0.87      0.83      0.85      1582\n",
      "            Book packaging       0.00      0.00      0.00         2\n",
      "Cardb. Sleeve w - w/o Shr.       0.75      0.71      0.73       135\n",
      "  Cardboard hanger w/o bag       1.00      0.84      0.91        80\n",
      "    Carton cover (Lid box)       0.63      0.63      0.63       130\n",
      "   Carton tube with or w/o       1.00      0.67      0.80         9\n",
      "                      Case       0.72      0.92      0.81        97\n",
      "         Corrugated carton       0.81      0.84      0.82       774\n",
      "        Countertop display       1.00      0.97      0.98        30\n",
      "                  Envelope       0.95      0.98      0.97        59\n",
      "          Fabric packaging       1.00      0.33      0.50         3\n",
      "            Folding carton       0.86      0.82      0.84      1644\n",
      "              Hanger/ Clip       0.95      0.95      0.95      2709\n",
      "            Metal Cassette       0.73      0.80      0.76        10\n",
      "          Paperboard pouch       0.82      0.91      0.86       696\n",
      "               Plastic Box       0.92      0.93      0.93       298\n",
      "          Plastic Cassette       0.89      0.85      0.87       342\n",
      "             Plastic Pouch       0.87      0.85      0.86       381\n",
      "   Plastic bag with header       0.70      0.78      0.74       370\n",
      "  Shrink film and insert o       0.81      0.88      0.84       300\n",
      "                  Skincard       0.81      0.93      0.86       229\n",
      "                 TightPack       0.93      0.91      0.92      1659\n",
      "                 Trap Card       0.99      1.00      0.99       161\n",
      "         Trap Folding Card       0.70      0.94      0.81       438\n",
      "               Tray Packer       0.65      0.92      0.76        86\n",
      "                      Tube       0.95      0.88      0.91      2337\n",
      "                  Unpacked       0.75      0.80      0.77       283\n",
      "                Wooden box       1.00      0.33      0.50         3\n",
      "\n",
      "                  accuracy                           0.88     16596\n",
      "                 macro avg       0.83      0.80      0.80     16596\n",
      "              weighted avg       0.88      0.88      0.88     16596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For a single specified model: make predictions and perform detailed evaluation on hold out test data\n",
    "# i = -1  # index of model to use\n",
    "# model_to_use = automl_predictor.model_names()[i]\n",
    "model_to_use = automl_std_leaderboard_testdata.iloc[0, 0] # use best model from leaderboard\n",
    "print(f\"Model to be evaluated: {model_to_use}\")\n",
    "preds_y_test = automl_predictor.predict(X_test, model=model_to_use)\n",
    "print(\"Predictions:  \", list(preds_y_test)[:5])\n",
    "\n",
    "print(classification_report(y_test, preds_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML: custom pre-processing; restricted selection of models including HPO and model ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define features and target, performe oversampling, split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversmapling\n",
      "{'Hanger/ Clip': 13543, 'Tube': 11687, 'Blister and Insert Card': 8744, 'TightPack': 8296, 'Folding carton': 8219, 'Blister and sealed blist': 7912, 'Corrugated carton': 3872, 'Paperboard pouch': 3478, 'Trap Folding Card': 2188, 'Plastic Pouch': 1904, 'Plastic bag with header': 1850, 'Plastic Cassette': 1708, 'Shrink film and insert o': 1499, 'Plastic Box': 1491, 'Unpacked': 1415, 'Skincard': 1143, 'Trap Card': 804, 'Cardb. Sleeve w - w/o Shr.': 676, 'Carton cover (Lid box)': 652, 'Case': 485, 'Tray Packer': 431, 'Cardboard hanger w/o bag': 400, 'Envelope': 295, 'Countertop display': 150, 'Metal Cassette': 50, 'Carton tube with or w/o': 44, 'Wooden box': 16, 'Fabric packaging': 15, 'Book packaging': 10}\n",
      "Class distribution after oversmapling\n",
      "{'Hanger/ Clip': 13543, 'Tube': 11687, 'Blister and Insert Card': 8744, 'TightPack': 8296, 'Folding carton': 8219, 'Blister and sealed blist': 7912, 'Corrugated carton': 3872, 'Paperboard pouch': 3478, 'Trap Folding Card': 2188, 'Plastic Pouch': 1904, 'Plastic bag with header': 1850, 'Plastic Cassette': 1708, 'Shrink film and insert o': 1499, 'Plastic Box': 1491, 'Unpacked': 1415, 'Skincard': 1143, 'Trap Card': 804, 'Cardb. Sleeve w - w/o Shr.': 676, 'Carton cover (Lid box)': 652, 'Case': 485, 'Tray Packer': 431, 'Cardboard hanger w/o bag': 400, 'Envelope': 295, 'Countertop display': 150, 'Carton tube with or w/o': 100, 'Wooden box': 100, 'Metal Cassette': 100, 'Book packaging': 100, 'Fabric packaging': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "X = df_sub.iloc[:, :-1]\n",
    "y = df_sub.iloc[:, -1]  # the last column is the target\n",
    "\n",
    "# Oversampling\n",
    "distribution_classes = y.value_counts()\n",
    "print('Class distribution before oversmapling')\n",
    "print(distribution_classes.to_dict())\n",
    "# NOTE: Oversampling so each class has at least 100 sample; to properly apply CV and evaluation\n",
    "dict_oversmapling = {\n",
    "    'Metal Cassette': 100,\n",
    "    'Carton tube with or w/o': 100,\n",
    "    'Wooden box': 100,\n",
    "    'Fabric packaging': 100,\n",
    "    'Book packaging': 100\n",
    "}\n",
    "# define oversampling strategy\n",
    "oversampler = RandomOverSampler(sampling_strategy=dict_oversmapling, random_state=SEED)\n",
    "# fit and apply the transform\n",
    "X_oversample, y_oversample = oversampler.fit_resample(X, y)\n",
    "print('Class distribution after oversmapling')\n",
    "print(y_oversample.value_counts().to_dict())\n",
    "\n",
    "# Generate train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_oversample, y_oversample, test_size=0.2, stratify=y_oversample,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE & EXECUTE PIPELINE\n",
    "# Define pipeline\n",
    "numerical_features = X_train.select_dtypes(include='number').columns.tolist()\n",
    "numeric_feature_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('log_transform', PowerTransformer()),\n",
    "    # ('scale', MinMaxScaler())\n",
    "])\n",
    "categorical_features = X_train.select_dtypes(exclude='number').columns.tolist()\n",
    "categorical_feature_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "])\n",
    "preprocess_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('number', numeric_feature_pipeline, numerical_features),\n",
    "        ('category', categorical_feature_pipeline, categorical_features)\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform=\"pandas\")\n",
    "# transform data\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)\n",
    "\n",
    "# encode target variable\n",
    "label_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, encoded_missing_value=-1)\n",
    "y_train_transformed = label_encoder.fit_transform(y_train.to_frame())\n",
    "y_train_transformed = pd.DataFrame(data=y_train_transformed, index=y_train.index, columns=[y_train.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to AutoML data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train_transformed, y_train_transformed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(df_train)\n",
    "if subsample is True:\n",
    "    train_data = train_data.sample(n=subsample_size, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was trained during hyperparameter tuning NeuralNetTorch... Skipping this model.\n",
      "Fitting model: LightGBMLarge ... Training model for up to 1993.81s of the 17758.43s of remaining time.\n",
      "\t0.7914\t = Validation score   (f1_macro)\n",
      "\t144.01s\t = Training   runtime\n",
      "\t55.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 2879.95s of the 17532.49s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMLarge': 0.357, 'KNeighborsDist': 0.214, 'RandomForestGini': 0.143, 'RandomForestEntr': 0.143, 'KNeighborsUnif': 0.071, 'ExtraTreesGini': 0.071}\n",
      "\t0.7983\t = Validation score   (f1_macro)\n",
      "\t3.17s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11271.22s ... Best model: WeightedEnsemble_L2\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241113_225037\")\n"
     ]
    }
   ],
   "source": [
    "label = 'packaging_category'\n",
    "automl_predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    problem_type='multiclass',\n",
    "    eval_metric='f1_macro',\n",
    "    sample_weight='balance_weight'\n",
    ").fit(\n",
    "    train_data=train_data,\n",
    "    tuning_data=None, # If tuning_data = None, fit() will automatically hold out some random validation examples from train_data.\n",
    "    holdout_frac=0.2, # Default value (if None) is selected based on the number of rows in the training data.\n",
    "    time_limit=experiment_time_limit, # 3*60*60\n",
    "    presets=['high_quality'], # ['high_quality'] # default = ['medium_quality'], any user-specified arguments in fit() will override the values used by presets.\n",
    "    # auto_stack=False, # Whether AutoGluon should automatically utilize bagging and multi-layer stack ensembling to boost predictive accuracy.\n",
    "    # included_model_types=['LR', 'KNN', 'RF', 'XT', 'GBM', 'XGB', 'CAT', 'NN'], \n",
    "    # excluded_model_types=['FASTAI', 'AG_AUTOMM'],\n",
    "    hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified. Searchspaces are provided for some models, but not for all. Where no searchspace is provided, a fixed set of hyper-parameters is defined. (see /searchspace under each model: https://github.com/autogluon/autogluon/tree/master/tabular/src/autogluon/tabular/models).\n",
    "        # 'num_trials': 15, # try at most n different hyperparameter configurations for each type of model\n",
    "        'scheduler' : 'local',\n",
    "        'searcher': 'auto', # ‘auto’: Perform bayesian optimization search on NN_TORCH and FASTAI models. Perform random search on other models.\n",
    "    }  # Refer to TabularPredictor.fit docstring for all valid values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.798341</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>63.077952</td>\n",
       "      <td>194.487381</td>\n",
       "      <td>0.218747</td>\n",
       "      <td>3.174761</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.791435</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>55.271506</td>\n",
       "      <td>144.005281</td>\n",
       "      <td>55.271506</td>\n",
       "      <td>144.005281</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.763345</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>2.218809</td>\n",
       "      <td>15.697407</td>\n",
       "      <td>2.218809</td>\n",
       "      <td>15.697407</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.761439</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>2.849804</td>\n",
       "      <td>26.464896</td>\n",
       "      <td>2.849804</td>\n",
       "      <td>26.464896</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.759531</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1.834237</td>\n",
       "      <td>5.276078</td>\n",
       "      <td>1.834237</td>\n",
       "      <td>5.276078</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.758739</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>1.936817</td>\n",
       "      <td>4.777079</td>\n",
       "      <td>1.936817</td>\n",
       "      <td>4.777079</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.437977</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.298646</td>\n",
       "      <td>0.236018</td>\n",
       "      <td>0.298646</td>\n",
       "      <td>0.236018</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.321687</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.283623</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>0.283623</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val eval_metric  pred_time_val    fit_time  \\\n",
       "0  WeightedEnsemble_L2   0.798341    f1_macro      63.077952  194.487381   \n",
       "1        LightGBMLarge   0.791435    f1_macro      55.271506  144.005281   \n",
       "2     RandomForestGini   0.763345    f1_macro       2.218809   15.697407   \n",
       "3     RandomForestEntr   0.761439    f1_macro       2.849804   26.464896   \n",
       "4       ExtraTreesEntr   0.759531    f1_macro       1.834237    5.276078   \n",
       "5       ExtraTreesGini   0.758739    f1_macro       1.936817    4.777079   \n",
       "6       KNeighborsDist   0.437977    f1_macro       0.298646    0.236018   \n",
       "7       KNeighborsUnif   0.321687    f1_macro       0.283623    0.131939   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.218747           3.174761            2       True   \n",
       "1               55.271506         144.005281            1       True   \n",
       "2                2.218809          15.697407            1       True   \n",
       "3                2.849804          26.464896            1       True   \n",
       "4                1.834237           5.276078            1       True   \n",
       "5                1.936817           4.777079            1       True   \n",
       "6                0.298646           0.236018            1       True   \n",
       "7                0.283623           0.131939            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          8  \n",
       "1          7  \n",
       "2          3  \n",
       "3          4  \n",
       "4          6  \n",
       "5          5  \n",
       "6          2  \n",
       "7          1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of models on training data\n",
    "automl_predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate AutoML experiment and best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: AutogluonModels/ag-20241113_225037\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.740478</td>\n",
       "      <td>0.798341</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>91.967577</td>\n",
       "      <td>63.077952</td>\n",
       "      <td>194.487381</td>\n",
       "      <td>0.152463</td>\n",
       "      <td>0.218747</td>\n",
       "      <td>3.174761</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.739120</td>\n",
       "      <td>0.758739</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>3.753227</td>\n",
       "      <td>1.936817</td>\n",
       "      <td>4.777079</td>\n",
       "      <td>3.753227</td>\n",
       "      <td>1.936817</td>\n",
       "      <td>4.777079</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.734841</td>\n",
       "      <td>0.759531</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>3.846254</td>\n",
       "      <td>1.834237</td>\n",
       "      <td>5.276078</td>\n",
       "      <td>3.846254</td>\n",
       "      <td>1.834237</td>\n",
       "      <td>5.276078</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.734640</td>\n",
       "      <td>0.791435</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>76.845919</td>\n",
       "      <td>55.271506</td>\n",
       "      <td>144.005281</td>\n",
       "      <td>76.845919</td>\n",
       "      <td>55.271506</td>\n",
       "      <td>144.005281</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.728181</td>\n",
       "      <td>0.761439</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>6.205621</td>\n",
       "      <td>2.849804</td>\n",
       "      <td>26.464896</td>\n",
       "      <td>6.205621</td>\n",
       "      <td>2.849804</td>\n",
       "      <td>26.464896</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.725460</td>\n",
       "      <td>0.763345</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>4.805619</td>\n",
       "      <td>2.218809</td>\n",
       "      <td>15.697407</td>\n",
       "      <td>4.805619</td>\n",
       "      <td>2.218809</td>\n",
       "      <td>15.697407</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.405158</td>\n",
       "      <td>0.437977</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.104866</td>\n",
       "      <td>0.298646</td>\n",
       "      <td>0.236018</td>\n",
       "      <td>0.104866</td>\n",
       "      <td>0.298646</td>\n",
       "      <td>0.236018</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.301214</td>\n",
       "      <td>0.321687</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.099862</td>\n",
       "      <td>0.283623</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>0.099862</td>\n",
       "      <td>0.283623</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0  WeightedEnsemble_L2    0.740478   0.798341    f1_macro       91.967577   \n",
       "1       ExtraTreesGini    0.739120   0.758739    f1_macro        3.753227   \n",
       "2       ExtraTreesEntr    0.734841   0.759531    f1_macro        3.846254   \n",
       "3        LightGBMLarge    0.734640   0.791435    f1_macro       76.845919   \n",
       "4     RandomForestEntr    0.728181   0.761439    f1_macro        6.205621   \n",
       "5     RandomForestGini    0.725460   0.763345    f1_macro        4.805619   \n",
       "6       KNeighborsDist    0.405158   0.437977    f1_macro        0.104866   \n",
       "7       KNeighborsUnif    0.301214   0.321687    f1_macro        0.099862   \n",
       "\n",
       "   pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0      63.077952  194.487381                 0.152463                0.218747   \n",
       "1       1.936817    4.777079                 3.753227                1.936817   \n",
       "2       1.834237    5.276078                 3.846254                1.834237   \n",
       "3      55.271506  144.005281                76.845919               55.271506   \n",
       "4       2.849804   26.464896                 6.205621                2.849804   \n",
       "5       2.218809   15.697407                 4.805619                2.218809   \n",
       "6       0.298646    0.236018                 0.104866                0.298646   \n",
       "7       0.283623    0.131939                 0.099862                0.283623   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           3.174761            2       True          8  \n",
       "1           4.777079            1       True          5  \n",
       "2           5.276078            1       True          6  \n",
       "3         144.005281            1       True          7  \n",
       "4          26.464896            1       True          4  \n",
       "5          15.697407            1       True          3  \n",
       "6           0.236018            1       True          2  \n",
       "7           0.131939            1       True          1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of models on test data\n",
    "\n",
    "# NOTE: Load a TabularPredictor object previously produced by fit() from file and returns this object.\n",
    "try:\n",
    "    # NOTE: set the directory to the saved model\n",
    "    specific_path = None # Default: None ; Path fromat: 'AutogluonModels/ag-20241113_002120'\n",
    "    autogluon_saved_model_path = specific_path if specific_path else automl_predictor.path\n",
    "    automl_predictor = automl_predictor if automl_predictor else TabularPredictor.load(f\"{config['autogluon_exp_storage_directory']}/{autogluon_saved_model_path}\")\n",
    "    print(f\"Model loaded from: {automl_predictor.path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Model could not be loaded. An error occurred: {e}\")\n",
    "\n",
    "# process X_test for evaluation and predictions\n",
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "# evaluate models on test data\n",
    "y_test_transformed = label_encoder.transform(y_test.to_frame())\n",
    "y_test_transformed = pd.DataFrame(data=y_test_transformed, index=y_test.index, columns=[y_test.name])\n",
    "df_test = pd.concat([X_test_transformed, y_test_transformed], axis=1)\n",
    "test_data = TabularDataset(df_test)\n",
    "\n",
    "automl_custom_leaderboard_testdata = automl_predictor.leaderboard(test_data)\n",
    "automl_custom_leaderboard_testdata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WeightedEnsemble_L2', 'ExtraTreesGini', 'ExtraTreesEntr',\n",
       "       'LightGBMLarge', 'RandomForestEntr', 'RandomForestGini',\n",
       "       'KNeighborsDist', 'KNeighborsUnif'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_custom_leaderboard_testdata.model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.739069</td>\n",
       "      <td>0.758777</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>3.120127</td>\n",
       "      <td>3.023791</td>\n",
       "      <td>9.571872</td>\n",
       "      <td>3.120127</td>\n",
       "      <td>3.023791</td>\n",
       "      <td>9.571872</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "1  ExtraTreesGini    0.739069   0.758777    f1_macro        3.120127   \n",
       "\n",
       "   pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "1       3.023791  9.571872                 3.120127                3.023791   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "1           9.571872            1       True          5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_custom_leaderboard_testdata[automl_custom_leaderboard_testdata['model'].str.contains('ExtraTreesGini')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model to be evaluated: WeightedEnsemble_L2\n",
      "Predictions:   [23.0, 0.0, 1.0, 26.0, 26.0]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "   Blister and Insert Card       0.77      0.85      0.81      1749\n",
      "  Blister and sealed blist       0.78      0.77      0.78      1582\n",
      "            Book packaging       0.91      1.00      0.95        20\n",
      "Cardb. Sleeve w - w/o Shr.       0.59      0.41      0.49       135\n",
      "  Cardboard hanger w/o bag       0.49      0.39      0.43        80\n",
      "    Carton cover (Lid box)       0.55      0.54      0.54       130\n",
      "   Carton tube with or w/o       0.68      0.85      0.76        20\n",
      "                      Case       0.65      0.53      0.58        97\n",
      "         Corrugated carton       0.77      0.75      0.76       774\n",
      "        Countertop display       0.81      0.73      0.77        30\n",
      "                  Envelope       0.94      0.86      0.90        59\n",
      "          Fabric packaging       0.95      1.00      0.98        20\n",
      "            Folding carton       0.80      0.69      0.74      1644\n",
      "              Hanger/ Clip       0.88      0.95      0.91      2709\n",
      "            Metal Cassette       1.00      0.75      0.86        20\n",
      "          Paperboard pouch       0.78      0.83      0.81       696\n",
      "               Plastic Box       0.92      0.76      0.83       298\n",
      "          Plastic Cassette       0.81      0.52      0.63       342\n",
      "             Plastic Pouch       0.72      0.70      0.71       381\n",
      "   Plastic bag with header       0.72      0.69      0.70       370\n",
      "  Shrink film and insert o       0.67      0.65      0.66       300\n",
      "                  Skincard       0.48      0.86      0.62       229\n",
      "                 TightPack       0.90      0.85      0.87      1659\n",
      "                 Trap Card       0.65      0.78      0.71       161\n",
      "         Trap Folding Card       0.73      0.76      0.74       438\n",
      "               Tray Packer       0.34      0.31      0.33        86\n",
      "                      Tube       0.87      0.87      0.87      2337\n",
      "                  Unpacked       0.75      0.72      0.74       283\n",
      "                Wooden box       1.00      1.00      1.00        20\n",
      "\n",
      "                  accuracy                           0.80     16669\n",
      "                 macro avg       0.76      0.74      0.74     16669\n",
      "              weighted avg       0.81      0.80      0.80     16669\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For a single specified model: make predictions and perform detailed evaluation on hold out test data\n",
    "# i = -1  # index of model to use\n",
    "# model_to_use = automl_predictor.model_names()[i]\n",
    "# model_to_use = automl_custom_leaderboard_testdata.iloc[0, 0] # use best model from leaderboard\n",
    "model_to_use = automl_predictor.model_best\n",
    "print(f\"Model to be evaluated: {model_to_use}\")\n",
    "preds_y_test = automl_predictor.predict(X_test_transformed, model=model_to_use)\n",
    "print(\"Predictions:  \", list(preds_y_test)[:5])\n",
    "\n",
    "preds_y_test_inverse = label_encoder.inverse_transform(preds_y_test.to_frame())\n",
    "\n",
    "# print classification report for holdout test data\n",
    "print(classification_report(y_test, preds_y_test_inverse))\n",
    "report = classification_report(y_test, preds_y_test_inverse, output_dict=True)\n",
    "f1_score = report['accuracy']\n",
    "f1_macro = report['macro avg']['f1-score']\n",
    "\n",
    "# get best model parameters for mlflow tracking\n",
    "trainer = automl_predictor._trainer\n",
    "best_model = trainer.load_model(trainer.model_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track performance using MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Change to a meaningful name\n",
    "EXPERIMENT_NAME = \"AutoPackagingCategories\"\n",
    "RUN_NAME = \"run_AutoML_AutoGluonTabular\"\n",
    "\n",
    "with open('../env_vars.yml', 'r') as file:\n",
    "    env_vars = yaml.safe_load(file)\n",
    "\n",
    "project_dir = env_vars['project_directory']\n",
    "os.makedirs(project_dir + '/mlruns', exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(\"file://\" + project_dir + \"/mlruns\")\n",
    "\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    EXPERIMENT_ID = experiment.experiment_id\n",
    "except AttributeError:\n",
    "    EXPERIMENT_ID = mlflow.create_experiment(\n",
    "        EXPERIMENT_NAME,\n",
    "        # mlflow.set_artifact_uri(\"file://\" + project_dir + \"/artifacts/\")\n",
    "    )\n",
    "\n",
    "current_time = datetime.datetime.now()\n",
    "time_stamp = str(current_time)\n",
    "# NOTE: Change to a meaningful name for the single trial\n",
    "# exp_run_name = f\"run_MeaningfulTrialName_{time_stamp}\"\n",
    "exp_run_name = f\"{RUN_NAME}_{time_stamp}\"\n",
    "\n",
    "# Start MLflow\n",
    "with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=exp_run_name) as run:\n",
    "\n",
    "    # Retrieve run id\n",
    "    RUN_ID = run.info.run_id\n",
    "\n",
    "    # Track parameters\n",
    "    # track pipeline configs: preprocessing_pipeline\n",
    "    mlflow.log_dict(\n",
    "        {'oversampler': type(oversampler), 'label_encoder': type(label_encoder)} | preprocess_pipeline.named_transformers_,\n",
    "        \"preprocessing_pipeline.json\"\n",
    "    )\n",
    "\n",
    "    # mode specfic parameters\n",
    "    mlflow.log_param('model', f'{type(best_model)}: {best_model.base_model_names}')\n",
    "    mlflow.log_param('model_configs', best_model.get_trained_params())\n",
    "\n",
    "    # Track metrics\n",
    "    mlflow.log_dict(report, \"classification_report.json\")\n",
    "    mlflow.log_metric(\"Report_Test_f1_score\", f1_score)\n",
    "    mlflow.log_metric(\"Report_Test_f1_macro\", f1_macro)\n",
    "    \n",
    "    # Track model\n",
    "    # mlflow.sklearn.log_model(clf, \"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def keep_alive_with_cpu_activity(duration_hours=1):\n",
    "    \"\"\"\n",
    "    Keeps the compute instance alive by running a periodic CPU task for a specified duration.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    end_time = start_time + duration_hours * 3600  # convert hours to seconds\n",
    "    print(f\"Keeping the instance alive for {duration_hours} hours with periodic CPU activity.\")\n",
    "    print(\"To stop the function, create an empty file named stop_signal.txt in the same directory as your notebook.\")\n",
    "    print(f\"os.path: {os.path}\")\n",
    "\n",
    "    while time.time() < end_time:\n",
    "        # Check if stop signal file exists\n",
    "        if os.path.isfile(\"stop_signal.txt\"):\n",
    "            print(\"Stop signal received. Exiting the loop.\")\n",
    "            break\n",
    "\n",
    "        # Perform a small computation to generate CPU activity\n",
    "        _ = np.random.rand(1000000, 1000000).dot(np.random.rand(1000000, 1000000))\n",
    "        time.sleep(60)  # Sleep for 60 seconds\n",
    "\n",
    "    print(\"Finished keeping the instance alive.\")\n",
    "\n",
    "# Run for the desired duration (e.g., 4 hours)\n",
    "keep_alive_with_cpu_activity(duration_hours=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
